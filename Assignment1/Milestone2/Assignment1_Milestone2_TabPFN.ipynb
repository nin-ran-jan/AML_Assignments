{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_o82TjduV4L",
        "outputId": "f754f5bc-8a03-44b7-db36-4a0aa52ad1f9"
      },
      "outputs": [],
      "source": [
        "# !gdown https://drive.google.com/file/d/1Hv4RAltBumSfOkRacoX8qrfDYfd_NDss/view?usp=drive_link --fuzzy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UD9ZDc-TvXuQ",
        "outputId": "bd6856a8-62d4-442f-adda-0f87f8b8e47d"
      },
      "outputs": [],
      "source": [
        "# !unzip Dataset_AML_Assignment1_Part1.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMiPtCSFLfGA",
        "outputId": "5677688c-94a4-422c-bb36-da7e1a8da60d"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "HwsdAOp9wdrt"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tabpfn import TabPFNClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "from copy import deepcopy\n",
        "import gc\n",
        "\n",
        "import time\n",
        "\n",
        "import keras.backend as K\n",
        "\n",
        "import pickle as pkl\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "prefix = './data_dump_tabpfn'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "def accuracy(y_pred, y_test, verbose=False):\n",
        "    m = y_test.shape[0]\n",
        "    correct = (y_pred == y_test).sum()\n",
        "    if verbose:\n",
        "        print(correct,m)\n",
        "    accuracy = correct/m\n",
        "    return accuracy, correct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "def Train_Test(X_train, y_train, all_X_test, class_label, mode, noise_level):\n",
        "    binary_labels = (y_train == class_label).astype(int)    \n",
        "    net = TabPFNClassifier(device=device, N_ensemble_configurations=1)\n",
        "    net.fit(X_train, binary_labels)\n",
        "\n",
        "    p_test_all = np.array([]) # 32 x b'\n",
        "    for x_test in all_X_test: #32\n",
        "        p_test = net.predict_proba(x_test)[:, 1]\n",
        "        p_test_all = np.concatenate((p_test_all, p_test), axis=None)\n",
        "    \n",
        "    # with open(f'{prefix}/net_{mode}_{noise_level}_{str(time.time())}.pkl', 'wb') as f:\n",
        "    #     pkl.dump(net, f)\n",
        "\n",
        "    del net\n",
        "    K.clear_session()\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "    return p_test_all\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "def predict(classifiers, X_test):\n",
        "    predictions = np.zeros((len(classifiers.keys()), X_test.shape[0]))\n",
        "    for class_label, classifier in classifiers.items():\n",
        "        p_test = classifier.predict_proba(X_test)[:, 1]\n",
        "        predictions[class_label, :] = np.array(p_test)\n",
        "    y_preds = np.argmax(predictions, axis=0)\n",
        "    return y_preds\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "def make_data_splits(df, mode):\n",
        "\n",
        "    def encode(v, class_values):\n",
        "        return class_values.index(v)\n",
        "    \n",
        "    df = deepcopy(df)\n",
        "\n",
        "    class_values = df[mode].unique().tolist()\n",
        "    df[mode] = df[mode].apply(lambda x: encode(x, class_values))\n",
        "    df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "    X = df.iloc[:, :26]\n",
        "    y = df[mode]\n",
        "\n",
        "    # X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "    return X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(7800, 29)\n",
            "Noise Level: none Mode: era\n",
            "1/7 2/7 3/7 4/7 5/7 6/7 7/7 \n",
            "Accuracy: 0.9039077514413837\n",
            "Noise Level: none Mode: target_5_val\n",
            "1/7 2/7 3/7 4/7 5/7 6/7 7/7 \n",
            "Accuracy: 0.9282511210762332\n",
            "Noise Level: none Mode: target_10_val\n",
            "1/7 2/7 3/7 4/7 5/7 6/7 7/7 \n",
            "Accuracy: 0.9276105060858424\n",
            "(312000, 30)\n",
            "Noise Level: low Mode: era\n",
            "1/250 2/250 3/250 4/250 5/250 6/250 7/250 8/250 9/250 10/250 11/250 12/250 13/250 14/250 15/250 16/250 17/250 18/250 19/250 20/250 21/250 22/250 23/250 24/250 25/250 26/250 27/250 28/250 29/250 30/250 31/250 32/250 33/250 34/250 35/250 36/250 37/250 38/250 39/250 40/250 41/250 42/250 43/250 44/250 45/250 46/250 47/250 48/250 49/250 50/250 51/250 52/250 53/250 54/250 55/250 56/250 57/250 58/250 59/250 60/250 61/250 62/250 63/250 64/250 65/250 66/250 67/250 68/250 69/250 70/250 71/250 72/250 73/250 74/250 75/250 76/250 77/250 78/250 79/250 80/250 81/250 82/250 83/250 84/250 85/250 86/250 87/250 88/250 89/250 90/250 91/250 92/250 93/250 94/250 95/250 96/250 97/250 98/250 99/250 100/250 101/250 102/250 103/250 104/250 105/250 106/250 107/250 108/250 109/250 110/250 111/250 112/250 113/250 114/250 115/250 116/250 117/250 118/250 119/250 120/250 121/250 122/250 "
          ]
        }
      ],
      "source": [
        "# device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
        "df_paths = ['../Datasets/df_syn_train_0_0_.csv',\n",
        "            '../Datasets/df_synA_train_shuffled.csv',\n",
        "            '../Datasets/df_synA_test_hard_shuffled_sample.csv']\n",
        "\n",
        "noise_levels = ['none', 'low', 'high']\n",
        "\n",
        "\n",
        "for i in range(1, 3):\n",
        "    df = pd.read_csv(df_paths[i])\n",
        "    print(df.shape)\n",
        "\n",
        "    \n",
        "    size_limit = 1_250\n",
        "    n_splits = (df.shape[0] // size_limit) + 1\n",
        "\n",
        "    modes = ['era', 'target_5_val', 'target_10_val']\n",
        "\n",
        "    for mode in modes:\n",
        "        print(\"Noise Level:\", noise_levels[i], \"Mode:\", mode)\n",
        "\n",
        "        all_classes = len(df[mode].unique())\n",
        "\n",
        "        net_classifiers = []\n",
        "\n",
        "        all_X_train = []\n",
        "        all_y_train = []\n",
        "        all_X_test = []\n",
        "        all_y_test = []\n",
        "\n",
        "        skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "        \n",
        "        # jump = 0\n",
        "        # for batch in range(0, df.shape[0], size_limit):\n",
        "        #     jump += 1\n",
        "        #     data = df[batch: batch + size_limit]\n",
        "        #     X_train, X_test, y_train, y_test = make_data_splits(data, mode)\n",
        "        #     all_classes = set.union(all_classes, set(y_train.unique()))\n",
        "\n",
        "        X, y = make_data_splits(df, mode)\n",
        "        for _, cur_samples_index in skf.split(X, y):\n",
        "            \n",
        "            X_cur = np.array(X.iloc[cur_samples_index])\n",
        "            y_cur = np.array(y.iloc[cur_samples_index])\n",
        "\n",
        "            X_train, X_test, y_train, y_test = train_test_split(X_cur, y_cur, test_size=0.2, random_state=42, stratify=y_cur)\n",
        "\n",
        "            all_X_test.append(X_test)\n",
        "            all_y_test.append(y_test)\n",
        "            all_X_train.append(X_train)\n",
        "            all_y_train.append(y_train)\n",
        "        \n",
        "        test_correct = 0\n",
        "        test_samples = 0\n",
        "        \n",
        "        all_y_preds = [] #32 x 80,000\n",
        "\n",
        "        count = 1\n",
        "        for train_x, train_y in zip(all_X_train, all_y_train): #32\n",
        "            print(f'{count}/{n_splits}', end = \" \")\n",
        "            count += 1\n",
        "            y_bin_preds = [] #12 x 80,000\n",
        "            for class_label in range(all_classes): #12\n",
        "                y_bin_pred = Train_Test(train_x, train_y, all_X_test, class_label, mode, noise_levels[i]) #32 x b'\n",
        "                y_bin_preds.append(y_bin_pred) #train on one class, train on some data, test on all samples\n",
        "            y_bin_preds = np.array(y_bin_preds)\n",
        "            y_preds = np.argmax(y_bin_preds, axis=0) # 80,000\n",
        "            all_y_preds.append(y_preds)\n",
        "        print()\n",
        "        \n",
        "        majority_y_preds = []\n",
        "    \n",
        "        for sample in range(all_y_preds[0].shape[0]):\n",
        "            voting_array = [0] * all_classes\n",
        "            for batch in range(len(all_y_preds)):\n",
        "                voting_array[all_y_preds[batch][sample]] += 1\n",
        "            max_val = -1\n",
        "            max_ind = -1\n",
        "            for ind in range(len(voting_array)):\n",
        "                if voting_array[ind] > max_val:\n",
        "                    max_val = voting_array[ind]\n",
        "                    max_ind = ind\n",
        "            majority_y_preds.append(max_ind)\n",
        "        \n",
        "        majority_y_preds = np.array(majority_y_preds)\n",
        "        print(\"Accuracy:\", accuracy(majority_y_preds, np.array(all_y_test).reshape((-1,)))[0])\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
