{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_o82TjduV4L",
        "outputId": "f754f5bc-8a03-44b7-db36-4a0aa52ad1f9"
      },
      "outputs": [],
      "source": [
        "# !gdown https://drive.google.com/file/d/1Hv4RAltBumSfOkRacoX8qrfDYfd_NDss/view?usp=drive_link --fuzzy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UD9ZDc-TvXuQ",
        "outputId": "bd6856a8-62d4-442f-adda-0f87f8b8e47d"
      },
      "outputs": [],
      "source": [
        "# !unzip Dataset_AML_Assignment1_Part1.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMiPtCSFLfGA",
        "outputId": "5677688c-94a4-422c-bb36-da7e1a8da60d"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "HwsdAOp9wdrt"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import torch.nn.functional as F\n",
        "from IPython import display\n",
        "from tqdm.notebook import tqdm\n",
        "import random\n",
        "import math, time, os\n",
        "from matplotlib import pyplot as plt\n",
        "import pickle as pkl\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "prefix = './data_dump_nal'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Q5NZw6c2zf81"
      },
      "outputs": [],
      "source": [
        "class SinusodialDataset(Dataset):\n",
        "    def __init__(self, df, mode='era'):\n",
        "        \"\"\" creating label columns of eras and targets \"\"\"\n",
        "        self.X = df.iloc[:, :24]\n",
        "        if mode == 'era':\n",
        "          self.y = df['era_label']\n",
        "        else:\n",
        "          self.y = df[f'{mode}']\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.X.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        X = torch.tensor(self.X.iloc[idx].values, dtype=torch.float32)\n",
        "        y = torch.tensor(int(self.y.iloc[idx]), dtype=torch.long)\n",
        "        return X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "RnMHIA5F2jBV"
      },
      "outputs": [],
      "source": [
        "def make_data_splits(df, mode, batch_size=32, train_perc=0.7, val_test_perc=0.5):\n",
        "\n",
        "    def encode(v, class_values):\n",
        "        return class_values.index(v)\n",
        "\n",
        "    #adding new era_label column indexed 0, 1,...\n",
        "    class_values = df['era'].unique().tolist()\n",
        "    df['era_label'] = df['era'].apply(lambda x: encode(x, class_values))\n",
        "    df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "    train_samples = int(len(df)*train_perc)\n",
        "    val_test_samples = len(df)-train_samples\n",
        "\n",
        "    data = SinusodialDataset(df, mode=mode)\n",
        "    data_train, data_test = random_split(data, [train_samples, val_test_samples])\n",
        "\n",
        "    val_samples = int(len(data_test)*val_test_perc)\n",
        "    test_samples = len(data_test)-val_samples\n",
        "    data_val, data_test = random_split(data_test, [val_samples, test_samples])\n",
        "\n",
        "    print(\"Train-val-test lengths: \", len(data_train), len(data_val), len(data_test))\n",
        "\n",
        "    loader_train = DataLoader(data_train, batch_size=batch_size, shuffle=True)\n",
        "    loader_val = DataLoader(data_val, batch_size=batch_size, shuffle=False)\n",
        "    loader_test = DataLoader(data_test, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    return loader_train, loader_val, loader_test, data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJWMzGJ6QYS4"
      },
      "source": [
        "#NAL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "pIev8M38FwkD"
      },
      "outputs": [],
      "source": [
        "class NAL_MLP(nn.Module):\n",
        "    def __init__(self, dims, lr=1e-2, weight_decay=1e-3):\n",
        "        super(NAL_MLP,self).__init__()\n",
        "        self.dims=dims\n",
        "        self.layers=nn.ModuleList()\n",
        "        for i in range(len(self.dims)-2):\n",
        "            self.layers.append(nn.Linear(dims[i],dims[i+1]))\n",
        "            self.layers.append(nn.ReLU())\n",
        "\n",
        "        self.output_layer = nn.Linear(dims[i+1],dims[i+2])\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "        self.nal_head = nn.Linear(dims[i+1], 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "        self.optimizer = optim.SGD(self.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = x.float()\n",
        "        for l in self.layers:\n",
        "            x = l(x)\n",
        "        output = self.softmax(self.output_layer(x))\n",
        "        attn = self.sigmoid(self.nal_head(x))\n",
        "        return output, attn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "TI_5uJrIL5di"
      },
      "outputs": [],
      "source": [
        "def accuracy(y_pred, y_test, verbose=True):\n",
        "    m = y_test.shape[0]\n",
        "    predicted = torch.max(y_pred, 1)[1]\n",
        "    correct = (predicted == y_test).float().sum().item()\n",
        "    if verbose:\n",
        "        print(correct,m)\n",
        "    accuracy = correct/m\n",
        "    return accuracy, correct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {},
      "outputs": [],
      "source": [
        "def NAL_Loss(preds, attn, targets, lamb1=1, lamb2=1):\n",
        "    #reduction sum\n",
        "    # loss_a = -torch.sum( torch.log( preds[range(len(targets)), targets] ) )\n",
        "    loss_a = -torch.sum(torch.log( torch.mul(attn, (preds[range(len(targets)), targets]-1)) + 1 ))\n",
        "    loss_b = -torch.sum(torch.log(attn))\n",
        "    return (lamb1*loss_a, lamb2*loss_b)\n",
        "    # return loss_a\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "ioBeC96SEKnx"
      },
      "outputs": [],
      "source": [
        "def Test(net, loader_test, mode, noise_level, device='cpu', Loss=NAL_Loss):\n",
        "    net.eval()\n",
        "    total_samples = 0\n",
        "    correct_samples = 0\n",
        "    loss = 0.0\n",
        "    for (X, y) in loader_test:\n",
        "        X=X.to(device)\n",
        "        y=y.to(device)\n",
        "        total_samples += y.shape[0]\n",
        "        y_out, _ = net(X)\n",
        "        _, i_cor_sam = accuracy(y_out,y,verbose=False)\n",
        "        correct_samples += i_cor_sam\n",
        "        y_out, y_attn = net(X)\n",
        "        # loss += Loss(y_out, y).cpu().detach().item()\n",
        "        loss_a, loss_b = Loss(y_out, y_attn, y)\n",
        "        loss_a, loss_b = loss_a.cpu().detach().item(), loss_b.cpu().detach().item()\n",
        "        loss += (loss_a+loss_b)\n",
        "    acc = correct_samples / total_samples\n",
        "    loss /= total_samples\n",
        "    net.train()\n",
        "    return loss, acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "id": "0npX0g97CS4B"
      },
      "outputs": [],
      "source": [
        "def Train(Net, data, mode, noise_level, epochs=20, lr=5e-2, Loss=NAL_Loss, verbose=False, device='cpu',\n",
        "          val_ds=None, plot_accs=False, plot_losses=False):\n",
        "    model_save_time = time.time()\n",
        "    losses = []\n",
        "    accs = []\n",
        "    val_losses=[]\n",
        "    val_accL=[]\n",
        "    Net.to(device)\n",
        "    for e in range(epochs):\n",
        "        Net.train()\n",
        "        step=0\n",
        "        tot_loss, tot_loss_a, tot_loss_b = 0.0, 0.0, 0.0\n",
        "        start_time = time.time()\n",
        "        correct_samples = 0\n",
        "        total_samples = 0\n",
        "        range_attn = [-100, 100] # max, min\n",
        "        for (X,y) in data:\n",
        "            X=X.to(device)\n",
        "            y=y.to(device)\n",
        "            total_samples += y.shape[0]\n",
        "            y_out, y_attn = Net(X)\n",
        "\n",
        "            if y_attn.min() < range_attn[1]:\n",
        "                range_attn[1] = y_attn.min().item()\n",
        "            if y_attn.max() > range_attn[0]:\n",
        "                range_attn[0] = y_attn.max().item()\n",
        "\n",
        "            loss_a, loss_b = Loss(y_out, y_attn, y)\n",
        "            # loss = Loss(y_out, y)\n",
        "            Net.optimizer.zero_grad()\n",
        "            loss = loss_a+loss_b\n",
        "            loss.backward()\n",
        "            Net.optimizer.step()\n",
        "            step+=1\n",
        "            tot_loss_a+=loss_a\n",
        "            tot_loss_b+=loss_b\n",
        "            tot_loss+=loss\n",
        "            if verbose:\n",
        "                _, i_cor_sam = accuracy(y_out,y,verbose=False)\n",
        "                correct_samples += i_cor_sam\n",
        "        end_time = time.time()\n",
        "        print(\"RANGE_ATTN:\",range_attn)\n",
        "        print(\"LOSS RATIO:\",tot_loss_a.item(), tot_loss_b.item())\n",
        "        t = end_time-start_time\n",
        "        l = tot_loss.item()/total_samples\n",
        "        losses += [l]\n",
        "        if verbose:\n",
        "            a = correct_samples/total_samples\n",
        "            accs += [a]\n",
        "            print('Epoch %2d Loss: %2.5e Accuracy: %2.5f Epoch Time: %2.5f' %(e,l,a,t))\n",
        "\n",
        "        val_loss, val_acc = Test(Net, val_ds, mode, noise_level, device)\n",
        "        val_losses.append(val_loss)\n",
        "        val_accL.append(val_acc)\n",
        "\n",
        "        torch.save(Net.state_dict(), f'{prefix}/net_{noise_level}_{mode}_{str(model_save_time)}.pth')\n",
        "\n",
        "    return Net, losses, accs, val_losses, val_accL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "id": "qkoa2_muJIwq"
      },
      "outputs": [],
      "source": [
        "def plot_loss_acc(losses, accs, val_losses, val_accs, mode, noise_level):\n",
        "\n",
        "    plt.plot(np.array(accs),color='red', label='Train accuracy')\n",
        "    plt.plot(np.array(val_accs),color='blue', label='Val accuracy')\n",
        "    plt.legend()\n",
        "    plt.savefig(f'{prefix}/acc_{mode}_{noise_level}.png')\n",
        "    plt.clf()\n",
        "\n",
        "    plt.plot(np.array(losses),color='red', label='Train loss')\n",
        "    plt.plot(np.array(val_losses),color='blue', label='Val loss')\n",
        "    plt.legend()\n",
        "    plt.savefig(f'{prefix}/loss_{mode}_{noise_level}.png')\n",
        "    plt.clf()\n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "id": "hh6eKpraxMP-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Noise Level: none Mode: era\n",
            "Train-val-test lengths:  5460 1170 1170\n",
            "RANGE_ATTN: [0.5210817456245422, 0.09757984429597855]\n",
            "LOSS RATIO: 5271.3857421875 11455.3125\n",
            "Epoch  0 Loss: 3.06350e+00 Accuracy: 0.08828 Epoch Time: 2.25864\n",
            "RANGE_ATTN: [0.13153067231178284, 0.11542418599128723]\n",
            "LOSS RATIO: 5146.43505859375 11516.498046875\n",
            "Epoch  1 Loss: 3.05182e+00 Accuracy: 0.09048 Epoch Time: 2.16335\n",
            "RANGE_ATTN: [0.13165442645549774, 0.11673764884471893]\n",
            "LOSS RATIO: 5145.76513671875 11515.0048828125\n",
            "Epoch  2 Loss: 3.05143e+00 Accuracy: 0.09048 Epoch Time: 2.13929\n",
            "RANGE_ATTN: [0.13237862288951874, 0.11672475188970566]\n",
            "LOSS RATIO: 5145.12548828125 11511.90625\n",
            "Epoch  3 Loss: 3.05074e+00 Accuracy: 0.12106 Epoch Time: 2.17624\n",
            "RANGE_ATTN: [0.13202029466629028, 0.11572710424661636]\n",
            "LOSS RATIO: 5142.50048828125 11501.6181640625\n",
            "Epoch  4 Loss: 3.04837e+00 Accuracy: 0.09982 Epoch Time: 2.18165\n",
            "RANGE_ATTN: [0.1662692278623581, 0.10948130488395691]\n",
            "LOSS RATIO: 5129.44140625 11344.294921875\n",
            "Epoch  5 Loss: 3.01717e+00 Accuracy: 0.12619 Epoch Time: 2.19282\n",
            "RANGE_ATTN: [0.21454736590385437, 0.10936090350151062]\n",
            "LOSS RATIO: 5115.470703125 10957.5791015625\n",
            "Epoch  6 Loss: 2.94378e+00 Accuracy: 0.16795 Epoch Time: 2.11856\n",
            "RANGE_ATTN: [0.28876689076423645, 0.07599592208862305]\n",
            "LOSS RATIO: 5103.94189453125 10723.509765625\n",
            "Epoch  7 Loss: 2.89880e+00 Accuracy: 0.23571 Epoch Time: 2.27001\n",
            "RANGE_ATTN: [0.29388701915740967, 0.0780709758400917]\n",
            "LOSS RATIO: 5094.84912109375 10569.0234375\n",
            "Epoch  8 Loss: 2.86884e+00 Accuracy: 0.26923 Epoch Time: 2.20501\n",
            "RANGE_ATTN: [0.3162096440792084, 0.07254919409751892]\n",
            "LOSS RATIO: 5065.43017578125 10170.244140625\n",
            "Epoch  9 Loss: 2.79042e+00 Accuracy: 0.32857 Epoch Time: 2.26542\n",
            "RANGE_ATTN: [0.46215954422950745, 0.044468674808740616]\n",
            "LOSS RATIO: 5048.7958984375 9786.2099609375\n",
            "Epoch 10 Loss: 2.71703e+00 Accuracy: 0.41300 Epoch Time: 2.25405\n",
            "RANGE_ATTN: [0.49449044466018677, 0.04999963939189911]\n",
            "LOSS RATIO: 5001.21875 9322.3662109375\n",
            "Epoch 11 Loss: 2.62337e+00 Accuracy: 0.47143 Epoch Time: 2.21902\n",
            "RANGE_ATTN: [0.6924809813499451, 0.00654978072270751]\n",
            "LOSS RATIO: 4960.763671875 8983.796875\n",
            "Epoch 12 Loss: 2.55395e+00 Accuracy: 0.51868 Epoch Time: 2.18061\n",
            "RANGE_ATTN: [0.5865952968597412, 0.04779408499598503]\n",
            "LOSS RATIO: 4927.8740234375 8719.2470703125\n",
            "Epoch 13 Loss: 2.49947e+00 Accuracy: 0.53516 Epoch Time: 2.25119\n",
            "RANGE_ATTN: [0.6734256148338318, 0.015489863231778145]\n",
            "LOSS RATIO: 4897.71533203125 8616.716796875\n",
            "Epoch 14 Loss: 2.47517e+00 Accuracy: 0.54451 Epoch Time: 2.21444\n",
            "RANGE_ATTN: [0.5588065385818481, 0.06913796812295914]\n",
            "LOSS RATIO: 4897.3505859375 8501.6416015625\n",
            "Epoch 15 Loss: 2.45403e+00 Accuracy: 0.54817 Epoch Time: 2.23425\n",
            "RANGE_ATTN: [0.6108793616294861, 0.05466216057538986]\n",
            "LOSS RATIO: 4873.98291015625 8281.091796875\n",
            "Epoch 16 Loss: 2.40935e+00 Accuracy: 0.57637 Epoch Time: 2.22990\n",
            "RANGE_ATTN: [0.6754303574562073, 0.03822295740246773]\n",
            "LOSS RATIO: 4821.7275390625 7892.1357421875\n",
            "Epoch 17 Loss: 2.32855e+00 Accuracy: 0.61685 Epoch Time: 2.18128\n",
            "RANGE_ATTN: [0.5587120056152344, 0.0568842887878418]\n",
            "LOSS RATIO: 4822.162109375 7719.43408203125\n",
            "Epoch 18 Loss: 2.29700e+00 Accuracy: 0.62582 Epoch Time: 2.27117\n",
            "RANGE_ATTN: [0.649546205997467, 0.028635965660214424]\n",
            "LOSS RATIO: 4797.3837890625 7534.783203125\n",
            "Epoch 19 Loss: 2.25864e+00 Accuracy: 0.64982 Epoch Time: 2.15006\n",
            "RANGE_ATTN: [0.6110518574714661, 0.046245042234659195]\n",
            "LOSS RATIO: 4788.7978515625 7516.04638671875\n",
            "Epoch 20 Loss: 2.25363e+00 Accuracy: 0.64487 Epoch Time: 2.17067\n",
            "RANGE_ATTN: [0.6463044881820679, 0.02604294940829277]\n",
            "LOSS RATIO: 4751.36572265625 7326.59326171875\n",
            "Epoch 21 Loss: 2.21208e+00 Accuracy: 0.66136 Epoch Time: 2.26858\n",
            "RANGE_ATTN: [0.6922890543937683, 0.04197803512215614]\n",
            "LOSS RATIO: 4733.09423828125 7186.57470703125\n",
            "Epoch 22 Loss: 2.18309e+00 Accuracy: 0.67271 Epoch Time: 2.16000\n",
            "RANGE_ATTN: [0.5522772669792175, 0.06062838435173035]\n",
            "LOSS RATIO: 4700.39111328125 7084.43115234375\n",
            "Epoch 23 Loss: 2.15839e+00 Accuracy: 0.68040 Epoch Time: 2.18398\n",
            "RANGE_ATTN: [0.7123751640319824, 0.049376990646123886]\n",
            "LOSS RATIO: 4692.76416015625 7055.42138671875\n",
            "Epoch 24 Loss: 2.15168e+00 Accuracy: 0.68168 Epoch Time: 2.36767\n",
            "RANGE_ATTN: [0.7294089794158936, 0.11919184774160385]\n",
            "LOSS RATIO: 4690.1025390625 7037.87060546875\n",
            "Epoch 25 Loss: 2.14798e+00 Accuracy: 0.68168 Epoch Time: 2.16573\n",
            "RANGE_ATTN: [0.6486061811447144, 0.07871129363775253]\n",
            "LOSS RATIO: 4691.427734375 6993.3359375\n",
            "Epoch 26 Loss: 2.14006e+00 Accuracy: 0.68480 Epoch Time: 2.18303\n",
            "RANGE_ATTN: [0.5818609595298767, 0.06586983054876328]\n",
            "LOSS RATIO: 4651.86474609375 6887.94140625\n",
            "Epoch 27 Loss: 2.11352e+00 Accuracy: 0.69231 Epoch Time: 2.29360\n",
            "RANGE_ATTN: [0.6173366904258728, 0.09233683347702026]\n",
            "LOSS RATIO: 4654.9560546875 6813.61083984375\n",
            "Epoch 28 Loss: 2.10047e+00 Accuracy: 0.69780 Epoch Time: 2.26710\n",
            "RANGE_ATTN: [0.7812346816062927, 0.05266427621245384]\n",
            "LOSS RATIO: 4672.9892578125 6690.24853515625\n",
            "Epoch 29 Loss: 2.08118e+00 Accuracy: 0.70769 Epoch Time: 2.19420\n",
            "RANGE_ATTN: [0.6911879181861877, 0.04629527032375336]\n",
            "LOSS RATIO: 4676.6083984375 6750.150390625\n",
            "Epoch 30 Loss: 2.09281e+00 Accuracy: 0.70403 Epoch Time: 2.30516\n",
            "RANGE_ATTN: [0.7086706161499023, 0.016382889822125435]\n",
            "LOSS RATIO: 4657.69384765625 6619.74853515625\n",
            "Epoch 31 Loss: 2.06546e+00 Accuracy: 0.71429 Epoch Time: 2.26829\n",
            "RANGE_ATTN: [0.8018355369567871, 0.048553287982940674]\n",
            "LOSS RATIO: 4614.6689453125 6459.7294921875\n",
            "Epoch 32 Loss: 2.02828e+00 Accuracy: 0.72399 Epoch Time: 2.22054\n",
            "RANGE_ATTN: [0.7075091004371643, 0.03349101543426514]\n",
            "LOSS RATIO: 4666.357421875 6707.216796875\n",
            "Epoch 33 Loss: 2.08307e+00 Accuracy: 0.70916 Epoch Time: 2.23562\n",
            "RANGE_ATTN: [0.667300283908844, 0.037037551403045654]\n",
            "LOSS RATIO: 4618.4970703125 6557.24365234375\n",
            "Epoch 34 Loss: 2.04684e+00 Accuracy: 0.71740 Epoch Time: 2.21185\n",
            "RANGE_ATTN: [0.6623860597610474, 0.012917239218950272]\n",
            "LOSS RATIO: 4640.037109375 6602.59765625\n",
            "Epoch 35 Loss: 2.05909e+00 Accuracy: 0.71300 Epoch Time: 2.30684\n",
            "RANGE_ATTN: [0.7600575685501099, 0.027354786172509193]\n",
            "LOSS RATIO: 4588.26025390625 6406.24365234375\n",
            "Epoch 36 Loss: 2.01365e+00 Accuracy: 0.72802 Epoch Time: 2.23978\n",
            "RANGE_ATTN: [0.6844098567962646, 0.0536031499505043]\n",
            "LOSS RATIO: 4583.80810546875 6384.5\n",
            "Epoch 37 Loss: 2.00885e+00 Accuracy: 0.72821 Epoch Time: 2.20568\n",
            "RANGE_ATTN: [0.7703512907028198, 0.06788347661495209]\n",
            "LOSS RATIO: 4578.0546875 6371.73046875\n",
            "Epoch 38 Loss: 2.00546e+00 Accuracy: 0.73004 Epoch Time: 2.27778\n",
            "RANGE_ATTN: [0.7139734029769897, 0.06570162624120712]\n",
            "LOSS RATIO: 4610.95703125 6500.57568359375\n",
            "Epoch 39 Loss: 2.03508e+00 Accuracy: 0.71868 Epoch Time: 2.27932\n",
            "RANGE_ATTN: [0.7703887224197388, 0.014514877460896969]\n",
            "LOSS RATIO: 4574.62890625 6282.10595703125\n",
            "Epoch 40 Loss: 1.98841e+00 Accuracy: 0.73498 Epoch Time: 2.25686\n",
            "RANGE_ATTN: [0.7941710948944092, 0.04023613780736923]\n",
            "LOSS RATIO: 4555.35009765625 6291.71826171875\n",
            "Epoch 41 Loss: 1.98664e+00 Accuracy: 0.73791 Epoch Time: 2.33054\n",
            "RANGE_ATTN: [0.743968665599823, 0.07271222025156021]\n",
            "LOSS RATIO: 4553.439453125 6174.22802734375\n",
            "Epoch 42 Loss: 1.96477e+00 Accuracy: 0.74304 Epoch Time: 2.33801\n",
            "RANGE_ATTN: [0.8061646223068237, 0.06869921833276749]\n",
            "LOSS RATIO: 4585.517578125 6388.91748046875\n",
            "Epoch 43 Loss: 2.00997e+00 Accuracy: 0.72711 Epoch Time: 2.21835\n",
            "RANGE_ATTN: [0.791201651096344, 0.0008565761963836849]\n",
            "LOSS RATIO: 4578.0498046875 6154.0263671875\n",
            "Epoch 44 Loss: 1.96558e+00 Accuracy: 0.74487 Epoch Time: 2.16539\n",
            "RANGE_ATTN: [0.8398857116699219, 0.021829135715961456]\n",
            "LOSS RATIO: 4537.00244140625 5995.68505859375\n",
            "Epoch 45 Loss: 1.92906e+00 Accuracy: 0.75513 Epoch Time: 2.34215\n",
            "RANGE_ATTN: [0.949205756187439, 0.015046303160488605]\n",
            "LOSS RATIO: 4564.65380859375 6079.67919921875\n",
            "Epoch 46 Loss: 1.94951e+00 Accuracy: 0.75165 Epoch Time: 2.29031\n",
            "RANGE_ATTN: [0.7864506840705872, 0.008065744303166866]\n",
            "LOSS RATIO: 4554.083984375 5981.2607421875\n",
            "Epoch 47 Loss: 1.92955e+00 Accuracy: 0.75440 Epoch Time: 2.18127\n",
            "RANGE_ATTN: [0.89863121509552, 0.013148405589163303]\n",
            "LOSS RATIO: 4524.9775390625 5983.16259765625\n",
            "Epoch 48 Loss: 1.92457e+00 Accuracy: 0.75696 Epoch Time: 2.34462\n",
            "RANGE_ATTN: [0.8733384609222412, 0.022706320509314537]\n",
            "LOSS RATIO: 4513.78076171875 5939.5205078125\n",
            "Epoch 49 Loss: 1.91452e+00 Accuracy: 0.75879 Epoch Time: 2.31884\n",
            "1.738701348434253 0.805982905982906\n",
            "Noise Level: none Mode: target_5_val\n",
            "Train-val-test lengths:  5460 1170 1170\n",
            "RANGE_ATTN: [0.8199586272239685, 0.0900467038154602]\n",
            "LOSS RATIO: 4639.25439453125 6069.45361328125\n",
            "Epoch  0 Loss: 1.96130e+00 Accuracy: 0.75311 Epoch Time: 2.24809\n",
            "RANGE_ATTN: [0.9231104254722595, 0.028863748535513878]\n",
            "LOSS RATIO: 4199.56005859375 4442.62451171875\n",
            "Epoch  1 Loss: 1.58282e+00 Accuracy: 0.84560 Epoch Time: 2.31135\n",
            "RANGE_ATTN: [0.8867217898368835, 0.14466215670108795]\n",
            "LOSS RATIO: 4015.27587890625 3930.10986328125\n",
            "Epoch  2 Loss: 1.45520e+00 Accuracy: 0.86612 Epoch Time: 2.26522\n",
            "RANGE_ATTN: [0.932735800743103, 0.21981099247932434]\n",
            "LOSS RATIO: 3915.593505859375 3506.239990234375\n",
            "Epoch  3 Loss: 1.35931e+00 Accuracy: 0.87967 Epoch Time: 2.20876\n",
            "RANGE_ATTN: [0.9227132201194763, 0.1826252043247223]\n",
            "LOSS RATIO: 3752.1064453125 3133.053955078125\n",
            "Epoch  4 Loss: 1.26102e+00 Accuracy: 0.89689 Epoch Time: 2.25536\n",
            "RANGE_ATTN: [0.9114096164703369, 0.17754733562469482]\n",
            "LOSS RATIO: 3661.8466796875 2969.517578125\n",
            "Epoch  5 Loss: 1.21454e+00 Accuracy: 0.90256 Epoch Time: 2.21917\n",
            "RANGE_ATTN: [0.8765502572059631, 0.1320577710866928]\n",
            "LOSS RATIO: 3683.845947265625 3074.72802734375\n",
            "Epoch  6 Loss: 1.23783e+00 Accuracy: 0.90037 Epoch Time: 2.23778\n",
            "RANGE_ATTN: [0.9291778206825256, 0.27861112356185913]\n",
            "LOSS RATIO: 3566.459228515625 2876.70751953125\n",
            "Epoch  7 Loss: 1.18007e+00 Accuracy: 0.90714 Epoch Time: 2.28250\n",
            "RANGE_ATTN: [0.9817761778831482, 0.16638682782649994]\n",
            "LOSS RATIO: 3627.649658203125 2778.6884765625\n",
            "Epoch  8 Loss: 1.17332e+00 Accuracy: 0.90842 Epoch Time: 2.23378\n",
            "RANGE_ATTN: [0.9755979776382446, 0.16581213474273682]\n",
            "LOSS RATIO: 3542.47021484375 2751.62548828125\n",
            "Epoch  9 Loss: 1.15276e+00 Accuracy: 0.91190 Epoch Time: 2.19088\n",
            "RANGE_ATTN: [0.9264002442359924, 0.2967212498188019]\n",
            "LOSS RATIO: 3420.007080078125 2466.891845703125\n",
            "Epoch 10 Loss: 1.07819e+00 Accuracy: 0.92143 Epoch Time: 2.24636\n",
            "RANGE_ATTN: [0.97603839635849, 0.036746151745319366]\n",
            "LOSS RATIO: 3538.40087890625 2591.742919921875\n",
            "Epoch 11 Loss: 1.12274e+00 Accuracy: 0.91703 Epoch Time: 2.23402\n",
            "RANGE_ATTN: [0.9654174447059631, 0.13108278810977936]\n",
            "LOSS RATIO: 3494.912841796875 2624.5654296875\n",
            "Epoch 12 Loss: 1.12078e+00 Accuracy: 0.91868 Epoch Time: 2.18581\n",
            "RANGE_ATTN: [0.9194691181182861, 0.19813615083694458]\n",
            "LOSS RATIO: 3431.321533203125 2362.2958984375\n",
            "Epoch 13 Loss: 1.06110e+00 Accuracy: 0.92363 Epoch Time: 2.21857\n",
            "RANGE_ATTN: [0.9514263272285461, 0.17202794551849365]\n",
            "LOSS RATIO: 3367.64697265625 2416.885986328125\n",
            "Epoch 14 Loss: 1.05944e+00 Accuracy: 0.92509 Epoch Time: 2.25066\n",
            "RANGE_ATTN: [0.994460940361023, 0.1516735851764679]\n",
            "LOSS RATIO: 3398.4599609375 2448.53515625\n",
            "Epoch 15 Loss: 1.07088e+00 Accuracy: 0.92253 Epoch Time: 2.31109\n",
            "RANGE_ATTN: [0.9614373445510864, 0.006380496080964804]\n",
            "LOSS RATIO: 3359.5048828125 2452.409423828125\n",
            "Epoch 16 Loss: 1.06445e+00 Accuracy: 0.92491 Epoch Time: 2.23780\n",
            "RANGE_ATTN: [0.9942224621772766, 0.1564318686723709]\n",
            "LOSS RATIO: 3353.639404296875 2398.340087890625\n",
            "Epoch 17 Loss: 1.05348e+00 Accuracy: 0.92216 Epoch Time: 2.20648\n",
            "RANGE_ATTN: [0.9864653944969177, 0.4304593801498413]\n",
            "LOSS RATIO: 3103.779296875 1935.90234375\n",
            "Epoch 18 Loss: 9.23019e-01 Accuracy: 0.93810 Epoch Time: 2.28510\n",
            "RANGE_ATTN: [0.9219906330108643, 0.20728936791419983]\n",
            "LOSS RATIO: 3230.67138671875 2133.316162109375\n",
            "Epoch 19 Loss: 9.82415e-01 Accuracy: 0.93260 Epoch Time: 2.24875\n",
            "RANGE_ATTN: [0.9600476026535034, 0.06834148615598679]\n",
            "LOSS RATIO: 3144.583984375 2148.791259765625\n",
            "Epoch 20 Loss: 9.69482e-01 Accuracy: 0.93462 Epoch Time: 2.20415\n",
            "RANGE_ATTN: [0.9311495423316956, 0.3693254292011261]\n",
            "LOSS RATIO: 3078.06787109375 1934.9053955078125\n",
            "Epoch 21 Loss: 9.18127e-01 Accuracy: 0.93901 Epoch Time: 2.21420\n",
            "RANGE_ATTN: [0.9934578537940979, 0.013574371114373207]\n",
            "LOSS RATIO: 3091.06640625 1935.911865234375\n",
            "Epoch 22 Loss: 9.20691e-01 Accuracy: 0.93974 Epoch Time: 2.25495\n",
            "RANGE_ATTN: [0.9873381853103638, 4.860958142671734e-06]\n",
            "LOSS RATIO: 3046.038818359375 1676.4285888671875\n",
            "Epoch 23 Loss: 8.64921e-01 Accuracy: 0.94579 Epoch Time: 2.31269\n",
            "RANGE_ATTN: [0.9783808588981628, 0.08458917587995529]\n",
            "LOSS RATIO: 3130.2412109375 1808.9188232421875\n",
            "Epoch 24 Loss: 9.04607e-01 Accuracy: 0.94267 Epoch Time: 2.27157\n",
            "RANGE_ATTN: [0.9859442710876465, 0.040124062448740005]\n",
            "LOSS RATIO: 3115.8798828125 1991.6192626953125\n",
            "Epoch 25 Loss: 9.35440e-01 Accuracy: 0.94084 Epoch Time: 2.28120\n",
            "RANGE_ATTN: [0.9591591358184814, 0.2177926003932953]\n",
            "LOSS RATIO: 2974.996337890625 1773.85400390625\n",
            "Epoch 26 Loss: 8.69753e-01 Accuracy: 0.94505 Epoch Time: 2.30723\n",
            "RANGE_ATTN: [0.9798908233642578, 0.21713735163211823]\n",
            "LOSS RATIO: 3084.16845703125 1722.0518798828125\n",
            "Epoch 27 Loss: 8.80260e-01 Accuracy: 0.94469 Epoch Time: 2.22877\n",
            "RANGE_ATTN: [0.9860532283782959, 0.24530567228794098]\n",
            "LOSS RATIO: 2948.69921875 1724.473876953125\n",
            "Epoch 28 Loss: 8.55892e-01 Accuracy: 0.94634 Epoch Time: 2.30053\n",
            "RANGE_ATTN: [0.9781233668327332, 0.13381832838058472]\n",
            "LOSS RATIO: 2890.89453125 1570.1024169921875\n",
            "Epoch 29 Loss: 8.17032e-01 Accuracy: 0.94890 Epoch Time: 2.35834\n",
            "RANGE_ATTN: [0.9693163633346558, 0.21746118366718292]\n",
            "LOSS RATIO: 2959.510986328125 1584.648193359375\n",
            "Epoch 30 Loss: 8.32264e-01 Accuracy: 0.94817 Epoch Time: 2.22433\n",
            "RANGE_ATTN: [0.9747002720832825, 0.30271831154823303]\n",
            "LOSS RATIO: 2929.034423828125 1593.734130859375\n",
            "Epoch 31 Loss: 8.28346e-01 Accuracy: 0.95018 Epoch Time: 2.22729\n",
            "RANGE_ATTN: [0.9946557283401489, 0.22586241364479065]\n",
            "LOSS RATIO: 2997.052978515625 1593.086669921875\n",
            "Epoch 32 Loss: 8.40685e-01 Accuracy: 0.94744 Epoch Time: 2.27032\n",
            "RANGE_ATTN: [0.9886360168457031, 0.20304825901985168]\n",
            "LOSS RATIO: 2813.3583984375 1354.2559814453125\n",
            "Epoch 33 Loss: 7.63300e-01 Accuracy: 0.95623 Epoch Time: 2.13954\n",
            "RANGE_ATTN: [0.9772616624832153, 0.03931041806936264]\n",
            "LOSS RATIO: 2995.347412109375 1433.0006103515625\n",
            "Epoch 34 Loss: 8.11053e-01 Accuracy: 0.94908 Epoch Time: 2.17536\n",
            "RANGE_ATTN: [0.9730619192123413, 0.131979838013649]\n",
            "LOSS RATIO: 2812.40625 1468.5640869140625\n",
            "Epoch 35 Loss: 7.84060e-01 Accuracy: 0.95385 Epoch Time: 2.31105\n",
            "RANGE_ATTN: [0.9890511631965637, 0.16558720171451569]\n",
            "LOSS RATIO: 2771.5419921875 1357.545654296875\n",
            "Epoch 36 Loss: 7.56243e-01 Accuracy: 0.95549 Epoch Time: 2.26743\n",
            "RANGE_ATTN: [0.9877602458000183, 0.24639122188091278]\n",
            "LOSS RATIO: 2767.968505859375 1336.5458984375\n",
            "Epoch 37 Loss: 7.51743e-01 Accuracy: 0.95604 Epoch Time: 2.21651\n",
            "RANGE_ATTN: [0.9903325438499451, 0.16266337037086487]\n",
            "LOSS RATIO: 3000.545654296875 1393.4345703125\n",
            "Epoch 38 Loss: 8.04758e-01 Accuracy: 0.95018 Epoch Time: 2.33397\n",
            "RANGE_ATTN: [0.9964755177497864, 0.0023911939933896065]\n",
            "LOSS RATIO: 2863.681884765625 1441.717041015625\n",
            "Epoch 39 Loss: 7.88535e-01 Accuracy: 0.95366 Epoch Time: 2.24694\n",
            "RANGE_ATTN: [0.9846222996711731, 0.08579462766647339]\n",
            "LOSS RATIO: 2919.38037109375 1599.601318359375\n",
            "Epoch 40 Loss: 8.27652e-01 Accuracy: 0.95018 Epoch Time: 2.29196\n",
            "RANGE_ATTN: [0.988595187664032, 0.19444675743579865]\n",
            "LOSS RATIO: 2756.736328125 1413.699951171875\n",
            "Epoch 41 Loss: 7.63816e-01 Accuracy: 0.95568 Epoch Time: 2.21698\n",
            "RANGE_ATTN: [0.9934589266777039, 0.2535180449485779]\n",
            "LOSS RATIO: 2687.57568359375 1227.126220703125\n",
            "Epoch 42 Loss: 7.16978e-01 Accuracy: 0.95861 Epoch Time: 2.23059\n",
            "RANGE_ATTN: [0.9948660135269165, 0.12738026678562164]\n",
            "LOSS RATIO: 2855.906005859375 1418.47216796875\n",
            "Epoch 43 Loss: 7.82853e-01 Accuracy: 0.95348 Epoch Time: 2.29003\n",
            "RANGE_ATTN: [0.9826143383979797, 0.05024450644850731]\n",
            "LOSS RATIO: 2788.6142578125 1346.9373779296875\n",
            "Epoch 44 Loss: 7.57427e-01 Accuracy: 0.95696 Epoch Time: 2.23529\n",
            "RANGE_ATTN: [0.9892839789390564, 0.11917773634195328]\n",
            "LOSS RATIO: 2722.653564453125 1362.404296875\n",
            "Epoch 45 Loss: 7.48179e-01 Accuracy: 0.95641 Epoch Time: 2.18178\n",
            "RANGE_ATTN: [0.9940468072891235, 0.045571062713861465]\n",
            "LOSS RATIO: 2751.598388671875 1278.34716796875\n",
            "Epoch 46 Loss: 7.38085e-01 Accuracy: 0.95714 Epoch Time: 2.29607\n",
            "RANGE_ATTN: [0.9784862995147705, 0.09675941616296768]\n",
            "LOSS RATIO: 2795.193603515625 1310.89990234375\n",
            "Epoch 47 Loss: 7.52032e-01 Accuracy: 0.95788 Epoch Time: 2.28827\n",
            "RANGE_ATTN: [0.9900683760643005, 0.07244174927473068]\n",
            "LOSS RATIO: 2885.01904296875 1388.095458984375\n",
            "Epoch 48 Loss: 7.82622e-01 Accuracy: 0.95238 Epoch Time: 2.22559\n",
            "RANGE_ATTN: [0.9914074540138245, 0.039768122136592865]\n",
            "LOSS RATIO: 2694.66162109375 1268.530517578125\n",
            "Epoch 49 Loss: 7.25859e-01 Accuracy: 0.95788 Epoch Time: 2.19924\n",
            "0.7863593850831164 0.9452991452991453\n",
            "Noise Level: none Mode: target_10_val\n",
            "Train-val-test lengths:  5460 1170 1170\n",
            "RANGE_ATTN: [0.7209455370903015, 0.13271085917949677]\n",
            "LOSS RATIO: 4630.68896484375 6210.0751953125\n",
            "Epoch  0 Loss: 1.98549e+00 Accuracy: 0.74982 Epoch Time: 2.17794\n",
            "RANGE_ATTN: [0.9107746481895447, 0.14049023389816284]\n",
            "LOSS RATIO: 4442.93115234375 5762.0546875\n",
            "Epoch  1 Loss: 1.86904e+00 Accuracy: 0.76502 Epoch Time: 2.24369\n",
            "RANGE_ATTN: [0.785832941532135, 0.1814454048871994]\n",
            "LOSS RATIO: 4107.6064453125 4160.3291015625\n",
            "Epoch  2 Loss: 1.51428e+00 Accuracy: 0.85385 Epoch Time: 2.28874\n",
            "RANGE_ATTN: [0.9584784507751465, 0.3087891936302185]\n",
            "LOSS RATIO: 3885.04052734375 3642.442138671875\n",
            "Epoch  3 Loss: 1.37866e+00 Accuracy: 0.87802 Epoch Time: 2.28404\n",
            "RANGE_ATTN: [0.8853123188018799, 0.20721961557865143]\n",
            "LOSS RATIO: 3781.800537109375 3422.06982421875\n",
            "Epoch  4 Loss: 1.31939e+00 Accuracy: 0.88828 Epoch Time: 2.27594\n",
            "RANGE_ATTN: [0.8866417407989502, 0.17254361510276794]\n",
            "LOSS RATIO: 3752.978759765625 3300.255126953125\n",
            "Epoch  5 Loss: 1.29180e+00 Accuracy: 0.89158 Epoch Time: 2.25142\n",
            "RANGE_ATTN: [0.905873715877533, 0.08969102799892426]\n",
            "LOSS RATIO: 3584.349853515625 2851.580078125\n",
            "Epoch  6 Loss: 1.17874e+00 Accuracy: 0.90934 Epoch Time: 2.22650\n",
            "RANGE_ATTN: [0.9091072678565979, 0.19875001907348633]\n",
            "LOSS RATIO: 3542.261474609375 2960.850830078125\n",
            "Epoch  7 Loss: 1.19105e+00 Accuracy: 0.90678 Epoch Time: 2.24856\n",
            "RANGE_ATTN: [0.9075402617454529, 0.04169517755508423]\n",
            "LOSS RATIO: 3383.460205078125 2696.128662109375\n",
            "Epoch  8 Loss: 1.11348e+00 Accuracy: 0.91850 Epoch Time: 2.19215\n",
            "RANGE_ATTN: [0.9154385924339294, 0.19711516797542572]\n",
            "LOSS RATIO: 3389.512451171875 2571.51123046875\n",
            "Epoch  9 Loss: 1.09176e+00 Accuracy: 0.92033 Epoch Time: 2.19321\n",
            "RANGE_ATTN: [0.896034836769104, 0.18259663879871368]\n",
            "LOSS RATIO: 3347.439453125 2545.69384765625\n",
            "Epoch 10 Loss: 1.07933e+00 Accuracy: 0.92234 Epoch Time: 2.27898\n",
            "RANGE_ATTN: [0.9436889886856079, 0.20381079614162445]\n",
            "LOSS RATIO: 3132.48291015625 2281.436767578125\n",
            "Epoch 11 Loss: 9.91560e-01 Accuracy: 0.93425 Epoch Time: 2.17405\n",
            "RANGE_ATTN: [0.91822749376297, 0.14811906218528748]\n",
            "LOSS RATIO: 3300.54931640625 2445.720947265625\n",
            "Epoch 12 Loss: 1.05243e+00 Accuracy: 0.92582 Epoch Time: 2.27601\n",
            "RANGE_ATTN: [0.9540107846260071, 0.17984995245933533]\n",
            "LOSS RATIO: 3254.58056640625 2394.635009765625\n",
            "Epoch 13 Loss: 1.03465e+00 Accuracy: 0.92839 Epoch Time: 2.30155\n",
            "RANGE_ATTN: [0.9413848519325256, 0.07396598905324936]\n",
            "LOSS RATIO: 3205.18408203125 2333.753662109375\n",
            "Epoch 14 Loss: 1.01446e+00 Accuracy: 0.93095 Epoch Time: 2.27737\n",
            "RANGE_ATTN: [0.9609269499778748, 0.08915108442306519]\n",
            "LOSS RATIO: 3235.4658203125 2339.435302734375\n",
            "Epoch 15 Loss: 1.02104e+00 Accuracy: 0.92894 Epoch Time: 2.24664\n",
            "RANGE_ATTN: [0.9573814868927002, 0.24709397554397583]\n",
            "LOSS RATIO: 3223.6689453125 2344.17236328125\n",
            "Epoch 16 Loss: 1.01975e+00 Accuracy: 0.93040 Epoch Time: 2.26938\n",
            "RANGE_ATTN: [0.9804979562759399, 0.024130044505000114]\n",
            "LOSS RATIO: 3267.1474609375 2356.3525390625\n",
            "Epoch 17 Loss: 1.02995e+00 Accuracy: 0.92857 Epoch Time: 2.21432\n",
            "RANGE_ATTN: [0.9681714177131653, 0.0967937633395195]\n",
            "LOSS RATIO: 3181.03369140625 2206.6474609375\n",
            "Epoch 18 Loss: 9.86755e-01 Accuracy: 0.93516 Epoch Time: 2.22585\n",
            "RANGE_ATTN: [0.9632560610771179, 0.19064664840698242]\n",
            "LOSS RATIO: 3159.5146484375 2125.2802734375\n",
            "Epoch 19 Loss: 9.67911e-01 Accuracy: 0.93590 Epoch Time: 2.16150\n",
            "RANGE_ATTN: [0.9680851697921753, 0.1863318383693695]\n",
            "LOSS RATIO: 3075.647705078125 2027.876953125\n",
            "Epoch 20 Loss: 9.34712e-01 Accuracy: 0.94139 Epoch Time: 2.27443\n",
            "RANGE_ATTN: [0.9843664169311523, 0.07687876373529434]\n",
            "LOSS RATIO: 3105.248779296875 2101.981201171875\n",
            "Epoch 21 Loss: 9.53706e-01 Accuracy: 0.93828 Epoch Time: 2.24683\n",
            "RANGE_ATTN: [0.9929108023643494, 0.12847349047660828]\n",
            "LOSS RATIO: 3231.666748046875 2240.22900390625\n",
            "Epoch 22 Loss: 1.00218e+00 Accuracy: 0.93260 Epoch Time: 2.15841\n",
            "RANGE_ATTN: [0.9975908994674683, 0.061402324587106705]\n",
            "LOSS RATIO: 3106.72314453125 2093.400146484375\n",
            "Epoch 23 Loss: 9.52404e-01 Accuracy: 0.93535 Epoch Time: 2.26340\n",
            "RANGE_ATTN: [0.9773198366165161, 0.1442583054304123]\n",
            "LOSS RATIO: 3103.759765625 2091.84423828125\n",
            "Epoch 24 Loss: 9.51576e-01 Accuracy: 0.93864 Epoch Time: 2.22584\n",
            "RANGE_ATTN: [0.9927757978439331, 0.0012034997344017029]\n",
            "LOSS RATIO: 2961.32666015625 1902.0023193359375\n",
            "Epoch 25 Loss: 8.90719e-01 Accuracy: 0.94451 Epoch Time: 2.17655\n",
            "RANGE_ATTN: [0.9846118092536926, 0.10077790170907974]\n",
            "LOSS RATIO: 3115.146240234375 1959.36181640625\n",
            "Epoch 26 Loss: 9.29397e-01 Accuracy: 0.94011 Epoch Time: 2.25015\n",
            "RANGE_ATTN: [0.9695656299591064, 0.0892789363861084]\n",
            "LOSS RATIO: 3056.032958984375 2026.955078125\n",
            "Epoch 27 Loss: 9.30950e-01 Accuracy: 0.94029 Epoch Time: 2.25651\n",
            "RANGE_ATTN: [0.961089015007019, 0.08759211748838425]\n",
            "LOSS RATIO: 3131.387939453125 2116.280029296875\n",
            "Epoch 28 Loss: 9.61111e-01 Accuracy: 0.93681 Epoch Time: 2.27362\n",
            "RANGE_ATTN: [0.9632145166397095, 0.32904210686683655]\n",
            "LOSS RATIO: 3124.01220703125 2060.09375\n",
            "Epoch 29 Loss: 9.49470e-01 Accuracy: 0.93700 Epoch Time: 2.29916\n",
            "RANGE_ATTN: [0.9682038426399231, 0.17307066917419434]\n",
            "LOSS RATIO: 3173.173095703125 2127.942138671875\n",
            "Epoch 30 Loss: 9.70900e-01 Accuracy: 0.93571 Epoch Time: 2.29522\n",
            "RANGE_ATTN: [0.9645154476165771, 0.25470006465911865]\n",
            "LOSS RATIO: 3071.24609375 2068.62890625\n",
            "Epoch 31 Loss: 9.41369e-01 Accuracy: 0.94048 Epoch Time: 2.25057\n",
            "RANGE_ATTN: [0.9360386729240417, 0.17491650581359863]\n",
            "LOSS RATIO: 2948.2138671875 1977.16357421875\n",
            "Epoch 32 Loss: 9.02084e-01 Accuracy: 0.94249 Epoch Time: 2.22784\n",
            "RANGE_ATTN: [0.9418969750404358, 0.18858467042446136]\n",
            "LOSS RATIO: 3039.925048828125 1983.3021240234375\n",
            "Epoch 33 Loss: 9.20005e-01 Accuracy: 0.94066 Epoch Time: 2.25317\n",
            "RANGE_ATTN: [0.9442443251609802, 0.1617472916841507]\n",
            "LOSS RATIO: 2988.805908203125 1960.8353271484375\n",
            "Epoch 34 Loss: 9.06528e-01 Accuracy: 0.94322 Epoch Time: 2.21566\n",
            "RANGE_ATTN: [0.9858337044715881, 0.24338605999946594]\n",
            "LOSS RATIO: 3078.897216796875 1933.7796630859375\n",
            "Epoch 35 Loss: 9.18073e-01 Accuracy: 0.94103 Epoch Time: 2.24826\n",
            "RANGE_ATTN: [0.9865620732307434, 0.006779476068913937]\n",
            "LOSS RATIO: 3016.949462890625 1906.220703125\n",
            "Epoch 36 Loss: 9.01680e-01 Accuracy: 0.94286 Epoch Time: 2.27718\n",
            "RANGE_ATTN: [0.9912692308425903, 0.2944609820842743]\n",
            "LOSS RATIO: 3013.78955078125 1971.06884765625\n",
            "Epoch 37 Loss: 9.12978e-01 Accuracy: 0.94249 Epoch Time: 2.27166\n",
            "RANGE_ATTN: [0.9512248039245605, 0.1114368811249733]\n",
            "LOSS RATIO: 3060.248046875 2069.235107421875\n",
            "Epoch 38 Loss: 9.39466e-01 Accuracy: 0.94048 Epoch Time: 2.26230\n",
            "RANGE_ATTN: [0.9551159739494324, 0.33200183510780334]\n",
            "LOSS RATIO: 2994.91162109375 1843.478515625\n",
            "Epoch 39 Loss: 8.86152e-01 Accuracy: 0.94469 Epoch Time: 2.22750\n",
            "RANGE_ATTN: [0.9834679365158081, 0.30940282344818115]\n",
            "LOSS RATIO: 2822.22705078125 1767.3831787109375\n",
            "Epoch 40 Loss: 8.40587e-01 Accuracy: 0.95073 Epoch Time: 2.25676\n",
            "RANGE_ATTN: [0.9608312249183655, 0.27519580721855164]\n",
            "LOSS RATIO: 2908.845947265625 1779.1693115234375\n",
            "Epoch 41 Loss: 8.58611e-01 Accuracy: 0.94799 Epoch Time: 2.31150\n",
            "RANGE_ATTN: [0.9990725517272949, 2.4254446543636732e-05]\n",
            "LOSS RATIO: 3242.920654296875 2218.448974609375\n",
            "Epoch 42 Loss: 1.00025e+00 Accuracy: 0.93242 Epoch Time: 2.20780\n",
            "RANGE_ATTN: [0.9790760278701782, 0.0751231461763382]\n",
            "LOSS RATIO: 3148.65087890625 2241.295166015625\n",
            "Epoch 43 Loss: 9.87169e-01 Accuracy: 0.93462 Epoch Time: 2.14489\n",
            "RANGE_ATTN: [0.9833111763000488, 0.22028791904449463]\n",
            "LOSS RATIO: 2952.23486328125 1831.7061767578125\n",
            "Epoch 44 Loss: 8.76180e-01 Accuracy: 0.94744 Epoch Time: 2.28696\n",
            "RANGE_ATTN: [0.9690895676612854, 0.3298509120941162]\n",
            "LOSS RATIO: 2894.3916015625 1722.5684814453125\n",
            "Epoch 45 Loss: 8.45597e-01 Accuracy: 0.94963 Epoch Time: 2.18859\n",
            "RANGE_ATTN: [0.9999996423721313, 0.003844935679808259]\n",
            "LOSS RATIO: 3007.882568359375 1887.5638427734375\n",
            "Epoch 46 Loss: 8.96601e-01 Accuracy: 0.94579 Epoch Time: 2.20004\n",
            "RANGE_ATTN: [0.9903938174247742, 0.11760177463293076]\n",
            "LOSS RATIO: 2934.53125 1741.01611328125\n",
            "Epoch 47 Loss: 8.56328e-01 Accuracy: 0.94780 Epoch Time: 2.23449\n",
            "RANGE_ATTN: [0.9844422936439514, 0.17634296417236328]\n",
            "LOSS RATIO: 2986.361328125 1789.4619140625\n",
            "Epoch 48 Loss: 8.74693e-01 Accuracy: 0.94505 Epoch Time: 2.23635\n",
            "RANGE_ATTN: [0.979223370552063, 0.08231206238269806]\n",
            "LOSS RATIO: 2947.44873046875 1745.6082763671875\n",
            "Epoch 49 Loss: 8.59534e-01 Accuracy: 0.94853 Epoch Time: 2.19399\n",
            "1.0428861100097342 0.9290598290598291\n",
            "Noise Level: low Mode: era\n",
            "Train-val-test lengths:  218400 46800 46800\n",
            "RANGE_ATTN: [0.5272802710533142, 0.0]\n",
            "LOSS RATIO: nan nan\n",
            "Epoch  0 Loss: nan Accuracy: 0.08327 Epoch Time: 14.48339\n",
            "RANGE_ATTN: [-100, 100]\n",
            "LOSS RATIO: nan nan\n",
            "Epoch  1 Loss: nan Accuracy: 0.08325 Epoch Time: 14.53050\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[133], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m loader_train, loader_val, loader_test, data \u001b[38;5;241m=\u001b[39m make_data_splits(df, mode\u001b[38;5;241m=\u001b[39mmode, \\\n\u001b[1;32m     22\u001b[0m                                                                batch_size\u001b[38;5;241m=\u001b[39mbatch_sizes[i])\n\u001b[1;32m     23\u001b[0m net \u001b[38;5;241m=\u001b[39m NAL_MLP(dims\u001b[38;5;241m=\u001b[39m[data\u001b[38;5;241m.\u001b[39mX\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m32\u001b[39m, \u001b[38;5;28mlen\u001b[39m(data\u001b[38;5;241m.\u001b[39my\u001b[38;5;241m.\u001b[39munique())])\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 24\u001b[0m net, losses, accs, val_losses, val_accL \u001b[38;5;241m=\u001b[39m \u001b[43mTrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloader_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnoise_levels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_ds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloader_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mplot_accs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot_losses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m plot_loss_acc(losses, accs, val_losses, val_accL, mode, noise_levels[i])\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m#Testing code\u001b[39;00m\n",
            "Cell \u001b[0;32mIn[131], line 17\u001b[0m, in \u001b[0;36mTrain\u001b[0;34m(Net, data, mode, noise_level, epochs, lr, Loss, verbose, device, val_ds, plot_accs, plot_losses)\u001b[0m\n\u001b[1;32m     15\u001b[0m total_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     16\u001b[0m range_attn \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m100\u001b[39m] \u001b[38;5;66;03m# max, min\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (X,y) \u001b[38;5;129;01min\u001b[39;00m data:\n\u001b[1;32m     18\u001b[0m     X\u001b[38;5;241m=\u001b[39mX\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     19\u001b[0m     y\u001b[38;5;241m=\u001b[39my\u001b[38;5;241m.\u001b[39mto(device)\n",
            "File \u001b[0;32m~/anaconda3/envs/tiger/lib/python3.9/site-packages/torch/utils/data/dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    633\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    638\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
            "File \u001b[0;32m~/anaconda3/envs/tiger/lib/python3.9/site-packages/torch/utils/data/dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    677\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 678\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    680\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
            "File \u001b[0;32m~/anaconda3/envs/tiger/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
            "File \u001b[0;32m~/anaconda3/envs/tiger/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
            "File \u001b[0;32m~/anaconda3/envs/tiger/lib/python3.9/site-packages/torch/utils/data/dataset.py:298\u001b[0m, in \u001b[0;36mSubset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(idx, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    297\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m idx]]\n\u001b[0;32m--> 298\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n",
            "Cell \u001b[0;32mIn[5], line 15\u001b[0m, in \u001b[0;36mSinusodialDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[1;32m     14\u001b[0m     X \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX\u001b[38;5;241m.\u001b[39miloc[idx]\u001b[38;5;241m.\u001b[39mvalues, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m---> 15\u001b[0m     y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;28mint\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
            "File \u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/core/indexing.py:1061\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1059\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m   1060\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m-> 1061\u001b[0m     \u001b[43mcheck_deprecated_indexers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(key) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m:\n\u001b[1;32m   1063\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mlist\u001b[39m(x) \u001b[38;5;28;01mif\u001b[39;00m is_iterator(x) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m key)\n",
            "File \u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/core/indexing.py:2659\u001b[0m, in \u001b[0;36mcheck_deprecated_indexers\u001b[0;34m(key)\u001b[0m\n\u001b[1;32m   2656\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_deprecated_indexers\u001b[39m(key) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2657\u001b[0m     \u001b[38;5;124;03m\"\"\"Checks if the key is a deprecated indexer.\"\"\"\u001b[39;00m\n\u001b[1;32m   2658\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m-> 2659\u001b[0m         \u001b[38;5;28;43misinstance\u001b[39;49m(key, \u001b[38;5;28mset\u001b[39m)\n\u001b[1;32m   2660\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m)\n\u001b[1;32m   2661\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mset\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m key)\n\u001b[1;32m   2662\u001b[0m     ):\n\u001b[1;32m   2663\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   2664\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing a set as an indexer is deprecated and will raise in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2665\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma future version. Use a list instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2666\u001b[0m             \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m   2667\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m   2668\u001b[0m         )\n\u001b[1;32m   2669\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2670\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mdict\u001b[39m)\n\u001b[1;32m   2671\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m)\n\u001b[1;32m   2672\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m key)\n\u001b[1;32m   2673\u001b[0m     ):\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "df_paths = ['../Datasets/df_syn_train_0_0_.csv',\n",
        "            '../Datasets/df_synA_train_shuffled.csv',\n",
        "            '../Datasets/df_synA_test_hard_shuffled_sample.csv']\n",
        "\n",
        "noise_levels = ['none', 'low', 'high']\n",
        "batch_sizes = [8, 128, 128]\n",
        "\n",
        "losses_arr = []\n",
        "accs_arr = []\n",
        "\n",
        "for i in range(0, 3):\n",
        "    df = pd.read_csv(df_paths[i])\n",
        "\n",
        "    modes = ['era', 'target_5_val', 'target_10_val']\n",
        "\n",
        "    loss_per_mode = []\n",
        "    acc_per_mode = []\n",
        "\n",
        "    for mode in modes:\n",
        "        print(\"Noise Level:\", noise_levels[i], \"Mode:\", mode)\n",
        "        loader_train, loader_val, loader_test, data = make_data_splits(df, mode=mode, \\\n",
        "                                                                       batch_size=batch_sizes[i])\n",
        "        net = NAL_MLP(dims=[data.X.shape[1], 32, 64, 32, len(data.y.unique())]).to(device)\n",
        "        net, losses, accs, val_losses, val_accL = Train(net, loader_train, mode, noise_levels[i], \\\n",
        "                                      epochs=50, verbose=True, device=device, val_ds=loader_val, \\\n",
        "                                      plot_accs=True, plot_losses=True)\n",
        "        plot_loss_acc(losses, accs, val_losses, val_accL, mode, noise_levels[i])\n",
        "        \n",
        "        #Testing code\n",
        "        test_loss, test_acc = Test(net, loader_test, mode, noise_levels[i], device=device)\n",
        "        print(test_loss, test_acc)\n",
        "        loss_per_mode.append(test_loss)\n",
        "        acc_per_mode.append(test_acc)\n",
        "\n",
        "    losses_arr.append(loss_per_mode)\n",
        "    accs_arr.append(acc_per_mode)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aQ3F_j9-SCUT"
      },
      "outputs": [],
      "source": [
        "with open(f'{prefix}/losses_dump.pkl', 'wb') as f:\n",
        "    pkl.dump(losses_arr, f)\n",
        "\n",
        "with open(f'{prefix}/accs_dump.pkl', 'wb') as f:\n",
        "    pkl.dump(accs_arr, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.8905982905982905, 0.958974358974359, 0.9777777777777777], [0.7842948717948718, 0.9435042735042735, 0.9539957264957265], [0.5431089743589743, 0.8661057692307692, 0.8773771367521368]]\n"
          ]
        }
      ],
      "source": [
        "# import pickle as pkl\n",
        "# prefix = './data_dump_NAL_final'\n",
        "# with open(f'{prefix}/accs_dump.pkl', 'rb') as f:\n",
        "#     accs = pkl.load(f)\n",
        "\n",
        "# print(accs)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
