{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_o82TjduV4L",
        "outputId": "f754f5bc-8a03-44b7-db36-4a0aa52ad1f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/raid/home/niranjan20090/anaconda3/envs/tiger/bin/gdown\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/raid/home/niranjan20090/anaconda3/envs/tiger/lib/python3.9/site-packages/gdown/cli.py\", line 156, in main\n",
            "    filename = download(\n",
            "  File \"/raid/home/niranjan20090/anaconda3/envs/tiger/lib/python3.9/site-packages/gdown/download.py\", line 259, in download\n",
            "    filename_from_url = m.groups()[0]\n",
            "AttributeError: 'NoneType' object has no attribute 'groups'\n"
          ]
        }
      ],
      "source": [
        "# !gdown https://drive.google.com/file/d/1Hv4RAltBumSfOkRacoX8qrfDYfd_NDss/view?usp=drive_link --fuzzy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UD9ZDc-TvXuQ",
        "outputId": "bd6856a8-62d4-442f-adda-0f87f8b8e47d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  Dataset_AML_Assignment1_Part1.zip\n",
            "  inflating: df_syn_train_0_0_.csv   \n",
            "  inflating: df_synA_test_hard_shuffled_sample.csv  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  inflating: df_synA_train_shuffled.csv  \n"
          ]
        }
      ],
      "source": [
        "# !unzip Dataset_AML_Assignment1_Part1.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMiPtCSFLfGA",
        "outputId": "5677688c-94a4-422c-bb36-da7e1a8da60d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HwsdAOp9wdrt"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import torch.nn.functional as F\n",
        "from IPython import display\n",
        "from tqdm.notebook import tqdm\n",
        "import random\n",
        "import math, time, os\n",
        "from matplotlib import pyplot as plt\n",
        "import pickle as pkl\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "prefix = './data_dump'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "BSg9T51-MC-D"
      },
      "outputs": [],
      "source": [
        "# NAL - ninju\n",
        "# Ensemble - mudit\n",
        "# Autoencoder - ninju\n",
        "# SubTab\n",
        "# Meta Learning (clean+dirty)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Q5NZw6c2zf81"
      },
      "outputs": [],
      "source": [
        "class SinusodialDataset(Dataset):\n",
        "    def __init__(self, df, mode='era'):\n",
        "        \"\"\" creating label columns of eras and targets \"\"\"\n",
        "        self.X = df.iloc[:, :24]\n",
        "        if mode == 'era':\n",
        "          self.y = df['era_label']\n",
        "        else:\n",
        "          self.y = df[f'{mode}']\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.X.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        X = torch.tensor(self.X.iloc[idx].values, dtype=torch.float32)\n",
        "        y = torch.tensor(int(self.y.iloc[idx]), dtype=torch.long)\n",
        "        return X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "RnMHIA5F2jBV"
      },
      "outputs": [],
      "source": [
        "def make_data_splits(df, mode, batch_size=32, train_perc=0.7, val_test_perc=0.5):\n",
        "\n",
        "    def encode(v, class_values):\n",
        "        return class_values.index(v)\n",
        "\n",
        "    #adding new era_label column indexed 0, 1,...\n",
        "    class_values = df['era'].unique().tolist()\n",
        "    df['era_label'] = df['era'].apply(lambda x: encode(x, class_values))\n",
        "    df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "    train_samples = int(len(df)*train_perc)\n",
        "    val_test_samples = len(df)-train_samples\n",
        "\n",
        "    data = SinusodialDataset(df, mode=mode)\n",
        "    data_train, data_test = random_split(data, [train_samples, val_test_samples])\n",
        "\n",
        "    val_samples = int(len(data_test)*0.5)\n",
        "    test_samples = len(data_test)-val_samples\n",
        "    data_val, data_test = random_split(data_test, [val_samples, test_samples])\n",
        "\n",
        "    print(\"Train-val-test lengths: \", len(data_train), len(data_val), len(data_test))\n",
        "\n",
        "    loader_train = DataLoader(data_train, batch_size=batch_size, shuffle=True)\n",
        "    loader_val = DataLoader(data_val, batch_size=batch_size, shuffle=False)\n",
        "    loader_test = DataLoader(data_test, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    return loader_train, loader_val, loader_test, data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJWMzGJ6QYS4"
      },
      "source": [
        "#Base Model - MLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "pIev8M38FwkD"
      },
      "outputs": [],
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, dims, task='classification', lr=1e-3, weight_decay=1e-3):\n",
        "        super(MLP,self).__init__()\n",
        "        self.dims=dims\n",
        "        self.task=task\n",
        "        self.layers=nn.ModuleList()\n",
        "        for i in range(len(self.dims)-2):\n",
        "            self.layers.append(nn.Linear(dims[i],dims[i+1]))\n",
        "            self.layers.append(nn.ReLU())\n",
        "        if task == 'classification':\n",
        "            self.layers.append(nn.Linear(dims[i+1],dims[i+2]))\n",
        "            self.layers.append(nn.LogSoftmax(dim=1))\n",
        "        if task == 'regression':\n",
        "            self.layers.append(nn.Linear(dims[i+1],dims[i+2]))\n",
        "            self.layers.append(nn.ReLU())\n",
        "        self.optimizer = optim.Adam(self.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = x.float()\n",
        "        for l in self.layers:\n",
        "            x = l(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "TI_5uJrIL5di"
      },
      "outputs": [],
      "source": [
        "def accuracy(Net, X_test, y_test, verbose=True):\n",
        "    Net.eval()\n",
        "    m = X_test.shape[0]\n",
        "    y_pred = Net(X_test)\n",
        "    predicted = torch.max(y_pred, 1)[1]\n",
        "    correct = (predicted == y_test).float().sum().item()\n",
        "    if verbose:\n",
        "        print(correct,m)\n",
        "    accuracy = correct/m\n",
        "    Net.train()\n",
        "    return accuracy, correct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ioBeC96SEKnx"
      },
      "outputs": [],
      "source": [
        "def Test(net, loader_test, mode, noise_level, \\\n",
        "         device='cpu', Loss=nn.NLLLoss(reduction='sum')):\n",
        "    net.eval()\n",
        "    total_samples = 0\n",
        "    correct_samples = 0\n",
        "    loss = 0.0\n",
        "    for (X, y) in loader_test:\n",
        "        X=X.to(device)\n",
        "        y=y.to(device)\n",
        "        total_samples += y.shape[0]\n",
        "        _, i_cor_sam = accuracy(net,X,y,verbose=False)\n",
        "        correct_samples += i_cor_sam\n",
        "        loss += Loss(net(X), y).cpu().detach().item()\n",
        "    acc = correct_samples / total_samples\n",
        "    loss /= total_samples\n",
        "    return loss, acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "0npX0g97CS4B"
      },
      "outputs": [],
      "source": [
        "def Train(Net, data, mode, noise_level, epochs=20, lr=5e-2, Loss=nn.NLLLoss(reduction='sum'), verbose=False, device='cpu',\n",
        "          val_ds=None, plot_accs=False, plot_losses=False):\n",
        "    model_save_time = time.time()\n",
        "    losses = []\n",
        "    accs = []\n",
        "    val_losses=[]\n",
        "    val_accL=[]\n",
        "    Net.to(device)\n",
        "    for e in range(epochs):\n",
        "        Net.train()\n",
        "        step=0\n",
        "        tot_loss=0.0\n",
        "        start_time = time.time()\n",
        "        correct_samples = 0\n",
        "        total_samples = 0\n",
        "        for (X,y) in data:\n",
        "            X=X.to(device)\n",
        "            y=y.to(device)\n",
        "            total_samples += y.shape[0]\n",
        "            y_pred = Net(X)\n",
        "            loss = Loss(y_pred,y)\n",
        "            Net.optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            Net.optimizer.step()\n",
        "            step+=1\n",
        "            tot_loss+=loss\n",
        "            if verbose:\n",
        "                _, i_cor_sam = accuracy(Net,X,y,verbose=False)\n",
        "                correct_samples += i_cor_sam\n",
        "        end_time = time.time()\n",
        "        t = end_time-start_time\n",
        "        l = tot_loss.item()/total_samples\n",
        "        losses += [l]\n",
        "        if verbose:\n",
        "            a = correct_samples/total_samples\n",
        "            accs += [a]\n",
        "            print('Epoch %2d Loss: %2.5e Accuracy: %2.5f Epoch Time: %2.5f' %(e,l,a,t))\n",
        "\n",
        "        val_loss, val_acc = Test(Net, val_ds, mode, noise_level, device)\n",
        "        val_losses.append(val_loss)\n",
        "        val_accL.append(val_acc)\n",
        "\n",
        "        torch.save(Net.state_dict(), f'{prefix}/net_{noise_level}_{mode}_{str(model_save_time)}.pth')\n",
        "\n",
        "    return Net, losses, accs, val_losses, val_accL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "qkoa2_muJIwq"
      },
      "outputs": [],
      "source": [
        "def plot_loss_acc(losses, accs, val_losses, val_accs, mode, noise_level):\n",
        "\n",
        "    plt.plot(np.array(accs),color='red', label='Train accuracy')\n",
        "    plt.plot(np.array(val_accs),color='blue', label='Val accuracy')\n",
        "    plt.legend()\n",
        "    plt.savefig(f'{prefix}/acc_{mode}_{noise_level}.png')\n",
        "    plt.clf()\n",
        "\n",
        "    plt.plot(np.array(losses),color='red', label='Train loss')\n",
        "    plt.plot(np.array(val_losses),color='blue', label='Val loss')\n",
        "    plt.legend()\n",
        "    plt.savefig(f'{prefix}/loss_{mode}_{noise_level}.png')\n",
        "    plt.clf()\n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "hh6eKpraxMP-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Noise Level: none Mode: era\n",
            "Train-val-test lengths:  5460 1170 1170\n",
            "Epoch  0 Loss: 2.29510e+00 Accuracy: 0.20549 Epoch Time: 1.22482\n",
            "Epoch  1 Loss: 1.34349e+00 Accuracy: 0.52198 Epoch Time: 1.14499\n",
            "Epoch  2 Loss: 9.30129e-01 Accuracy: 0.65788 Epoch Time: 1.10347\n",
            "Epoch  3 Loss: 7.71677e-01 Accuracy: 0.72033 Epoch Time: 1.00233\n",
            "Epoch  4 Loss: 6.89737e-01 Accuracy: 0.75348 Epoch Time: 1.11284\n",
            "Epoch  5 Loss: 6.37575e-01 Accuracy: 0.77601 Epoch Time: 1.11866\n",
            "Epoch  6 Loss: 6.07297e-01 Accuracy: 0.77674 Epoch Time: 1.19121\n",
            "Epoch  7 Loss: 5.79508e-01 Accuracy: 0.78278 Epoch Time: 1.11765\n",
            "Epoch  8 Loss: 5.53314e-01 Accuracy: 0.79597 Epoch Time: 0.95850\n",
            "Epoch  9 Loss: 5.41746e-01 Accuracy: 0.79927 Epoch Time: 1.09161\n",
            "Epoch 10 Loss: 5.23154e-01 Accuracy: 0.80531 Epoch Time: 1.19283\n",
            "Epoch 11 Loss: 4.96686e-01 Accuracy: 0.80696 Epoch Time: 1.36781\n",
            "Epoch 12 Loss: 4.83682e-01 Accuracy: 0.81447 Epoch Time: 1.05633\n",
            "Epoch 13 Loss: 4.62371e-01 Accuracy: 0.82546 Epoch Time: 1.01182\n",
            "Epoch 14 Loss: 4.59002e-01 Accuracy: 0.82473 Epoch Time: 1.11629\n",
            "Epoch 15 Loss: 4.42214e-01 Accuracy: 0.82839 Epoch Time: 1.12731\n",
            "Epoch 16 Loss: 4.36334e-01 Accuracy: 0.83205 Epoch Time: 1.21609\n",
            "Epoch 17 Loss: 4.19955e-01 Accuracy: 0.83498 Epoch Time: 1.02017\n",
            "Epoch 18 Loss: 4.13655e-01 Accuracy: 0.84396 Epoch Time: 1.07037\n",
            "Epoch 19 Loss: 4.00603e-01 Accuracy: 0.84560 Epoch Time: 0.98531\n",
            "Epoch 20 Loss: 3.86902e-01 Accuracy: 0.85476 Epoch Time: 0.84551\n",
            "Epoch 21 Loss: 3.85307e-01 Accuracy: 0.85440 Epoch Time: 1.29121\n",
            "Epoch 22 Loss: 3.70099e-01 Accuracy: 0.85989 Epoch Time: 1.08289\n",
            "Epoch 23 Loss: 3.58438e-01 Accuracy: 0.86392 Epoch Time: 1.03359\n",
            "Epoch 24 Loss: 3.51741e-01 Accuracy: 0.86740 Epoch Time: 1.49048\n",
            "Epoch 25 Loss: 3.45922e-01 Accuracy: 0.87161 Epoch Time: 1.21503\n",
            "Epoch 26 Loss: 3.35530e-01 Accuracy: 0.87491 Epoch Time: 1.08197\n",
            "Epoch 27 Loss: 3.35998e-01 Accuracy: 0.87546 Epoch Time: 1.16961\n",
            "Epoch 28 Loss: 3.21777e-01 Accuracy: 0.88077 Epoch Time: 1.23115\n",
            "Epoch 29 Loss: 3.14269e-01 Accuracy: 0.88242 Epoch Time: 1.15665\n",
            "Epoch 30 Loss: 3.11546e-01 Accuracy: 0.88810 Epoch Time: 0.97870\n",
            "Epoch 31 Loss: 3.04693e-01 Accuracy: 0.88443 Epoch Time: 1.13740\n",
            "Epoch 32 Loss: 3.14734e-01 Accuracy: 0.88663 Epoch Time: 0.93560\n",
            "Epoch 33 Loss: 2.93331e-01 Accuracy: 0.89304 Epoch Time: 1.28726\n",
            "Epoch 34 Loss: 2.90368e-01 Accuracy: 0.89249 Epoch Time: 1.50543\n",
            "Epoch 35 Loss: 2.87378e-01 Accuracy: 0.89542 Epoch Time: 1.36543\n",
            "Epoch 36 Loss: 2.71958e-01 Accuracy: 0.90513 Epoch Time: 1.36004\n",
            "Epoch 37 Loss: 2.70273e-01 Accuracy: 0.90092 Epoch Time: 1.29630\n",
            "Epoch 38 Loss: 2.62894e-01 Accuracy: 0.90037 Epoch Time: 1.09034\n",
            "Epoch 39 Loss: 2.56091e-01 Accuracy: 0.91007 Epoch Time: 1.08496\n",
            "Epoch 40 Loss: 2.54932e-01 Accuracy: 0.90788 Epoch Time: 1.12029\n",
            "Epoch 41 Loss: 2.49505e-01 Accuracy: 0.91136 Epoch Time: 1.08553\n",
            "Epoch 42 Loss: 2.47322e-01 Accuracy: 0.90897 Epoch Time: 0.98139\n",
            "Epoch 43 Loss: 2.37063e-01 Accuracy: 0.91374 Epoch Time: 1.19646\n",
            "Epoch 44 Loss: 2.42775e-01 Accuracy: 0.91337 Epoch Time: 1.18478\n",
            "Epoch 45 Loss: 2.42740e-01 Accuracy: 0.91319 Epoch Time: 1.13065\n",
            "Epoch 46 Loss: 2.35537e-01 Accuracy: 0.91245 Epoch Time: 1.28826\n",
            "Epoch 47 Loss: 2.28366e-01 Accuracy: 0.91667 Epoch Time: 0.91237\n",
            "Epoch 48 Loss: 2.34187e-01 Accuracy: 0.91630 Epoch Time: 1.24733\n",
            "Epoch 49 Loss: 2.24717e-01 Accuracy: 0.91813 Epoch Time: 1.08397\n",
            "0.2568475688624586 0.8905982905982905\n",
            "Noise Level: none Mode: target_5_val\n",
            "Train-val-test lengths:  5460 1170 1170\n",
            "Epoch  0 Loss: 6.56400e-01 Accuracy: 0.75385 Epoch Time: 1.41515\n",
            "Epoch  1 Loss: 2.52019e-01 Accuracy: 0.88608 Epoch Time: 1.36624\n",
            "Epoch  2 Loss: 1.98668e-01 Accuracy: 0.90586 Epoch Time: 1.07640\n",
            "Epoch  3 Loss: 1.70349e-01 Accuracy: 0.92253 Epoch Time: 0.93249\n",
            "Epoch  4 Loss: 1.59048e-01 Accuracy: 0.93205 Epoch Time: 1.23345\n",
            "Epoch  5 Loss: 1.45466e-01 Accuracy: 0.93974 Epoch Time: 1.18889\n",
            "Epoch  6 Loss: 1.31881e-01 Accuracy: 0.94780 Epoch Time: 1.23098\n",
            "Epoch  7 Loss: 1.29235e-01 Accuracy: 0.95147 Epoch Time: 1.17578\n",
            "Epoch  8 Loss: 1.18305e-01 Accuracy: 0.95366 Epoch Time: 1.06546\n",
            "Epoch  9 Loss: 1.14810e-01 Accuracy: 0.95568 Epoch Time: 1.21365\n",
            "Epoch 10 Loss: 1.07312e-01 Accuracy: 0.95842 Epoch Time: 1.21205\n",
            "Epoch 11 Loss: 1.12093e-01 Accuracy: 0.95788 Epoch Time: 1.02642\n",
            "Epoch 12 Loss: 1.01434e-01 Accuracy: 0.95952 Epoch Time: 0.94112\n",
            "Epoch 13 Loss: 1.01122e-01 Accuracy: 0.96007 Epoch Time: 1.02876\n",
            "Epoch 14 Loss: 9.58243e-02 Accuracy: 0.96227 Epoch Time: 1.12017\n",
            "Epoch 15 Loss: 9.63615e-02 Accuracy: 0.96117 Epoch Time: 1.23583\n",
            "Epoch 16 Loss: 9.45990e-02 Accuracy: 0.96136 Epoch Time: 1.18003\n",
            "Epoch 17 Loss: 9.51465e-02 Accuracy: 0.96374 Epoch Time: 1.07794\n",
            "Epoch 18 Loss: 9.03440e-02 Accuracy: 0.96538 Epoch Time: 0.95710\n",
            "Epoch 19 Loss: 8.78041e-02 Accuracy: 0.96465 Epoch Time: 1.20239\n",
            "Epoch 20 Loss: 8.91018e-02 Accuracy: 0.96538 Epoch Time: 1.21557\n",
            "Epoch 21 Loss: 8.77323e-02 Accuracy: 0.96465 Epoch Time: 0.98497\n",
            "Epoch 22 Loss: 8.22860e-02 Accuracy: 0.96722 Epoch Time: 1.12446\n",
            "Epoch 23 Loss: 8.15175e-02 Accuracy: 0.96777 Epoch Time: 1.20161\n",
            "Epoch 24 Loss: 8.33042e-02 Accuracy: 0.96648 Epoch Time: 1.18512\n",
            "Epoch 25 Loss: 8.60696e-02 Accuracy: 0.96758 Epoch Time: 1.12692\n",
            "Epoch 26 Loss: 7.90627e-02 Accuracy: 0.96777 Epoch Time: 1.26622\n",
            "Epoch 27 Loss: 8.14322e-02 Accuracy: 0.96941 Epoch Time: 1.16915\n",
            "Epoch 28 Loss: 7.58320e-02 Accuracy: 0.97125 Epoch Time: 0.93239\n",
            "Epoch 29 Loss: 7.70258e-02 Accuracy: 0.96996 Epoch Time: 0.96821\n",
            "Epoch 30 Loss: 7.64671e-02 Accuracy: 0.97070 Epoch Time: 1.15573\n",
            "Epoch 31 Loss: 7.46434e-02 Accuracy: 0.97326 Epoch Time: 1.07027\n",
            "Epoch 32 Loss: 7.53086e-02 Accuracy: 0.96868 Epoch Time: 1.26695\n",
            "Epoch 33 Loss: 7.53152e-02 Accuracy: 0.97216 Epoch Time: 1.02904\n",
            "Epoch 34 Loss: 7.18982e-02 Accuracy: 0.97308 Epoch Time: 1.27038\n",
            "Epoch 35 Loss: 7.08246e-02 Accuracy: 0.97289 Epoch Time: 0.92788\n",
            "Epoch 36 Loss: 7.19481e-02 Accuracy: 0.97308 Epoch Time: 1.27338\n",
            "Epoch 37 Loss: 7.01596e-02 Accuracy: 0.97289 Epoch Time: 0.90622\n",
            "Epoch 38 Loss: 6.55917e-02 Accuracy: 0.97711 Epoch Time: 1.16848\n",
            "Epoch 39 Loss: 6.35224e-02 Accuracy: 0.97784 Epoch Time: 1.17265\n",
            "Epoch 40 Loss: 6.35422e-02 Accuracy: 0.97747 Epoch Time: 1.19680\n",
            "Epoch 41 Loss: 6.34897e-02 Accuracy: 0.97729 Epoch Time: 1.30793\n",
            "Epoch 42 Loss: 6.20014e-02 Accuracy: 0.97802 Epoch Time: 1.00432\n",
            "Epoch 43 Loss: 6.50245e-02 Accuracy: 0.97601 Epoch Time: 1.10613\n",
            "Epoch 44 Loss: 6.08774e-02 Accuracy: 0.97747 Epoch Time: 1.29933\n",
            "Epoch 45 Loss: 5.73824e-02 Accuracy: 0.97930 Epoch Time: 0.97941\n",
            "Epoch 46 Loss: 6.25231e-02 Accuracy: 0.97857 Epoch Time: 1.03489\n",
            "Epoch 47 Loss: 6.18594e-02 Accuracy: 0.97711 Epoch Time: 1.20311\n",
            "Epoch 48 Loss: 5.84265e-02 Accuracy: 0.98004 Epoch Time: 1.07405\n",
            "Epoch 49 Loss: 5.60079e-02 Accuracy: 0.97875 Epoch Time: 1.17192\n",
            "0.07912419518599144 0.958974358974359\n",
            "Noise Level: none Mode: target_10_val\n",
            "Train-val-test lengths:  5460 1170 1170\n",
            "Epoch  0 Loss: 6.03907e-01 Accuracy: 0.78480 Epoch Time: 1.21281\n",
            "Epoch  1 Loss: 3.19477e-01 Accuracy: 0.86044 Epoch Time: 1.20669\n",
            "Epoch  2 Loss: 2.81654e-01 Accuracy: 0.88352 Epoch Time: 1.12860\n",
            "Epoch  3 Loss: 2.62711e-01 Accuracy: 0.89231 Epoch Time: 1.13804\n",
            "Epoch  4 Loss: 2.47992e-01 Accuracy: 0.89890 Epoch Time: 1.15426\n",
            "Epoch  5 Loss: 2.39928e-01 Accuracy: 0.90220 Epoch Time: 0.72880\n",
            "Epoch  6 Loss: 2.21129e-01 Accuracy: 0.91337 Epoch Time: 0.88221\n",
            "Epoch  7 Loss: 2.13531e-01 Accuracy: 0.91648 Epoch Time: 0.97498\n",
            "Epoch  8 Loss: 2.10546e-01 Accuracy: 0.91447 Epoch Time: 1.07578\n",
            "Epoch  9 Loss: 1.97049e-01 Accuracy: 0.92033 Epoch Time: 0.86012\n",
            "Epoch 10 Loss: 1.94184e-01 Accuracy: 0.92161 Epoch Time: 1.12748\n",
            "Epoch 11 Loss: 1.83860e-01 Accuracy: 0.92967 Epoch Time: 1.24891\n",
            "Epoch 12 Loss: 1.71462e-01 Accuracy: 0.93352 Epoch Time: 1.16818\n",
            "Epoch 13 Loss: 1.65879e-01 Accuracy: 0.93626 Epoch Time: 0.96649\n",
            "Epoch 14 Loss: 1.59936e-01 Accuracy: 0.93883 Epoch Time: 1.34921\n",
            "Epoch 15 Loss: 1.47089e-01 Accuracy: 0.94579 Epoch Time: 1.28091\n",
            "Epoch 16 Loss: 1.44058e-01 Accuracy: 0.94377 Epoch Time: 1.09080\n",
            "Epoch 17 Loss: 1.34344e-01 Accuracy: 0.95183 Epoch Time: 0.90242\n",
            "Epoch 18 Loss: 1.31287e-01 Accuracy: 0.95110 Epoch Time: 1.31854\n",
            "Epoch 19 Loss: 1.25095e-01 Accuracy: 0.95531 Epoch Time: 0.98603\n",
            "Epoch 20 Loss: 1.18371e-01 Accuracy: 0.95714 Epoch Time: 1.27129\n",
            "Epoch 21 Loss: 1.21452e-01 Accuracy: 0.95568 Epoch Time: 1.05775\n",
            "Epoch 22 Loss: 1.11033e-01 Accuracy: 0.96190 Epoch Time: 1.09477\n",
            "Epoch 23 Loss: 1.16245e-01 Accuracy: 0.95659 Epoch Time: 0.85151\n",
            "Epoch 24 Loss: 1.03550e-01 Accuracy: 0.96245 Epoch Time: 1.04703\n",
            "Epoch 25 Loss: 9.90186e-02 Accuracy: 0.96612 Epoch Time: 0.97487\n",
            "Epoch 26 Loss: 9.97645e-02 Accuracy: 0.96520 Epoch Time: 1.04334\n",
            "Epoch 27 Loss: 9.64835e-02 Accuracy: 0.96520 Epoch Time: 1.02814\n",
            "Epoch 28 Loss: 1.01254e-01 Accuracy: 0.96410 Epoch Time: 0.93660\n",
            "Epoch 29 Loss: 8.73714e-02 Accuracy: 0.97015 Epoch Time: 0.95908\n",
            "Epoch 30 Loss: 8.52331e-02 Accuracy: 0.96996 Epoch Time: 1.08707\n",
            "Epoch 31 Loss: 8.05349e-02 Accuracy: 0.96996 Epoch Time: 1.16759\n",
            "Epoch 32 Loss: 8.42407e-02 Accuracy: 0.97070 Epoch Time: 1.07476\n",
            "Epoch 33 Loss: 7.97151e-02 Accuracy: 0.97308 Epoch Time: 1.39204\n",
            "Epoch 34 Loss: 7.83756e-02 Accuracy: 0.97363 Epoch Time: 1.23140\n",
            "Epoch 35 Loss: 7.87729e-02 Accuracy: 0.97088 Epoch Time: 0.97563\n",
            "Epoch 36 Loss: 7.73645e-02 Accuracy: 0.97326 Epoch Time: 1.05403\n",
            "Epoch 37 Loss: 7.56980e-02 Accuracy: 0.97326 Epoch Time: 0.89374\n",
            "Epoch 38 Loss: 7.17300e-02 Accuracy: 0.97601 Epoch Time: 1.05027\n",
            "Epoch 39 Loss: 7.21548e-02 Accuracy: 0.97619 Epoch Time: 1.08127\n",
            "Epoch 40 Loss: 6.99875e-02 Accuracy: 0.97674 Epoch Time: 0.93343\n",
            "Epoch 41 Loss: 6.82595e-02 Accuracy: 0.97784 Epoch Time: 1.21170\n",
            "Epoch 42 Loss: 6.67517e-02 Accuracy: 0.97582 Epoch Time: 1.46738\n",
            "Epoch 43 Loss: 6.65562e-02 Accuracy: 0.97747 Epoch Time: 1.26098\n",
            "Epoch 44 Loss: 6.44899e-02 Accuracy: 0.97766 Epoch Time: 1.05114\n",
            "Epoch 45 Loss: 6.82523e-02 Accuracy: 0.97637 Epoch Time: 0.95680\n",
            "Epoch 46 Loss: 6.00094e-02 Accuracy: 0.97930 Epoch Time: 1.00015\n",
            "Epoch 47 Loss: 6.24989e-02 Accuracy: 0.97802 Epoch Time: 1.42528\n",
            "Epoch 48 Loss: 6.35376e-02 Accuracy: 0.97912 Epoch Time: 0.99276\n",
            "Epoch 49 Loss: 6.34551e-02 Accuracy: 0.97747 Epoch Time: 1.12773\n",
            "0.0547298049633829 0.9777777777777777\n",
            "Noise Level: low Mode: era\n",
            "Train-val-test lengths:  218400 46800 46800\n",
            "Epoch  0 Loss: 1.20223e+00 Accuracy: 0.56049 Epoch Time: 20.90022\n",
            "Epoch  1 Loss: 8.67707e-01 Accuracy: 0.67086 Epoch Time: 21.62141\n",
            "Epoch  2 Loss: 7.74073e-01 Accuracy: 0.70340 Epoch Time: 22.72150\n",
            "Epoch  3 Loss: 7.27721e-01 Accuracy: 0.71847 Epoch Time: 22.73060\n",
            "Epoch  4 Loss: 6.97557e-01 Accuracy: 0.73028 Epoch Time: 22.24878\n",
            "Epoch  5 Loss: 6.79006e-01 Accuracy: 0.73653 Epoch Time: 22.24836\n",
            "Epoch  6 Loss: 6.63636e-01 Accuracy: 0.74179 Epoch Time: 22.52813\n",
            "Epoch  7 Loss: 6.52097e-01 Accuracy: 0.74543 Epoch Time: 23.64531\n",
            "Epoch  8 Loss: 6.39437e-01 Accuracy: 0.74984 Epoch Time: 24.15099\n",
            "Epoch  9 Loss: 6.29033e-01 Accuracy: 0.75425 Epoch Time: 24.35072\n",
            "Epoch 10 Loss: 6.18226e-01 Accuracy: 0.75706 Epoch Time: 22.85795\n",
            "Epoch 11 Loss: 6.11506e-01 Accuracy: 0.75990 Epoch Time: 21.69795\n",
            "Epoch 12 Loss: 6.04463e-01 Accuracy: 0.76215 Epoch Time: 23.05108\n",
            "Epoch 13 Loss: 5.98280e-01 Accuracy: 0.76397 Epoch Time: 23.16605\n",
            "Epoch 14 Loss: 5.93643e-01 Accuracy: 0.76469 Epoch Time: 23.00722\n",
            "Epoch 15 Loss: 5.88582e-01 Accuracy: 0.76703 Epoch Time: 21.95277\n",
            "Epoch 16 Loss: 5.83934e-01 Accuracy: 0.76814 Epoch Time: 22.42449\n",
            "Epoch 17 Loss: 5.79204e-01 Accuracy: 0.76894 Epoch Time: 23.12248\n",
            "Epoch 18 Loss: 5.75292e-01 Accuracy: 0.77083 Epoch Time: 21.80242\n",
            "Epoch 19 Loss: 5.72519e-01 Accuracy: 0.77185 Epoch Time: 20.22477\n",
            "Epoch 20 Loss: 5.69338e-01 Accuracy: 0.77339 Epoch Time: 22.22543\n",
            "Epoch 21 Loss: 5.65554e-01 Accuracy: 0.77337 Epoch Time: 21.57340\n",
            "Epoch 22 Loss: 5.62802e-01 Accuracy: 0.77574 Epoch Time: 21.49901\n",
            "Epoch 23 Loss: 5.60289e-01 Accuracy: 0.77635 Epoch Time: 22.22542\n",
            "Epoch 24 Loss: 5.58967e-01 Accuracy: 0.77689 Epoch Time: 22.37781\n",
            "Epoch 25 Loss: 5.55004e-01 Accuracy: 0.77880 Epoch Time: 22.24482\n",
            "Epoch 26 Loss: 5.52444e-01 Accuracy: 0.77879 Epoch Time: 22.48398\n",
            "Epoch 27 Loss: 5.48512e-01 Accuracy: 0.78092 Epoch Time: 21.93127\n",
            "Epoch 28 Loss: 5.47504e-01 Accuracy: 0.78106 Epoch Time: 21.45795\n",
            "Epoch 29 Loss: 5.44456e-01 Accuracy: 0.78228 Epoch Time: 22.37025\n",
            "Epoch 30 Loss: 5.42393e-01 Accuracy: 0.78313 Epoch Time: 21.45624\n",
            "Epoch 31 Loss: 5.41189e-01 Accuracy: 0.78291 Epoch Time: 21.58464\n",
            "Epoch 32 Loss: 5.39296e-01 Accuracy: 0.78401 Epoch Time: 21.62244\n",
            "Epoch 33 Loss: 5.39149e-01 Accuracy: 0.78330 Epoch Time: 22.05141\n",
            "Epoch 34 Loss: 5.37005e-01 Accuracy: 0.78440 Epoch Time: 21.66770\n",
            "Epoch 35 Loss: 5.34461e-01 Accuracy: 0.78579 Epoch Time: 22.62661\n",
            "Epoch 36 Loss: 5.32403e-01 Accuracy: 0.78733 Epoch Time: 23.04662\n",
            "Epoch 37 Loss: 5.31253e-01 Accuracy: 0.78728 Epoch Time: 23.62847\n",
            "Epoch 38 Loss: 5.29911e-01 Accuracy: 0.78782 Epoch Time: 21.81470\n",
            "Epoch 39 Loss: 5.29257e-01 Accuracy: 0.78821 Epoch Time: 22.85173\n",
            "Epoch 40 Loss: 5.27371e-01 Accuracy: 0.78840 Epoch Time: 22.09433\n",
            "Epoch 41 Loss: 5.26178e-01 Accuracy: 0.78975 Epoch Time: 21.96306\n",
            "Epoch 42 Loss: 5.25340e-01 Accuracy: 0.78981 Epoch Time: 22.79382\n",
            "Epoch 43 Loss: 5.21379e-01 Accuracy: 0.79114 Epoch Time: 21.69443\n",
            "Epoch 44 Loss: 5.22561e-01 Accuracy: 0.79125 Epoch Time: 22.71385\n",
            "Epoch 45 Loss: 5.21507e-01 Accuracy: 0.79146 Epoch Time: 22.35099\n",
            "Epoch 46 Loss: 5.20679e-01 Accuracy: 0.79155 Epoch Time: 21.13444\n",
            "Epoch 47 Loss: 5.18290e-01 Accuracy: 0.79233 Epoch Time: 22.17018\n",
            "Epoch 48 Loss: 5.16180e-01 Accuracy: 0.79305 Epoch Time: 22.05448\n",
            "Epoch 49 Loss: 5.15913e-01 Accuracy: 0.79414 Epoch Time: 21.94451\n",
            "0.5287766684833755 0.7842948717948718\n",
            "Noise Level: low Mode: target_5_val\n",
            "Train-val-test lengths:  218400 46800 46800\n",
            "Epoch  0 Loss: 3.28777e-01 Accuracy: 0.87755 Epoch Time: 19.90114\n",
            "Epoch  1 Loss: 2.33108e-01 Accuracy: 0.91522 Epoch Time: 23.20400\n",
            "Epoch  2 Loss: 2.03155e-01 Accuracy: 0.92340 Epoch Time: 22.30696\n",
            "Epoch  3 Loss: 1.91221e-01 Accuracy: 0.92711 Epoch Time: 22.27651\n",
            "Epoch  4 Loss: 1.85506e-01 Accuracy: 0.92911 Epoch Time: 21.69650\n",
            "Epoch  5 Loss: 1.80345e-01 Accuracy: 0.93082 Epoch Time: 22.09137\n",
            "Epoch  6 Loss: 1.76587e-01 Accuracy: 0.93288 Epoch Time: 22.22494\n",
            "Epoch  7 Loss: 1.72558e-01 Accuracy: 0.93473 Epoch Time: 22.79321\n",
            "Epoch  8 Loss: 1.69546e-01 Accuracy: 0.93543 Epoch Time: 24.09274\n",
            "Epoch  9 Loss: 1.66891e-01 Accuracy: 0.93654 Epoch Time: 26.64565\n",
            "Epoch 10 Loss: 1.64786e-01 Accuracy: 0.93751 Epoch Time: 26.61882\n",
            "Epoch 11 Loss: 1.62690e-01 Accuracy: 0.93824 Epoch Time: 29.99910\n",
            "Epoch 12 Loss: 1.60311e-01 Accuracy: 0.93888 Epoch Time: 26.25049\n",
            "Epoch 13 Loss: 1.59542e-01 Accuracy: 0.93935 Epoch Time: 26.70087\n",
            "Epoch 14 Loss: 1.57696e-01 Accuracy: 0.93941 Epoch Time: 21.95980\n",
            "Epoch 15 Loss: 1.56905e-01 Accuracy: 0.94000 Epoch Time: 21.99636\n",
            "Epoch 16 Loss: 1.55172e-01 Accuracy: 0.94037 Epoch Time: 22.87746\n",
            "Epoch 17 Loss: 1.54897e-01 Accuracy: 0.94033 Epoch Time: 22.18751\n",
            "Epoch 18 Loss: 1.53690e-01 Accuracy: 0.94110 Epoch Time: 22.27529\n",
            "Epoch 19 Loss: 1.53173e-01 Accuracy: 0.94096 Epoch Time: 21.88974\n",
            "Epoch 20 Loss: 1.51749e-01 Accuracy: 0.94152 Epoch Time: 22.47140\n",
            "Epoch 21 Loss: 1.51593e-01 Accuracy: 0.94190 Epoch Time: 22.93212\n",
            "Epoch 22 Loss: 1.50739e-01 Accuracy: 0.94179 Epoch Time: 21.98198\n",
            "Epoch 23 Loss: 1.49762e-01 Accuracy: 0.94220 Epoch Time: 22.12749\n",
            "Epoch 24 Loss: 1.49401e-01 Accuracy: 0.94239 Epoch Time: 22.11264\n",
            "Epoch 25 Loss: 1.48207e-01 Accuracy: 0.94253 Epoch Time: 22.70134\n",
            "Epoch 26 Loss: 1.48001e-01 Accuracy: 0.94250 Epoch Time: 22.72012\n",
            "Epoch 27 Loss: 1.46963e-01 Accuracy: 0.94310 Epoch Time: 21.91029\n",
            "Epoch 28 Loss: 1.46714e-01 Accuracy: 0.94317 Epoch Time: 21.88671\n",
            "Epoch 29 Loss: 1.46083e-01 Accuracy: 0.94352 Epoch Time: 22.57700\n",
            "Epoch 30 Loss: 1.45401e-01 Accuracy: 0.94363 Epoch Time: 23.14162\n",
            "Epoch 31 Loss: 1.44922e-01 Accuracy: 0.94374 Epoch Time: 22.26643\n",
            "Epoch 32 Loss: 1.44423e-01 Accuracy: 0.94394 Epoch Time: 20.39465\n",
            "Epoch 33 Loss: 1.44401e-01 Accuracy: 0.94340 Epoch Time: 20.84345\n",
            "Epoch 34 Loss: 1.43651e-01 Accuracy: 0.94401 Epoch Time: 21.77471\n",
            "Epoch 35 Loss: 1.43305e-01 Accuracy: 0.94389 Epoch Time: 22.64672\n",
            "Epoch 36 Loss: 1.43014e-01 Accuracy: 0.94462 Epoch Time: 21.40673\n",
            "Epoch 37 Loss: 1.42255e-01 Accuracy: 0.94463 Epoch Time: 21.81156\n",
            "Epoch 38 Loss: 1.41748e-01 Accuracy: 0.94503 Epoch Time: 22.62377\n",
            "Epoch 39 Loss: 1.41533e-01 Accuracy: 0.94496 Epoch Time: 21.67438\n",
            "Epoch 40 Loss: 1.41136e-01 Accuracy: 0.94519 Epoch Time: 21.75177\n",
            "Epoch 41 Loss: 1.41241e-01 Accuracy: 0.94498 Epoch Time: 21.74991\n",
            "Epoch 42 Loss: 1.40698e-01 Accuracy: 0.94506 Epoch Time: 21.32160\n",
            "Epoch 43 Loss: 1.40277e-01 Accuracy: 0.94526 Epoch Time: 23.29893\n",
            "Epoch 44 Loss: 1.40291e-01 Accuracy: 0.94536 Epoch Time: 22.47668\n",
            "Epoch 45 Loss: 1.39334e-01 Accuracy: 0.94568 Epoch Time: 22.29155\n",
            "Epoch 46 Loss: 1.39547e-01 Accuracy: 0.94582 Epoch Time: 22.32557\n",
            "Epoch 47 Loss: 1.39078e-01 Accuracy: 0.94564 Epoch Time: 21.87881\n",
            "Epoch 48 Loss: 1.38915e-01 Accuracy: 0.94585 Epoch Time: 22.76787\n",
            "Epoch 49 Loss: 1.39203e-01 Accuracy: 0.94594 Epoch Time: 21.93482\n",
            "0.14377032667143733 0.9435042735042735\n",
            "Noise Level: low Mode: target_10_val\n",
            "Train-val-test lengths:  218400 46800 46800\n",
            "Epoch  0 Loss: 3.39891e-01 Accuracy: 0.86425 Epoch Time: 21.89463\n",
            "Epoch  1 Loss: 2.34009e-01 Accuracy: 0.91090 Epoch Time: 22.18730\n",
            "Epoch  2 Loss: 2.05940e-01 Accuracy: 0.92231 Epoch Time: 21.24803\n",
            "Epoch  3 Loss: 1.89096e-01 Accuracy: 0.92974 Epoch Time: 17.68645\n",
            "Epoch  4 Loss: 1.78153e-01 Accuracy: 0.93399 Epoch Time: 17.51402\n",
            "Epoch  5 Loss: 1.70191e-01 Accuracy: 0.93758 Epoch Time: 17.89513\n",
            "Epoch  6 Loss: 1.65174e-01 Accuracy: 0.93944 Epoch Time: 17.62375\n",
            "Epoch  7 Loss: 1.61060e-01 Accuracy: 0.94050 Epoch Time: 18.43657\n",
            "Epoch  8 Loss: 1.57882e-01 Accuracy: 0.94233 Epoch Time: 18.88303\n",
            "Epoch  9 Loss: 1.53451e-01 Accuracy: 0.94431 Epoch Time: 18.35152\n",
            "Epoch 10 Loss: 1.49837e-01 Accuracy: 0.94538 Epoch Time: 18.50821\n",
            "Epoch 11 Loss: 1.46580e-01 Accuracy: 0.94667 Epoch Time: 17.51623\n",
            "Epoch 12 Loss: 1.43650e-01 Accuracy: 0.94725 Epoch Time: 18.13884\n",
            "Epoch 13 Loss: 1.41394e-01 Accuracy: 0.94850 Epoch Time: 17.77053\n",
            "Epoch 14 Loss: 1.38188e-01 Accuracy: 0.94940 Epoch Time: 18.16386\n",
            "Epoch 15 Loss: 1.36760e-01 Accuracy: 0.94974 Epoch Time: 18.05287\n",
            "Epoch 16 Loss: 1.34899e-01 Accuracy: 0.95055 Epoch Time: 17.49547\n",
            "Epoch 17 Loss: 1.33126e-01 Accuracy: 0.95102 Epoch Time: 18.00647\n",
            "Epoch 18 Loss: 1.31354e-01 Accuracy: 0.95214 Epoch Time: 17.09762\n",
            "Epoch 19 Loss: 1.30183e-01 Accuracy: 0.95234 Epoch Time: 18.33101\n",
            "Epoch 20 Loss: 1.29080e-01 Accuracy: 0.95241 Epoch Time: 18.25530\n",
            "Epoch 21 Loss: 1.27111e-01 Accuracy: 0.95327 Epoch Time: 18.16297\n",
            "Epoch 22 Loss: 1.27176e-01 Accuracy: 0.95303 Epoch Time: 17.68244\n",
            "Epoch 23 Loss: 1.26510e-01 Accuracy: 0.95337 Epoch Time: 18.07054\n",
            "Epoch 24 Loss: 1.25291e-01 Accuracy: 0.95379 Epoch Time: 17.63845\n",
            "Epoch 25 Loss: 1.24872e-01 Accuracy: 0.95370 Epoch Time: 18.06626\n",
            "Epoch 26 Loss: 1.23773e-01 Accuracy: 0.95458 Epoch Time: 18.92208\n",
            "Epoch 27 Loss: 1.23227e-01 Accuracy: 0.95432 Epoch Time: 18.26905\n",
            "Epoch 28 Loss: 1.22536e-01 Accuracy: 0.95464 Epoch Time: 17.92923\n",
            "Epoch 29 Loss: 1.22023e-01 Accuracy: 0.95482 Epoch Time: 17.85977\n",
            "Epoch 30 Loss: 1.21490e-01 Accuracy: 0.95504 Epoch Time: 18.21007\n",
            "Epoch 31 Loss: 1.20633e-01 Accuracy: 0.95533 Epoch Time: 18.04516\n",
            "Epoch 32 Loss: 1.20008e-01 Accuracy: 0.95533 Epoch Time: 18.55419\n",
            "Epoch 33 Loss: 1.19536e-01 Accuracy: 0.95583 Epoch Time: 18.49233\n",
            "Epoch 34 Loss: 1.18720e-01 Accuracy: 0.95586 Epoch Time: 17.77126\n",
            "Epoch 35 Loss: 1.18928e-01 Accuracy: 0.95601 Epoch Time: 18.09088\n",
            "Epoch 36 Loss: 1.18565e-01 Accuracy: 0.95584 Epoch Time: 18.17357\n",
            "Epoch 37 Loss: 1.18329e-01 Accuracy: 0.95609 Epoch Time: 18.06308\n",
            "Epoch 38 Loss: 1.17864e-01 Accuracy: 0.95644 Epoch Time: 18.66638\n",
            "Epoch 39 Loss: 1.17063e-01 Accuracy: 0.95640 Epoch Time: 17.81816\n",
            "Epoch 40 Loss: 1.16917e-01 Accuracy: 0.95648 Epoch Time: 19.04904\n",
            "Epoch 41 Loss: 1.16768e-01 Accuracy: 0.95640 Epoch Time: 18.28422\n",
            "Epoch 42 Loss: 1.16052e-01 Accuracy: 0.95686 Epoch Time: 17.27191\n",
            "Epoch 43 Loss: 1.15952e-01 Accuracy: 0.95658 Epoch Time: 17.88710\n",
            "Epoch 44 Loss: 1.15824e-01 Accuracy: 0.95685 Epoch Time: 18.13271\n",
            "Epoch 45 Loss: 1.14764e-01 Accuracy: 0.95712 Epoch Time: 18.22692\n",
            "Epoch 46 Loss: 1.14478e-01 Accuracy: 0.95712 Epoch Time: 17.96523\n",
            "Epoch 47 Loss: 1.14149e-01 Accuracy: 0.95750 Epoch Time: 17.72365\n",
            "Epoch 48 Loss: 1.14648e-01 Accuracy: 0.95703 Epoch Time: 18.19149\n",
            "Epoch 49 Loss: 1.13454e-01 Accuracy: 0.95760 Epoch Time: 18.07548\n",
            "0.12144435371089185 0.9539957264957265\n",
            "Noise Level: high Mode: era\n",
            "Train-val-test lengths:  174720 37440 37440\n",
            "Epoch  0 Loss: 1.78906e+00 Accuracy: 0.35757 Epoch Time: 14.58180\n",
            "Epoch  1 Loss: 1.54280e+00 Accuracy: 0.44054 Epoch Time: 14.53807\n",
            "Epoch  2 Loss: 1.47740e+00 Accuracy: 0.46360 Epoch Time: 14.99195\n",
            "Epoch  3 Loss: 1.43373e+00 Accuracy: 0.47849 Epoch Time: 14.03409\n",
            "Epoch  4 Loss: 1.40357e+00 Accuracy: 0.48729 Epoch Time: 14.04119\n",
            "Epoch  5 Loss: 1.37943e+00 Accuracy: 0.49406 Epoch Time: 15.24648\n",
            "Epoch  6 Loss: 1.36000e+00 Accuracy: 0.49965 Epoch Time: 14.90311\n",
            "Epoch  7 Loss: 1.34137e+00 Accuracy: 0.50530 Epoch Time: 14.77168\n",
            "Epoch  8 Loss: 1.32903e+00 Accuracy: 0.50849 Epoch Time: 15.90753\n",
            "Epoch  9 Loss: 1.31444e+00 Accuracy: 0.51455 Epoch Time: 14.75666\n",
            "Epoch 10 Loss: 1.30415e+00 Accuracy: 0.51807 Epoch Time: 14.62543\n",
            "Epoch 11 Loss: 1.29604e+00 Accuracy: 0.51999 Epoch Time: 14.04514\n",
            "Epoch 12 Loss: 1.28826e+00 Accuracy: 0.52265 Epoch Time: 14.54168\n",
            "Epoch 13 Loss: 1.28103e+00 Accuracy: 0.52491 Epoch Time: 14.33738\n",
            "Epoch 14 Loss: 1.27642e+00 Accuracy: 0.52578 Epoch Time: 15.04146\n",
            "Epoch 15 Loss: 1.27137e+00 Accuracy: 0.52796 Epoch Time: 14.03411\n",
            "Epoch 16 Loss: 1.26594e+00 Accuracy: 0.52936 Epoch Time: 13.90827\n",
            "Epoch 17 Loss: 1.26227e+00 Accuracy: 0.53135 Epoch Time: 14.45620\n",
            "Epoch 18 Loss: 1.25837e+00 Accuracy: 0.53223 Epoch Time: 14.20881\n",
            "Epoch 19 Loss: 1.25549e+00 Accuracy: 0.53349 Epoch Time: 14.17266\n",
            "Epoch 20 Loss: 1.25146e+00 Accuracy: 0.53483 Epoch Time: 14.34106\n",
            "Epoch 21 Loss: 1.24824e+00 Accuracy: 0.53510 Epoch Time: 14.44976\n",
            "Epoch 22 Loss: 1.24590e+00 Accuracy: 0.53751 Epoch Time: 14.54699\n",
            "Epoch 23 Loss: 1.24212e+00 Accuracy: 0.53776 Epoch Time: 13.96710\n",
            "Epoch 24 Loss: 1.24121e+00 Accuracy: 0.53725 Epoch Time: 14.04588\n",
            "Epoch 25 Loss: 1.23917e+00 Accuracy: 0.53874 Epoch Time: 13.87287\n",
            "Epoch 26 Loss: 1.23490e+00 Accuracy: 0.53937 Epoch Time: 13.98326\n",
            "Epoch 27 Loss: 1.23283e+00 Accuracy: 0.54010 Epoch Time: 13.63037\n",
            "Epoch 28 Loss: 1.23084e+00 Accuracy: 0.54056 Epoch Time: 14.37235\n",
            "Epoch 29 Loss: 1.22888e+00 Accuracy: 0.54180 Epoch Time: 14.41293\n",
            "Epoch 30 Loss: 1.22779e+00 Accuracy: 0.54180 Epoch Time: 14.49938\n",
            "Epoch 31 Loss: 1.22532e+00 Accuracy: 0.54212 Epoch Time: 13.77596\n",
            "Epoch 32 Loss: 1.22263e+00 Accuracy: 0.54378 Epoch Time: 14.11653\n",
            "Epoch 33 Loss: 1.21970e+00 Accuracy: 0.54451 Epoch Time: 14.47100\n",
            "Epoch 34 Loss: 1.21980e+00 Accuracy: 0.54473 Epoch Time: 15.00879\n",
            "Epoch 35 Loss: 1.21746e+00 Accuracy: 0.54542 Epoch Time: 13.71969\n",
            "Epoch 36 Loss: 1.21616e+00 Accuracy: 0.54654 Epoch Time: 14.30974\n",
            "Epoch 37 Loss: 1.21537e+00 Accuracy: 0.54686 Epoch Time: 14.51922\n",
            "Epoch 38 Loss: 1.21307e+00 Accuracy: 0.54716 Epoch Time: 14.75826\n",
            "Epoch 39 Loss: 1.21252e+00 Accuracy: 0.54808 Epoch Time: 13.67263\n",
            "Epoch 40 Loss: 1.21046e+00 Accuracy: 0.54805 Epoch Time: 14.33868\n",
            "Epoch 41 Loss: 1.21019e+00 Accuracy: 0.54896 Epoch Time: 13.82513\n",
            "Epoch 42 Loss: 1.20799e+00 Accuracy: 0.54894 Epoch Time: 14.15197\n",
            "Epoch 43 Loss: 1.20731e+00 Accuracy: 0.54881 Epoch Time: 14.12350\n",
            "Epoch 44 Loss: 1.20671e+00 Accuracy: 0.54983 Epoch Time: 14.72015\n",
            "Epoch 45 Loss: 1.20520e+00 Accuracy: 0.54979 Epoch Time: 14.35920\n",
            "Epoch 46 Loss: 1.20378e+00 Accuracy: 0.55093 Epoch Time: 13.86242\n",
            "Epoch 47 Loss: 1.20303e+00 Accuracy: 0.55157 Epoch Time: 14.48527\n",
            "Epoch 48 Loss: 1.20245e+00 Accuracy: 0.55135 Epoch Time: 13.85496\n",
            "Epoch 49 Loss: 1.20162e+00 Accuracy: 0.55156 Epoch Time: 14.33696\n",
            "1.2176168906383025 0.5431089743589743\n",
            "Noise Level: high Mode: target_5_val\n",
            "Train-val-test lengths:  174720 37440 37440\n",
            "Epoch  0 Loss: 4.71864e-01 Accuracy: 0.79610 Epoch Time: 14.25645\n",
            "Epoch  1 Loss: 3.97972e-01 Accuracy: 0.82853 Epoch Time: 14.26232\n",
            "Epoch  2 Loss: 3.74390e-01 Accuracy: 0.83928 Epoch Time: 14.28489\n",
            "Epoch  3 Loss: 3.59968e-01 Accuracy: 0.84457 Epoch Time: 14.69857\n",
            "Epoch  4 Loss: 3.48397e-01 Accuracy: 0.84857 Epoch Time: 13.49340\n",
            "Epoch  5 Loss: 3.41965e-01 Accuracy: 0.85110 Epoch Time: 13.84345\n",
            "Epoch  6 Loss: 3.37363e-01 Accuracy: 0.85336 Epoch Time: 14.22582\n",
            "Epoch  7 Loss: 3.33589e-01 Accuracy: 0.85448 Epoch Time: 14.66955\n",
            "Epoch  8 Loss: 3.29795e-01 Accuracy: 0.85579 Epoch Time: 14.24165\n",
            "Epoch  9 Loss: 3.26353e-01 Accuracy: 0.85734 Epoch Time: 14.48978\n",
            "Epoch 10 Loss: 3.24308e-01 Accuracy: 0.85831 Epoch Time: 13.94505\n",
            "Epoch 11 Loss: 3.21775e-01 Accuracy: 0.85915 Epoch Time: 13.88587\n",
            "Epoch 12 Loss: 3.20173e-01 Accuracy: 0.85980 Epoch Time: 13.78684\n",
            "Epoch 13 Loss: 3.18587e-01 Accuracy: 0.86034 Epoch Time: 13.62717\n",
            "Epoch 14 Loss: 3.17153e-01 Accuracy: 0.86110 Epoch Time: 13.89912\n",
            "Epoch 15 Loss: 3.15569e-01 Accuracy: 0.86162 Epoch Time: 13.63119\n",
            "Epoch 16 Loss: 3.14654e-01 Accuracy: 0.86207 Epoch Time: 13.82098\n",
            "Epoch 17 Loss: 3.12831e-01 Accuracy: 0.86293 Epoch Time: 13.86651\n",
            "Epoch 18 Loss: 3.12308e-01 Accuracy: 0.86280 Epoch Time: 14.11524\n",
            "Epoch 19 Loss: 3.10654e-01 Accuracy: 0.86353 Epoch Time: 13.98739\n",
            "Epoch 20 Loss: 3.10158e-01 Accuracy: 0.86355 Epoch Time: 13.98186\n",
            "Epoch 21 Loss: 3.09254e-01 Accuracy: 0.86449 Epoch Time: 13.86239\n",
            "Epoch 22 Loss: 3.08547e-01 Accuracy: 0.86447 Epoch Time: 13.97605\n",
            "Epoch 23 Loss: 3.07554e-01 Accuracy: 0.86488 Epoch Time: 13.97374\n",
            "Epoch 24 Loss: 3.07252e-01 Accuracy: 0.86480 Epoch Time: 14.19093\n",
            "Epoch 25 Loss: 3.06461e-01 Accuracy: 0.86588 Epoch Time: 14.01564\n",
            "Epoch 26 Loss: 3.06098e-01 Accuracy: 0.86523 Epoch Time: 14.40377\n",
            "Epoch 27 Loss: 3.05473e-01 Accuracy: 0.86620 Epoch Time: 14.38729\n",
            "Epoch 28 Loss: 3.04941e-01 Accuracy: 0.86648 Epoch Time: 14.19639\n",
            "Epoch 29 Loss: 3.04543e-01 Accuracy: 0.86639 Epoch Time: 13.76072\n",
            "Epoch 30 Loss: 3.03468e-01 Accuracy: 0.86688 Epoch Time: 14.12937\n",
            "Epoch 31 Loss: 3.03323e-01 Accuracy: 0.86690 Epoch Time: 14.35353\n",
            "Epoch 32 Loss: 3.02665e-01 Accuracy: 0.86709 Epoch Time: 13.54568\n",
            "Epoch 33 Loss: 3.02532e-01 Accuracy: 0.86716 Epoch Time: 14.14418\n",
            "Epoch 34 Loss: 3.02337e-01 Accuracy: 0.86734 Epoch Time: 13.80781\n",
            "Epoch 35 Loss: 3.02191e-01 Accuracy: 0.86730 Epoch Time: 14.46425\n",
            "Epoch 36 Loss: 3.01218e-01 Accuracy: 0.86777 Epoch Time: 13.82214\n",
            "Epoch 37 Loss: 3.01076e-01 Accuracy: 0.86807 Epoch Time: 13.63870\n",
            "Epoch 38 Loss: 3.01550e-01 Accuracy: 0.86733 Epoch Time: 13.81933\n",
            "Epoch 39 Loss: 3.00111e-01 Accuracy: 0.86809 Epoch Time: 14.86018\n",
            "Epoch 40 Loss: 3.00253e-01 Accuracy: 0.86866 Epoch Time: 13.84797\n",
            "Epoch 41 Loss: 2.99926e-01 Accuracy: 0.86828 Epoch Time: 14.30124\n",
            "Epoch 42 Loss: 2.99558e-01 Accuracy: 0.86798 Epoch Time: 13.74605\n",
            "Epoch 43 Loss: 2.99415e-01 Accuracy: 0.86875 Epoch Time: 13.98808\n",
            "Epoch 44 Loss: 2.99253e-01 Accuracy: 0.86840 Epoch Time: 14.52000\n",
            "Epoch 45 Loss: 2.99108e-01 Accuracy: 0.86856 Epoch Time: 14.74749\n",
            "Epoch 46 Loss: 2.98632e-01 Accuracy: 0.86870 Epoch Time: 14.02739\n",
            "Epoch 47 Loss: 2.98177e-01 Accuracy: 0.86909 Epoch Time: 13.70097\n",
            "Epoch 48 Loss: 2.98077e-01 Accuracy: 0.86886 Epoch Time: 13.77872\n",
            "Epoch 49 Loss: 2.97694e-01 Accuracy: 0.86928 Epoch Time: 13.96355\n",
            "0.3024562820410117 0.8661057692307692\n",
            "Noise Level: high Mode: target_10_val\n",
            "Train-val-test lengths:  174720 37440 37440\n",
            "Epoch  0 Loss: 4.31848e-01 Accuracy: 0.82054 Epoch Time: 13.94229\n",
            "Epoch  1 Loss: 3.57020e-01 Accuracy: 0.84979 Epoch Time: 13.70428\n",
            "Epoch  2 Loss: 3.39014e-01 Accuracy: 0.85675 Epoch Time: 14.17396\n",
            "Epoch  3 Loss: 3.24457e-01 Accuracy: 0.86242 Epoch Time: 14.34041\n",
            "Epoch  4 Loss: 3.16387e-01 Accuracy: 0.86580 Epoch Time: 14.32982\n",
            "Epoch  5 Loss: 3.10569e-01 Accuracy: 0.86807 Epoch Time: 14.31446\n",
            "Epoch  6 Loss: 3.05972e-01 Accuracy: 0.86985 Epoch Time: 14.06895\n",
            "Epoch  7 Loss: 3.01586e-01 Accuracy: 0.87122 Epoch Time: 14.28705\n",
            "Epoch  8 Loss: 2.98004e-01 Accuracy: 0.87301 Epoch Time: 14.43581\n",
            "Epoch  9 Loss: 2.95064e-01 Accuracy: 0.87382 Epoch Time: 13.45100\n",
            "Epoch 10 Loss: 2.92354e-01 Accuracy: 0.87556 Epoch Time: 13.60874\n",
            "Epoch 11 Loss: 2.90476e-01 Accuracy: 0.87605 Epoch Time: 14.43104\n",
            "Epoch 12 Loss: 2.89087e-01 Accuracy: 0.87657 Epoch Time: 14.89494\n",
            "Epoch 13 Loss: 2.87285e-01 Accuracy: 0.87755 Epoch Time: 13.57163\n",
            "Epoch 14 Loss: 2.85849e-01 Accuracy: 0.87810 Epoch Time: 14.25289\n",
            "Epoch 15 Loss: 2.84517e-01 Accuracy: 0.87911 Epoch Time: 13.61881\n",
            "Epoch 16 Loss: 2.83165e-01 Accuracy: 0.87916 Epoch Time: 14.48675\n",
            "Epoch 17 Loss: 2.82751e-01 Accuracy: 0.87963 Epoch Time: 14.58764\n",
            "Epoch 18 Loss: 2.81440e-01 Accuracy: 0.88039 Epoch Time: 14.46249\n",
            "Epoch 19 Loss: 2.80845e-01 Accuracy: 0.88048 Epoch Time: 14.01529\n",
            "Epoch 20 Loss: 2.79540e-01 Accuracy: 0.88084 Epoch Time: 14.28353\n",
            "Epoch 21 Loss: 2.78889e-01 Accuracy: 0.88065 Epoch Time: 13.76030\n",
            "Epoch 22 Loss: 2.77657e-01 Accuracy: 0.88103 Epoch Time: 13.68157\n",
            "Epoch 23 Loss: 2.77300e-01 Accuracy: 0.88206 Epoch Time: 14.04365\n",
            "Epoch 24 Loss: 2.76103e-01 Accuracy: 0.88219 Epoch Time: 14.12682\n",
            "Epoch 25 Loss: 2.75657e-01 Accuracy: 0.88210 Epoch Time: 14.47844\n",
            "Epoch 26 Loss: 2.74841e-01 Accuracy: 0.88233 Epoch Time: 13.71113\n",
            "Epoch 27 Loss: 2.74126e-01 Accuracy: 0.88292 Epoch Time: 14.40903\n",
            "Epoch 28 Loss: 2.73513e-01 Accuracy: 0.88364 Epoch Time: 14.18706\n",
            "Epoch 29 Loss: 2.72890e-01 Accuracy: 0.88285 Epoch Time: 14.15108\n",
            "Epoch 30 Loss: 2.73109e-01 Accuracy: 0.88350 Epoch Time: 14.26413\n",
            "Epoch 31 Loss: 2.72523e-01 Accuracy: 0.88351 Epoch Time: 14.18381\n",
            "Epoch 32 Loss: 2.71657e-01 Accuracy: 0.88378 Epoch Time: 13.75715\n",
            "Epoch 33 Loss: 2.71540e-01 Accuracy: 0.88403 Epoch Time: 14.05508\n",
            "Epoch 34 Loss: 2.70975e-01 Accuracy: 0.88436 Epoch Time: 13.99598\n",
            "Epoch 35 Loss: 2.70427e-01 Accuracy: 0.88451 Epoch Time: 13.75190\n",
            "Epoch 36 Loss: 2.70782e-01 Accuracy: 0.88437 Epoch Time: 13.78994\n",
            "Epoch 37 Loss: 2.70166e-01 Accuracy: 0.88477 Epoch Time: 13.95521\n",
            "Epoch 38 Loss: 2.69956e-01 Accuracy: 0.88537 Epoch Time: 14.15578\n",
            "Epoch 39 Loss: 2.69176e-01 Accuracy: 0.88470 Epoch Time: 13.13973\n",
            "Epoch 40 Loss: 2.68990e-01 Accuracy: 0.88531 Epoch Time: 13.90030\n",
            "Epoch 41 Loss: 2.68722e-01 Accuracy: 0.88562 Epoch Time: 14.07462\n",
            "Epoch 42 Loss: 2.68153e-01 Accuracy: 0.88534 Epoch Time: 14.27638\n",
            "Epoch 43 Loss: 2.68028e-01 Accuracy: 0.88533 Epoch Time: 14.20506\n",
            "Epoch 44 Loss: 2.67924e-01 Accuracy: 0.88531 Epoch Time: 14.02010\n",
            "Epoch 45 Loss: 2.67691e-01 Accuracy: 0.88587 Epoch Time: 13.90556\n",
            "Epoch 46 Loss: 2.67366e-01 Accuracy: 0.88558 Epoch Time: 13.82854\n",
            "Epoch 47 Loss: 2.66464e-01 Accuracy: 0.88589 Epoch Time: 13.45144\n",
            "Epoch 48 Loss: 2.66578e-01 Accuracy: 0.88602 Epoch Time: 13.14641\n",
            "Epoch 49 Loss: 2.66267e-01 Accuracy: 0.88570 Epoch Time: 13.57606\n",
            "0.28222252377587503 0.8773771367521368\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "df_paths = ['./df_syn_train_0_0_.csv',\n",
        "            './df_synA_train_shuffled.csv',\n",
        "            './df_synA_test_hard_shuffled_sample.csv']\n",
        "\n",
        "noise_levels = ['none', 'low', 'high']\n",
        "batch_sizes = [32, 128, 128]\n",
        "\n",
        "losses_arr = []\n",
        "accs_arr = []\n",
        "\n",
        "for i in range(0, 3):\n",
        "    df = pd.read_csv(df_paths[i])\n",
        "\n",
        "    modes = ['era', 'target_5_val', 'target_10_val']\n",
        "\n",
        "    loss_per_mode = []\n",
        "    acc_per_mode = []\n",
        "\n",
        "    for mode in modes:\n",
        "        print(\"Noise Level:\", noise_levels[i], \"Mode:\", mode)\n",
        "        loader_train, loader_val, loader_test, data = make_data_splits(df, mode=mode, \\\n",
        "                                                                       batch_size=batch_sizes[i])\n",
        "        net = MLP(dims=[data.X.shape[1], 32, 64, 32, len(data.y.unique())]).to(device)\n",
        "        net, losses, accs, val_losses, val_accL = Train(net, loader_train, mode, noise_levels[i], \\\n",
        "                                      epochs=50, verbose=True, device=device, val_ds=loader_val, \\\n",
        "                                      plot_accs=True, plot_losses=True)\n",
        "        plot_loss_acc(losses, accs, val_losses, val_accL, mode, noise_levels[i])\n",
        "        #Testing code\n",
        "        test_loss, test_acc = Test(net, loader_test, mode, noise_levels[i], device=device)\n",
        "        print(test_loss, test_acc)\n",
        "        loss_per_mode.append(test_loss)\n",
        "        acc_per_mode.append(test_acc)\n",
        "\n",
        "    losses_arr.append(loss_per_mode)\n",
        "    accs_arr.append(acc_per_mode)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "aQ3F_j9-SCUT"
      },
      "outputs": [],
      "source": [
        "with open(f'{prefix}/losses_dump.pkl', 'wb') as f:\n",
        "    pkl.dump(losses_arr, f)\n",
        "\n",
        "with open(f'{prefix}/accs_dump.pkl', 'wb') as f:\n",
        "    pkl.dump(accs_arr, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.8905982905982905, 0.958974358974359, 0.9777777777777777], [0.7842948717948718, 0.9435042735042735, 0.9539957264957265], [0.5431089743589743, 0.8661057692307692, 0.8773771367521368]]\n"
          ]
        }
      ],
      "source": [
        "import pickle as pkl\n",
        "prefix = './data_dump_base_model_final'\n",
        "with open(f'{prefix}/accs_dump.pkl', 'rb') as f:\n",
        "    accs = pkl.load(f)\n",
        "\n",
        "print(accs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cL3y7PzHYGg1"
      },
      "source": [
        "#Autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "prefix = './data_dump_ae_blah_blah'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Afxdqjp7gvUS"
      },
      "outputs": [],
      "source": [
        "def TrainAE(Net, data, mode, noise_level, epochs=20, lr=5e-2, Loss=nn.MSELoss(reduction='sum'), verbose=False, device='cpu',\n",
        "          val_ds=None, plot_accs=False, plot_losses=False):\n",
        "    model_save_time = time.time()\n",
        "    losses = []\n",
        "    Net.to(device)\n",
        "    for e in range(epochs):\n",
        "        Net.train()\n",
        "        step=0\n",
        "        tot_loss=0.0\n",
        "        start_time = time.time()\n",
        "        total_samples = 0\n",
        "        for (X,_) in data:\n",
        "            X=X.to(device)\n",
        "            # y=y.to(device)\n",
        "            total_samples += X.shape[0]\n",
        "            X_pred = Net(X)\n",
        "            loss = Loss(X_pred,X)\n",
        "            Net.optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            Net.optimizer.step()\n",
        "            step+=1\n",
        "            tot_loss+=loss\n",
        "        end_time = time.time()\n",
        "        t = end_time-start_time\n",
        "        l = tot_loss.item()/total_samples\n",
        "        losses += [l]\n",
        "        if verbose:\n",
        "            print('Epoch %2d Loss: %2.5e Epoch Time: %2.5f' %(e,l,t))\n",
        "\n",
        "        # val_loss, val_acc = Test(Net, val_ds, mode, noise_level, device)\n",
        "        # val_losses.append(val_loss)\n",
        "        # val_accL.append(val_acc)\n",
        "\n",
        "        # Net.eval()\n",
        "        # if plot_accs and val_ds is not None:\n",
        "        #     val_total_samples = 0\n",
        "        #     val_correct_samples = 0\n",
        "        #     for (X, y) in val_ds:\n",
        "        #       X=X.to(device)\n",
        "        #       y=y.to(device)\n",
        "        #       val_total_samples += y.shape[0]\n",
        "        #       _, i_val_cor_sam = accuracy(Net,X,y,verbose=False)\n",
        "        #       val_correct_samples += i_val_cor_sam\n",
        "        #     val_accL+=[val_correct_samples / val_total_samples]\n",
        "        #     plt.plot(np.array(val_accL),color='red')\n",
        "        #     plt.plot(np.array(accs),color='blue')\n",
        "        #     plt.show()\n",
        "\n",
        "        # if plot_losses and val_ds is not None:\n",
        "        #     val_loss_ = 0.0\n",
        "        #     val_total_samples = 0\n",
        "        #     for (X, y) in val_ds:\n",
        "        #       X=X.to(device)\n",
        "        #       y=y.to(device)\n",
        "        #       val_total_samples += y.shape[0]\n",
        "        #       val_loss_ += Loss(Net(X), y).cpu().detach().item()\n",
        "        #     val_losses+=[val_loss_/val_total_samples]\n",
        "        #     plt.plot(val_losses,color='red')\n",
        "        #     plt.plot(losses,color='blue')\n",
        "        #     plt.show()\n",
        "\n",
        "        torch.save(Net.state_dict(), f'{prefix}/net_{noise_level}_{mode}_reconstruct_{str(model_save_time)}.pth')\n",
        "\n",
        "    return Net, losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "VX8JxE6BYFUI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Noise Level: none Mode: era\n",
            "Train-val-test lengths:  5460 1170 1170\n",
            "Epoch  0 Loss: 5.62660e+00 Epoch Time: 0.95866\n",
            "Epoch  1 Loss: 3.55029e+00 Epoch Time: 0.71744\n",
            "Epoch  2 Loss: 2.25734e+00 Epoch Time: 0.62803\n",
            "Epoch  3 Loss: 2.11508e+00 Epoch Time: 0.70420\n",
            "Epoch  4 Loss: 1.88376e+00 Epoch Time: 0.74730\n",
            "Epoch  5 Loss: 1.28300e+00 Epoch Time: 0.58061\n",
            "Epoch  6 Loss: 9.79425e-01 Epoch Time: 0.69170\n",
            "Epoch  7 Loss: 8.19846e-01 Epoch Time: 0.81685\n",
            "Epoch  8 Loss: 7.70835e-01 Epoch Time: 0.62797\n",
            "Epoch  9 Loss: 7.45339e-01 Epoch Time: 0.58923\n",
            "Epoch 10 Loss: 7.27404e-01 Epoch Time: 0.70169\n",
            "Epoch 11 Loss: 7.17441e-01 Epoch Time: 0.69788\n",
            "Epoch 12 Loss: 7.09264e-01 Epoch Time: 0.67018\n",
            "Epoch 13 Loss: 3.72412e-01 Epoch Time: 0.77186\n",
            "Epoch 14 Loss: 3.07668e-01 Epoch Time: 0.68602\n",
            "Epoch 15 Loss: 3.01338e-01 Epoch Time: 0.58833\n",
            "Epoch 16 Loss: 2.97274e-01 Epoch Time: 0.64025\n",
            "Epoch 17 Loss: 2.92194e-01 Epoch Time: 0.82539\n",
            "Epoch 18 Loss: 2.88840e-01 Epoch Time: 0.58713\n",
            "Epoch 19 Loss: 2.85010e-01 Epoch Time: 0.67440\n",
            "Epoch 20 Loss: 2.81361e-01 Epoch Time: 0.68292\n",
            "Epoch 21 Loss: 2.79617e-01 Epoch Time: 0.74114\n",
            "Epoch 22 Loss: 2.78088e-01 Epoch Time: 0.56874\n",
            "Epoch 23 Loss: 2.74679e-01 Epoch Time: 0.64793\n",
            "Epoch 24 Loss: 2.72177e-01 Epoch Time: 0.71489\n",
            "Epoch 25 Loss: 2.68567e-01 Epoch Time: 0.58400\n",
            "Epoch 26 Loss: 2.65536e-01 Epoch Time: 0.61435\n",
            "Epoch 27 Loss: 2.63720e-01 Epoch Time: 0.67677\n",
            "Epoch 28 Loss: 2.60412e-01 Epoch Time: 0.70357\n",
            "Epoch 29 Loss: 2.57857e-01 Epoch Time: 0.57610\n",
            "Epoch 30 Loss: 2.56863e-01 Epoch Time: 0.67336\n",
            "Epoch 31 Loss: 2.53115e-01 Epoch Time: 0.70120\n",
            "Epoch 32 Loss: 2.51470e-01 Epoch Time: 0.64986\n",
            "Epoch 33 Loss: 2.49510e-01 Epoch Time: 0.64623\n",
            "Epoch 34 Loss: 2.46898e-01 Epoch Time: 0.61705\n",
            "Epoch 35 Loss: 2.45530e-01 Epoch Time: 0.70582\n",
            "Epoch 36 Loss: 2.41971e-01 Epoch Time: 0.69617\n",
            "Epoch 37 Loss: 2.39041e-01 Epoch Time: 0.64267\n",
            "Epoch 38 Loss: 2.38813e-01 Epoch Time: 0.67455\n",
            "Epoch 39 Loss: 2.37629e-01 Epoch Time: 0.71584\n",
            "Epoch 40 Loss: 2.35201e-01 Epoch Time: 0.69752\n",
            "Epoch 41 Loss: 2.34665e-01 Epoch Time: 0.70026\n",
            "Epoch 42 Loss: 2.32471e-01 Epoch Time: 0.64902\n",
            "Epoch 43 Loss: 2.31611e-01 Epoch Time: 0.73472\n",
            "Epoch 44 Loss: 2.30832e-01 Epoch Time: 0.66117\n",
            "Epoch 45 Loss: 2.31515e-01 Epoch Time: 0.59172\n",
            "Epoch 46 Loss: 2.27631e-01 Epoch Time: 0.67371\n",
            "Epoch 47 Loss: 2.26380e-01 Epoch Time: 0.64745\n",
            "Epoch 48 Loss: 2.25519e-01 Epoch Time: 0.61468\n",
            "Epoch 49 Loss: 2.25047e-01 Epoch Time: 0.60578\n",
            "Epoch 50 Loss: 2.25157e-01 Epoch Time: 0.64727\n",
            "Epoch 51 Loss: 2.24406e-01 Epoch Time: 0.61888\n",
            "Epoch 52 Loss: 2.22886e-01 Epoch Time: 0.60588\n",
            "Epoch 53 Loss: 2.22914e-01 Epoch Time: 0.78051\n",
            "Epoch 54 Loss: 2.22098e-01 Epoch Time: 0.59539\n",
            "Epoch 55 Loss: 2.19790e-01 Epoch Time: 0.68836\n",
            "Epoch 56 Loss: 2.19529e-01 Epoch Time: 0.58154\n",
            "Epoch 57 Loss: 2.20290e-01 Epoch Time: 0.72423\n",
            "Epoch 58 Loss: 2.17053e-01 Epoch Time: 0.69275\n",
            "Epoch 59 Loss: 2.16578e-01 Epoch Time: 0.75209\n",
            "Epoch 60 Loss: 2.15529e-01 Epoch Time: 0.55187\n",
            "Epoch 61 Loss: 2.15835e-01 Epoch Time: 0.73044\n",
            "Epoch 62 Loss: 2.17217e-01 Epoch Time: 0.68904\n",
            "Epoch 63 Loss: 2.14547e-01 Epoch Time: 0.67296\n",
            "Epoch 64 Loss: 2.14732e-01 Epoch Time: 0.65950\n",
            "Epoch 65 Loss: 2.12518e-01 Epoch Time: 0.69543\n",
            "Epoch 66 Loss: 2.12197e-01 Epoch Time: 0.58658\n",
            "Epoch 67 Loss: 2.11761e-01 Epoch Time: 0.57121\n",
            "Epoch 68 Loss: 2.11373e-01 Epoch Time: 0.77744\n",
            "Epoch 69 Loss: 2.11560e-01 Epoch Time: 0.63376\n",
            "Epoch 70 Loss: 2.10776e-01 Epoch Time: 0.58656\n",
            "Epoch 71 Loss: 2.08962e-01 Epoch Time: 0.70030\n",
            "Epoch 72 Loss: 2.09124e-01 Epoch Time: 0.64578\n",
            "Epoch 73 Loss: 2.08434e-01 Epoch Time: 0.60741\n",
            "Epoch 74 Loss: 2.07969e-01 Epoch Time: 0.59108\n",
            "Epoch 75 Loss: 2.07074e-01 Epoch Time: 0.68686\n",
            "Epoch 76 Loss: 2.06170e-01 Epoch Time: 0.56945\n",
            "Epoch 77 Loss: 2.07652e-01 Epoch Time: 0.64643\n",
            "Epoch 78 Loss: 2.05745e-01 Epoch Time: 0.79127\n",
            "Epoch 79 Loss: 2.03733e-01 Epoch Time: 0.56366\n",
            "Epoch 80 Loss: 2.06439e-01 Epoch Time: 0.61256\n",
            "Epoch 81 Loss: 2.05335e-01 Epoch Time: 0.68036\n",
            "Epoch 82 Loss: 2.04358e-01 Epoch Time: 0.69832\n",
            "Epoch 83 Loss: 2.04424e-01 Epoch Time: 0.57962\n",
            "Epoch 84 Loss: 2.04206e-01 Epoch Time: 0.64715\n",
            "Epoch 85 Loss: 2.01707e-01 Epoch Time: 0.78818\n",
            "Epoch 86 Loss: 2.02505e-01 Epoch Time: 0.62112\n",
            "Epoch 87 Loss: 2.03730e-01 Epoch Time: 0.60027\n",
            "Epoch 88 Loss: 2.02629e-01 Epoch Time: 0.68446\n",
            "Epoch 89 Loss: 2.01437e-01 Epoch Time: 0.67814\n",
            "Epoch 90 Loss: 2.01772e-01 Epoch Time: 0.56877\n",
            "Epoch 91 Loss: 2.00869e-01 Epoch Time: 0.67801\n",
            "Epoch 92 Loss: 1.99399e-01 Epoch Time: 0.75202\n",
            "Epoch 93 Loss: 1.99714e-01 Epoch Time: 0.61537\n",
            "Epoch 94 Loss: 1.98481e-01 Epoch Time: 0.56879\n",
            "Epoch 95 Loss: 1.98390e-01 Epoch Time: 0.69932\n",
            "Epoch 96 Loss: 1.98085e-01 Epoch Time: 0.68361\n",
            "Epoch 97 Loss: 1.97280e-01 Epoch Time: 0.58147\n",
            "Epoch 98 Loss: 1.98110e-01 Epoch Time: 0.63364\n",
            "Epoch 99 Loss: 1.97781e-01 Epoch Time: 0.76554\n",
            "Epoch  0 Loss: 2.70265e+00 Accuracy: 0.05806 Epoch Time: 0.73207\n",
            "Epoch  1 Loss: 2.54792e+00 Accuracy: 0.10018 Epoch Time: 0.88924\n",
            "Epoch  2 Loss: 2.50380e+00 Accuracy: 0.15055 Epoch Time: 0.82122\n",
            "Epoch  3 Loss: 2.47170e+00 Accuracy: 0.19377 Epoch Time: 0.71775\n",
            "Epoch  4 Loss: 2.44697e+00 Accuracy: 0.20989 Epoch Time: 1.02446\n",
            "Epoch  5 Loss: 2.42959e+00 Accuracy: 0.20385 Epoch Time: 0.74410\n",
            "Epoch  6 Loss: 2.41596e+00 Accuracy: 0.20403 Epoch Time: 1.08030\n",
            "Epoch  7 Loss: 2.40466e+00 Accuracy: 0.20623 Epoch Time: 0.72948\n",
            "Epoch  8 Loss: 2.39643e+00 Accuracy: 0.20659 Epoch Time: 0.95376\n",
            "Epoch  9 Loss: 2.38956e+00 Accuracy: 0.20659 Epoch Time: 0.81513\n",
            "Epoch 10 Loss: 2.38400e+00 Accuracy: 0.21026 Epoch Time: 0.95396\n",
            "Epoch 11 Loss: 2.37962e+00 Accuracy: 0.20678 Epoch Time: 0.81501\n",
            "Epoch 12 Loss: 2.37542e+00 Accuracy: 0.20879 Epoch Time: 0.97792\n",
            "Epoch 13 Loss: 2.37131e+00 Accuracy: 0.21044 Epoch Time: 0.85202\n",
            "Epoch 14 Loss: 2.36843e+00 Accuracy: 0.21136 Epoch Time: 0.89741\n",
            "Epoch 15 Loss: 2.36551e+00 Accuracy: 0.20916 Epoch Time: 0.98957\n",
            "Epoch 16 Loss: 2.36259e+00 Accuracy: 0.20769 Epoch Time: 0.90160\n",
            "Epoch 17 Loss: 2.35952e+00 Accuracy: 0.21300 Epoch Time: 0.73845\n",
            "Epoch 18 Loss: 2.35696e+00 Accuracy: 0.20989 Epoch Time: 0.74157\n",
            "Epoch 19 Loss: 2.35526e+00 Accuracy: 0.21099 Epoch Time: 1.02486\n",
            "2.376859172592815 0.19914529914529913\n",
            "Noise Level: none Mode: target_5_val\n",
            "Train-val-test lengths:  5460 1170 1170\n",
            "Epoch  0 Loss: 5.13764e+00 Epoch Time: 0.67118\n",
            "Epoch  1 Loss: 3.69910e+00 Epoch Time: 0.82443\n",
            "Epoch  2 Loss: 2.88112e+00 Epoch Time: 0.60738\n",
            "Epoch  3 Loss: 2.34123e+00 Epoch Time: 0.57127\n",
            "Epoch  4 Loss: 2.27355e+00 Epoch Time: 0.75557\n",
            "Epoch  5 Loss: 2.12812e+00 Epoch Time: 0.61406\n",
            "Epoch  6 Loss: 6.84486e-01 Epoch Time: 0.56648\n",
            "Epoch  7 Loss: 4.16748e-01 Epoch Time: 0.82576\n",
            "Epoch  8 Loss: 3.69415e-01 Epoch Time: 0.67060\n",
            "Epoch  9 Loss: 3.30918e-01 Epoch Time: 0.64088\n",
            "Epoch 10 Loss: 3.00741e-01 Epoch Time: 0.62000\n",
            "Epoch 11 Loss: 2.80913e-01 Epoch Time: 0.73534\n",
            "Epoch 12 Loss: 2.66357e-01 Epoch Time: 0.60752\n",
            "Epoch 13 Loss: 2.56370e-01 Epoch Time: 0.59573\n",
            "Epoch 14 Loss: 2.48813e-01 Epoch Time: 0.72484\n",
            "Epoch 15 Loss: 2.42169e-01 Epoch Time: 0.73234\n",
            "Epoch 16 Loss: 2.36154e-01 Epoch Time: 0.59448\n",
            "Epoch 17 Loss: 2.31779e-01 Epoch Time: 0.68116\n",
            "Epoch 18 Loss: 2.26087e-01 Epoch Time: 0.72279\n",
            "Epoch 19 Loss: 2.23554e-01 Epoch Time: 0.61758\n",
            "Epoch 20 Loss: 2.19479e-01 Epoch Time: 0.71460\n",
            "Epoch 21 Loss: 2.15798e-01 Epoch Time: 0.67113\n",
            "Epoch 22 Loss: 2.14470e-01 Epoch Time: 0.64687\n",
            "Epoch 23 Loss: 2.11898e-01 Epoch Time: 0.65050\n",
            "Epoch 24 Loss: 2.08204e-01 Epoch Time: 0.69957\n",
            "Epoch 25 Loss: 2.05706e-01 Epoch Time: 0.68944\n",
            "Epoch 26 Loss: 2.03930e-01 Epoch Time: 0.66800\n",
            "Epoch 27 Loss: 2.02747e-01 Epoch Time: 0.76926\n",
            "Epoch 28 Loss: 1.99208e-01 Epoch Time: 0.60980\n",
            "Epoch 29 Loss: 1.97444e-01 Epoch Time: 0.77345\n",
            "Epoch 30 Loss: 1.96015e-01 Epoch Time: 0.65691\n",
            "Epoch 31 Loss: 1.93718e-01 Epoch Time: 0.63491\n",
            "Epoch 32 Loss: 1.91588e-01 Epoch Time: 0.66851\n",
            "Epoch 33 Loss: 1.91423e-01 Epoch Time: 0.80126\n",
            "Epoch 34 Loss: 1.89170e-01 Epoch Time: 0.60232\n",
            "Epoch 35 Loss: 1.87069e-01 Epoch Time: 0.59489\n",
            "Epoch 36 Loss: 1.86605e-01 Epoch Time: 0.70520\n",
            "Epoch 37 Loss: 1.85698e-01 Epoch Time: 0.73061\n",
            "Epoch 38 Loss: 1.84098e-01 Epoch Time: 0.58388\n",
            "Epoch 39 Loss: 1.83951e-01 Epoch Time: 0.76043\n",
            "Epoch 40 Loss: 1.82434e-01 Epoch Time: 0.71564\n",
            "Epoch 41 Loss: 1.81829e-01 Epoch Time: 0.68480\n",
            "Epoch 42 Loss: 1.80342e-01 Epoch Time: 0.55568\n",
            "Epoch 43 Loss: 1.79854e-01 Epoch Time: 0.76848\n",
            "Epoch 44 Loss: 1.79074e-01 Epoch Time: 0.70867\n",
            "Epoch 45 Loss: 1.77584e-01 Epoch Time: 0.62110\n",
            "Epoch 46 Loss: 1.77432e-01 Epoch Time: 0.71621\n",
            "Epoch 47 Loss: 1.75533e-01 Epoch Time: 0.61234\n",
            "Epoch 48 Loss: 1.75157e-01 Epoch Time: 0.65037\n",
            "Epoch 49 Loss: 1.74396e-01 Epoch Time: 0.63059\n",
            "Epoch 50 Loss: 1.73465e-01 Epoch Time: 0.70301\n",
            "Epoch 51 Loss: 1.72508e-01 Epoch Time: 0.72225\n",
            "Epoch 52 Loss: 1.71781e-01 Epoch Time: 0.76871\n",
            "Epoch 53 Loss: 1.70126e-01 Epoch Time: 0.59988\n",
            "Epoch 54 Loss: 1.68279e-01 Epoch Time: 0.64442\n",
            "Epoch 55 Loss: 1.67454e-01 Epoch Time: 0.63059\n",
            "Epoch 56 Loss: 1.65834e-01 Epoch Time: 0.72025\n",
            "Epoch 57 Loss: 1.63961e-01 Epoch Time: 0.66841\n",
            "Epoch 58 Loss: 1.61847e-01 Epoch Time: 0.66454\n",
            "Epoch 59 Loss: 1.61004e-01 Epoch Time: 0.72394\n",
            "Epoch 60 Loss: 1.59346e-01 Epoch Time: 0.60393\n",
            "Epoch 61 Loss: 1.56667e-01 Epoch Time: 0.77329\n",
            "Epoch 62 Loss: 1.55549e-01 Epoch Time: 0.56548\n",
            "Epoch 63 Loss: 1.53520e-01 Epoch Time: 0.67024\n",
            "Epoch 64 Loss: 1.52866e-01 Epoch Time: 0.69241\n",
            "Epoch 65 Loss: 1.51359e-01 Epoch Time: 0.69293\n",
            "Epoch 66 Loss: 1.50682e-01 Epoch Time: 0.67843\n",
            "Epoch 67 Loss: 1.49429e-01 Epoch Time: 0.67988\n",
            "Epoch 68 Loss: 1.48249e-01 Epoch Time: 0.63960\n",
            "Epoch 69 Loss: 1.48373e-01 Epoch Time: 0.77470\n",
            "Epoch 70 Loss: 1.46754e-01 Epoch Time: 0.60402\n",
            "Epoch 71 Loss: 1.47350e-01 Epoch Time: 0.60936\n",
            "Epoch 72 Loss: 1.46138e-01 Epoch Time: 0.70720\n",
            "Epoch 73 Loss: 1.45177e-01 Epoch Time: 0.70197\n",
            "Epoch 74 Loss: 1.45349e-01 Epoch Time: 0.56124\n",
            "Epoch 75 Loss: 1.44530e-01 Epoch Time: 0.71853\n",
            "Epoch 76 Loss: 1.43761e-01 Epoch Time: 0.73681\n",
            "Epoch 77 Loss: 1.43522e-01 Epoch Time: 0.60555\n",
            "Epoch 78 Loss: 1.43344e-01 Epoch Time: 0.67744\n",
            "Epoch 79 Loss: 1.42582e-01 Epoch Time: 0.61433\n",
            "Epoch 80 Loss: 1.42610e-01 Epoch Time: 0.69425\n",
            "Epoch 81 Loss: 1.41799e-01 Epoch Time: 0.58230\n",
            "Epoch 82 Loss: 1.41737e-01 Epoch Time: 0.74208\n",
            "Epoch 83 Loss: 1.40868e-01 Epoch Time: 0.63379\n",
            "Epoch 84 Loss: 1.42258e-01 Epoch Time: 0.62836\n",
            "Epoch 85 Loss: 1.40983e-01 Epoch Time: 0.83262\n",
            "Epoch 86 Loss: 1.40657e-01 Epoch Time: 0.69447\n",
            "Epoch 87 Loss: 1.40314e-01 Epoch Time: 0.61004\n",
            "Epoch 88 Loss: 1.39411e-01 Epoch Time: 0.65561\n",
            "Epoch 89 Loss: 1.39511e-01 Epoch Time: 0.72820\n",
            "Epoch 90 Loss: 1.38866e-01 Epoch Time: 0.62375\n",
            "Epoch 91 Loss: 1.38287e-01 Epoch Time: 0.79980\n",
            "Epoch 92 Loss: 1.38221e-01 Epoch Time: 0.64129\n",
            "Epoch 93 Loss: 1.38743e-01 Epoch Time: 0.68256\n",
            "Epoch 94 Loss: 1.38382e-01 Epoch Time: 0.62792\n",
            "Epoch 95 Loss: 1.37733e-01 Epoch Time: 0.68180\n",
            "Epoch 96 Loss: 1.37889e-01 Epoch Time: 0.75657\n",
            "Epoch 97 Loss: 1.37280e-01 Epoch Time: 0.68026\n",
            "Epoch 98 Loss: 1.36900e-01 Epoch Time: 0.54630\n",
            "Epoch 99 Loss: 1.36337e-01 Epoch Time: 0.68643\n",
            "Epoch  0 Loss: 1.35958e+00 Accuracy: 0.55220 Epoch Time: 0.89290\n",
            "Epoch  1 Loss: 6.84799e-01 Accuracy: 0.75366 Epoch Time: 0.77930\n",
            "Epoch  2 Loss: 5.71969e-01 Accuracy: 0.75366 Epoch Time: 0.98067\n",
            "Epoch  3 Loss: 5.14653e-01 Accuracy: 0.76190 Epoch Time: 0.74789\n",
            "Epoch  4 Loss: 4.80259e-01 Accuracy: 0.79579 Epoch Time: 1.05054\n",
            "Epoch  5 Loss: 4.58095e-01 Accuracy: 0.81264 Epoch Time: 0.70140\n",
            "Epoch  6 Loss: 4.42356e-01 Accuracy: 0.82747 Epoch Time: 0.91787\n",
            "Epoch  7 Loss: 4.30652e-01 Accuracy: 0.83004 Epoch Time: 0.72296\n",
            "Epoch  8 Loss: 4.22030e-01 Accuracy: 0.83938 Epoch Time: 0.83352\n",
            "Epoch  9 Loss: 4.14475e-01 Accuracy: 0.83755 Epoch Time: 0.79768\n",
            "Epoch 10 Loss: 4.08328e-01 Accuracy: 0.84212 Epoch Time: 1.06466\n",
            "Epoch 11 Loss: 4.03643e-01 Accuracy: 0.84139 Epoch Time: 0.72528\n",
            "Epoch 12 Loss: 3.99055e-01 Accuracy: 0.84304 Epoch Time: 1.01287\n",
            "Epoch 13 Loss: 3.95255e-01 Accuracy: 0.84451 Epoch Time: 0.80368\n",
            "Epoch 14 Loss: 3.92000e-01 Accuracy: 0.84579 Epoch Time: 0.82119\n",
            "Epoch 15 Loss: 3.89053e-01 Accuracy: 0.84707 Epoch Time: 0.76060\n",
            "Epoch 16 Loss: 3.86489e-01 Accuracy: 0.84725 Epoch Time: 0.85806\n",
            "Epoch 17 Loss: 3.84954e-01 Accuracy: 0.84853 Epoch Time: 0.88544\n",
            "Epoch 18 Loss: 3.82268e-01 Accuracy: 0.84945 Epoch Time: 0.78103\n",
            "Epoch 19 Loss: 3.80783e-01 Accuracy: 0.84817 Epoch Time: 1.01852\n",
            "0.35908643119355554 0.8538461538461538\n",
            "Noise Level: none Mode: target_10_val\n",
            "Train-val-test lengths:  5460 1170 1170\n",
            "Epoch  0 Loss: 4.24545e+00 Epoch Time: 0.67162\n",
            "Epoch  1 Loss: 1.87293e+00 Epoch Time: 0.66648\n",
            "Epoch  2 Loss: 1.43259e+00 Epoch Time: 0.57373\n",
            "Epoch  3 Loss: 1.32376e+00 Epoch Time: 0.63324\n",
            "Epoch  4 Loss: 1.25894e+00 Epoch Time: 0.76312\n",
            "Epoch  5 Loss: 1.11013e+00 Epoch Time: 0.55440\n",
            "Epoch  6 Loss: 6.82780e-01 Epoch Time: 0.63527\n",
            "Epoch  7 Loss: 4.24896e-01 Epoch Time: 0.68190\n",
            "Epoch  8 Loss: 3.82074e-01 Epoch Time: 0.63997\n",
            "Epoch  9 Loss: 3.46196e-01 Epoch Time: 0.58945\n",
            "Epoch 10 Loss: 3.08721e-01 Epoch Time: 0.66746\n",
            "Epoch 11 Loss: 2.87110e-01 Epoch Time: 0.83271\n",
            "Epoch 12 Loss: 2.73721e-01 Epoch Time: 0.59250\n",
            "Epoch 13 Loss: 2.64360e-01 Epoch Time: 0.62511\n",
            "Epoch 14 Loss: 2.57513e-01 Epoch Time: 0.69148\n",
            "Epoch 15 Loss: 2.52171e-01 Epoch Time: 0.68453\n",
            "Epoch 16 Loss: 2.46877e-01 Epoch Time: 0.57035\n",
            "Epoch 17 Loss: 2.43308e-01 Epoch Time: 0.82335\n",
            "Epoch 18 Loss: 2.40793e-01 Epoch Time: 0.67143\n",
            "Epoch 19 Loss: 2.36901e-01 Epoch Time: 0.61658\n",
            "Epoch 20 Loss: 2.33770e-01 Epoch Time: 0.63453\n",
            "Epoch 21 Loss: 2.31104e-01 Epoch Time: 0.70234\n",
            "Epoch 22 Loss: 2.28754e-01 Epoch Time: 0.63554\n",
            "Epoch 23 Loss: 2.24850e-01 Epoch Time: 0.89202\n",
            "Epoch 24 Loss: 2.23423e-01 Epoch Time: 0.78696\n",
            "Epoch 25 Loss: 2.19235e-01 Epoch Time: 0.61187\n",
            "Epoch 26 Loss: 2.15986e-01 Epoch Time: 0.73921\n",
            "Epoch 27 Loss: 2.12164e-01 Epoch Time: 0.72713\n",
            "Epoch 28 Loss: 2.06299e-01 Epoch Time: 0.64860\n",
            "Epoch 29 Loss: 2.00106e-01 Epoch Time: 0.76875\n",
            "Epoch 30 Loss: 1.94091e-01 Epoch Time: 0.76184\n",
            "Epoch 31 Loss: 1.86995e-01 Epoch Time: 0.66048\n",
            "Epoch 32 Loss: 1.80287e-01 Epoch Time: 0.75663\n",
            "Epoch 33 Loss: 1.72754e-01 Epoch Time: 0.71221\n",
            "Epoch 34 Loss: 1.66707e-01 Epoch Time: 0.64653\n",
            "Epoch 35 Loss: 1.61728e-01 Epoch Time: 0.86787\n",
            "Epoch 36 Loss: 1.57453e-01 Epoch Time: 0.64253\n",
            "Epoch 37 Loss: 1.53779e-01 Epoch Time: 0.66251\n",
            "Epoch 38 Loss: 1.51769e-01 Epoch Time: 0.76102\n",
            "Epoch 39 Loss: 1.50123e-01 Epoch Time: 0.63260\n",
            "Epoch 40 Loss: 1.48714e-01 Epoch Time: 0.67901\n",
            "Epoch 41 Loss: 1.46225e-01 Epoch Time: 0.81263\n",
            "Epoch 42 Loss: 1.43948e-01 Epoch Time: 0.65704\n",
            "Epoch 43 Loss: 1.42665e-01 Epoch Time: 0.65198\n",
            "Epoch 44 Loss: 1.40787e-01 Epoch Time: 0.67691\n",
            "Epoch 45 Loss: 1.41030e-01 Epoch Time: 0.60487\n",
            "Epoch 46 Loss: 1.39914e-01 Epoch Time: 0.66605\n",
            "Epoch 47 Loss: 1.38368e-01 Epoch Time: 0.65839\n",
            "Epoch 48 Loss: 1.38253e-01 Epoch Time: 0.58935\n",
            "Epoch 49 Loss: 1.36537e-01 Epoch Time: 0.60094\n",
            "Epoch 50 Loss: 1.35605e-01 Epoch Time: 0.74996\n",
            "Epoch 51 Loss: 1.35657e-01 Epoch Time: 0.56026\n",
            "Epoch 52 Loss: 1.33964e-01 Epoch Time: 0.62770\n",
            "Epoch 53 Loss: 1.33241e-01 Epoch Time: 0.76059\n",
            "Epoch 54 Loss: 1.33000e-01 Epoch Time: 0.73691\n",
            "Epoch 55 Loss: 1.32621e-01 Epoch Time: 0.57467\n",
            "Epoch 56 Loss: 1.32062e-01 Epoch Time: 0.63708\n",
            "Epoch 57 Loss: 1.31191e-01 Epoch Time: 0.73534\n",
            "Epoch 58 Loss: 1.30303e-01 Epoch Time: 0.60920\n",
            "Epoch 59 Loss: 1.29750e-01 Epoch Time: 0.57805\n",
            "Epoch 60 Loss: 1.29702e-01 Epoch Time: 0.77362\n",
            "Epoch 61 Loss: 1.29784e-01 Epoch Time: 0.70343\n",
            "Epoch 62 Loss: 1.29018e-01 Epoch Time: 0.61847\n",
            "Epoch 63 Loss: 1.27666e-01 Epoch Time: 0.62419\n",
            "Epoch 64 Loss: 1.28085e-01 Epoch Time: 0.76598\n",
            "Epoch 65 Loss: 1.26976e-01 Epoch Time: 0.63723\n",
            "Epoch 66 Loss: 1.26262e-01 Epoch Time: 0.68832\n",
            "Epoch 67 Loss: 1.26353e-01 Epoch Time: 0.85219\n",
            "Epoch 68 Loss: 1.25649e-01 Epoch Time: 0.58825\n",
            "Epoch 69 Loss: 1.26001e-01 Epoch Time: 0.57882\n",
            "Epoch 70 Loss: 1.25127e-01 Epoch Time: 0.71470\n",
            "Epoch 71 Loss: 1.23876e-01 Epoch Time: 0.61574\n",
            "Epoch 72 Loss: 1.23455e-01 Epoch Time: 0.62335\n",
            "Epoch 73 Loss: 1.23793e-01 Epoch Time: 0.70687\n",
            "Epoch 74 Loss: 1.23084e-01 Epoch Time: 0.77102\n",
            "Epoch 75 Loss: 1.22424e-01 Epoch Time: 0.55713\n",
            "Epoch 76 Loss: 1.22047e-01 Epoch Time: 0.61896\n",
            "Epoch 77 Loss: 1.22252e-01 Epoch Time: 0.76058\n",
            "Epoch 78 Loss: 1.21936e-01 Epoch Time: 0.59941\n",
            "Epoch 79 Loss: 1.21046e-01 Epoch Time: 0.60866\n",
            "Epoch 80 Loss: 1.21481e-01 Epoch Time: 0.79091\n",
            "Epoch 81 Loss: 1.21211e-01 Epoch Time: 0.64890\n",
            "Epoch 82 Loss: 1.20076e-01 Epoch Time: 0.59851\n",
            "Epoch 83 Loss: 1.19649e-01 Epoch Time: 0.62433\n",
            "Epoch 84 Loss: 1.19560e-01 Epoch Time: 0.75736\n",
            "Epoch 85 Loss: 1.19378e-01 Epoch Time: 0.58669\n",
            "Epoch 86 Loss: 1.18500e-01 Epoch Time: 0.71070\n",
            "Epoch 87 Loss: 1.19079e-01 Epoch Time: 0.70401\n",
            "Epoch 88 Loss: 1.18201e-01 Epoch Time: 0.71788\n",
            "Epoch 89 Loss: 1.18372e-01 Epoch Time: 0.60162\n",
            "Epoch 90 Loss: 1.17853e-01 Epoch Time: 0.73752\n",
            "Epoch 91 Loss: 1.17496e-01 Epoch Time: 0.85955\n",
            "Epoch 92 Loss: 1.16521e-01 Epoch Time: 0.75229\n",
            "Epoch 93 Loss: 1.16883e-01 Epoch Time: 0.72918\n",
            "Epoch 94 Loss: 1.16321e-01 Epoch Time: 0.68490\n",
            "Epoch 95 Loss: 1.16748e-01 Epoch Time: 0.69348\n",
            "Epoch 96 Loss: 1.15331e-01 Epoch Time: 0.69903\n",
            "Epoch 97 Loss: 1.15114e-01 Epoch Time: 0.64699\n",
            "Epoch 98 Loss: 1.15371e-01 Epoch Time: 0.69172\n",
            "Epoch 99 Loss: 1.15001e-01 Epoch Time: 0.74528\n",
            "Epoch  0 Loss: 1.02466e+00 Accuracy: 0.66795 Epoch Time: 0.71722\n",
            "Epoch  1 Loss: 6.05359e-01 Accuracy: 0.76062 Epoch Time: 0.88156\n",
            "Epoch  2 Loss: 4.91437e-01 Accuracy: 0.75733 Epoch Time: 0.77006\n",
            "Epoch  3 Loss: 4.39185e-01 Accuracy: 0.76630 Epoch Time: 0.93066\n",
            "Epoch  4 Loss: 4.10179e-01 Accuracy: 0.79597 Epoch Time: 0.80421\n",
            "Epoch  5 Loss: 3.91138e-01 Accuracy: 0.81923 Epoch Time: 0.90281\n",
            "Epoch  6 Loss: 3.77160e-01 Accuracy: 0.83223 Epoch Time: 0.83386\n",
            "Epoch  7 Loss: 3.66594e-01 Accuracy: 0.83956 Epoch Time: 0.86979\n",
            "Epoch  8 Loss: 3.57630e-01 Accuracy: 0.84451 Epoch Time: 1.00651\n",
            "Epoch  9 Loss: 3.50602e-01 Accuracy: 0.83993 Epoch Time: 0.94672\n",
            "Epoch 10 Loss: 3.44282e-01 Accuracy: 0.84212 Epoch Time: 0.78169\n",
            "Epoch 11 Loss: 3.39610e-01 Accuracy: 0.84103 Epoch Time: 0.87964\n",
            "Epoch 12 Loss: 3.35288e-01 Accuracy: 0.84377 Epoch Time: 1.03880\n",
            "Epoch 13 Loss: 3.31308e-01 Accuracy: 0.84267 Epoch Time: 0.92493\n",
            "Epoch 14 Loss: 3.28563e-01 Accuracy: 0.84579 Epoch Time: 0.85842\n",
            "Epoch 15 Loss: 3.25525e-01 Accuracy: 0.84377 Epoch Time: 0.77718\n",
            "Epoch 16 Loss: 3.23133e-01 Accuracy: 0.85037 Epoch Time: 0.98714\n",
            "Epoch 17 Loss: 3.21366e-01 Accuracy: 0.85201 Epoch Time: 0.75792\n",
            "Epoch 18 Loss: 3.19325e-01 Accuracy: 0.85073 Epoch Time: 0.91103\n",
            "Epoch 19 Loss: 3.17618e-01 Accuracy: 0.85128 Epoch Time: 0.77839\n",
            "0.30657109276861205 0.8487179487179487\n",
            "Noise Level: low Mode: era\n",
            "Train-val-test lengths:  218400 46800 46800\n",
            "Epoch  0 Loss: 1.68426e+00 Epoch Time: 15.03833\n",
            "Epoch  1 Loss: 5.81419e-01 Epoch Time: 15.11658\n",
            "Epoch  2 Loss: 5.05249e-01 Epoch Time: 16.11261\n",
            "Epoch  3 Loss: 4.42329e-01 Epoch Time: 16.32346\n",
            "Epoch  4 Loss: 4.28080e-01 Epoch Time: 16.43507\n",
            "Epoch  5 Loss: 4.14601e-01 Epoch Time: 16.03868\n",
            "Epoch  6 Loss: 3.83471e-01 Epoch Time: 16.18382\n",
            "Epoch  7 Loss: 3.58655e-01 Epoch Time: 16.28389\n",
            "Epoch  8 Loss: 3.52840e-01 Epoch Time: 16.06330\n",
            "Epoch  9 Loss: 3.48852e-01 Epoch Time: 16.31522\n",
            "Epoch 10 Loss: 3.44043e-01 Epoch Time: 16.04405\n",
            "Epoch 11 Loss: 3.40905e-01 Epoch Time: 15.86787\n",
            "Epoch 12 Loss: 3.38607e-01 Epoch Time: 16.59725\n",
            "Epoch 13 Loss: 3.36760e-01 Epoch Time: 15.81914\n",
            "Epoch 14 Loss: 3.35286e-01 Epoch Time: 16.17953\n",
            "Epoch 15 Loss: 3.33833e-01 Epoch Time: 16.51655\n",
            "Epoch 16 Loss: 3.32053e-01 Epoch Time: 16.66630\n",
            "Epoch 17 Loss: 3.30605e-01 Epoch Time: 16.23788\n",
            "Epoch 18 Loss: 3.29365e-01 Epoch Time: 16.34905\n",
            "Epoch 19 Loss: 3.28361e-01 Epoch Time: 16.44455\n",
            "Epoch 20 Loss: 3.27521e-01 Epoch Time: 16.49967\n",
            "Epoch 21 Loss: 3.26633e-01 Epoch Time: 16.92997\n",
            "Epoch 22 Loss: 3.25953e-01 Epoch Time: 16.79807\n",
            "Epoch 23 Loss: 3.25273e-01 Epoch Time: 16.39314\n",
            "Epoch 24 Loss: 3.24420e-01 Epoch Time: 16.13429\n",
            "Epoch 25 Loss: 3.24078e-01 Epoch Time: 15.76078\n",
            "Epoch 26 Loss: 3.23659e-01 Epoch Time: 15.97399\n",
            "Epoch 27 Loss: 3.22790e-01 Epoch Time: 16.12349\n",
            "Epoch 28 Loss: 3.22062e-01 Epoch Time: 16.17420\n",
            "Epoch 29 Loss: 3.21507e-01 Epoch Time: 16.40081\n",
            "Epoch 30 Loss: 3.20424e-01 Epoch Time: 15.98247\n",
            "Epoch 31 Loss: 3.19398e-01 Epoch Time: 15.73153\n",
            "Epoch 32 Loss: 3.18100e-01 Epoch Time: 16.11482\n",
            "Epoch 33 Loss: 3.16815e-01 Epoch Time: 16.18316\n",
            "Epoch 34 Loss: 3.15526e-01 Epoch Time: 16.56185\n",
            "Epoch 35 Loss: 3.14405e-01 Epoch Time: 16.20420\n",
            "Epoch 36 Loss: 3.13217e-01 Epoch Time: 16.54713\n",
            "Epoch 37 Loss: 3.12276e-01 Epoch Time: 15.49514\n",
            "Epoch 38 Loss: 3.11270e-01 Epoch Time: 16.17463\n",
            "Epoch 39 Loss: 3.10333e-01 Epoch Time: 15.98514\n",
            "Epoch 40 Loss: 3.09112e-01 Epoch Time: 16.13270\n",
            "Epoch 41 Loss: 3.08036e-01 Epoch Time: 16.72738\n",
            "Epoch 42 Loss: 3.07133e-01 Epoch Time: 15.71066\n",
            "Epoch 43 Loss: 3.06308e-01 Epoch Time: 15.82730\n",
            "Epoch 44 Loss: 3.05667e-01 Epoch Time: 15.86294\n",
            "Epoch 45 Loss: 3.05251e-01 Epoch Time: 16.16413\n",
            "Epoch 46 Loss: 3.04629e-01 Epoch Time: 15.85892\n",
            "Epoch 47 Loss: 3.04368e-01 Epoch Time: 16.02155\n",
            "Epoch 48 Loss: 3.03835e-01 Epoch Time: 15.78890\n",
            "Epoch 49 Loss: 3.03274e-01 Epoch Time: 16.82265\n",
            "Epoch 50 Loss: 3.02802e-01 Epoch Time: 16.25973\n",
            "Epoch 51 Loss: 3.02228e-01 Epoch Time: 16.70849\n",
            "Epoch 52 Loss: 3.02101e-01 Epoch Time: 15.91609\n",
            "Epoch 53 Loss: 3.01596e-01 Epoch Time: 16.39217\n",
            "Epoch 54 Loss: 3.01306e-01 Epoch Time: 16.57334\n",
            "Epoch 55 Loss: 3.00678e-01 Epoch Time: 16.19127\n",
            "Epoch 56 Loss: 3.00055e-01 Epoch Time: 16.22910\n",
            "Epoch 57 Loss: 2.99508e-01 Epoch Time: 16.66939\n",
            "Epoch 58 Loss: 2.98972e-01 Epoch Time: 15.86331\n",
            "Epoch 59 Loss: 2.98162e-01 Epoch Time: 16.64620\n",
            "Epoch 60 Loss: 2.97763e-01 Epoch Time: 16.07664\n",
            "Epoch 61 Loss: 2.96996e-01 Epoch Time: 16.30878\n",
            "Epoch 62 Loss: 2.96554e-01 Epoch Time: 16.29176\n",
            "Epoch 63 Loss: 2.96122e-01 Epoch Time: 16.62123\n",
            "Epoch 64 Loss: 2.95663e-01 Epoch Time: 16.08290\n",
            "Epoch 65 Loss: 2.95142e-01 Epoch Time: 16.05976\n",
            "Epoch 66 Loss: 2.94675e-01 Epoch Time: 16.42878\n",
            "Epoch 67 Loss: 2.94307e-01 Epoch Time: 15.98850\n",
            "Epoch 68 Loss: 2.93961e-01 Epoch Time: 16.24305\n",
            "Epoch 69 Loss: 2.93454e-01 Epoch Time: 15.84923\n",
            "Epoch 70 Loss: 2.92439e-01 Epoch Time: 15.85772\n",
            "Epoch 71 Loss: 2.91706e-01 Epoch Time: 15.85815\n",
            "Epoch 72 Loss: 2.91154e-01 Epoch Time: 16.05781\n",
            "Epoch 73 Loss: 2.90755e-01 Epoch Time: 15.68848\n",
            "Epoch 74 Loss: 2.90525e-01 Epoch Time: 15.93095\n",
            "Epoch 75 Loss: 2.89988e-01 Epoch Time: 15.32131\n",
            "Epoch 76 Loss: 2.89658e-01 Epoch Time: 16.04942\n",
            "Epoch 77 Loss: 2.88998e-01 Epoch Time: 15.62457\n",
            "Epoch 78 Loss: 2.88699e-01 Epoch Time: 15.95155\n",
            "Epoch 79 Loss: 2.87840e-01 Epoch Time: 15.79007\n",
            "Epoch 80 Loss: 2.87251e-01 Epoch Time: 15.90098\n",
            "Epoch 81 Loss: 2.86190e-01 Epoch Time: 16.24762\n",
            "Epoch 82 Loss: 2.85263e-01 Epoch Time: 16.15311\n",
            "Epoch 83 Loss: 2.84464e-01 Epoch Time: 15.87262\n",
            "Epoch 84 Loss: 2.83817e-01 Epoch Time: 15.64829\n",
            "Epoch 85 Loss: 2.83408e-01 Epoch Time: 16.16627\n",
            "Epoch 86 Loss: 2.82837e-01 Epoch Time: 15.78992\n",
            "Epoch 87 Loss: 2.82558e-01 Epoch Time: 16.15442\n",
            "Epoch 88 Loss: 2.82183e-01 Epoch Time: 15.83942\n",
            "Epoch 89 Loss: 2.82014e-01 Epoch Time: 16.13504\n",
            "Epoch 90 Loss: 2.81488e-01 Epoch Time: 16.32303\n",
            "Epoch 91 Loss: 2.81261e-01 Epoch Time: 16.60452\n",
            "Epoch 92 Loss: 2.81034e-01 Epoch Time: 16.33881\n",
            "Epoch 93 Loss: 2.80807e-01 Epoch Time: 16.33240\n",
            "Epoch 94 Loss: 2.80453e-01 Epoch Time: 16.83946\n",
            "Epoch 95 Loss: 2.80100e-01 Epoch Time: 16.55757\n",
            "Epoch 96 Loss: 2.80056e-01 Epoch Time: 16.26481\n",
            "Epoch 97 Loss: 2.79905e-01 Epoch Time: 16.18725\n",
            "Epoch 98 Loss: 2.79570e-01 Epoch Time: 15.68937\n",
            "Epoch 99 Loss: 2.79436e-01 Epoch Time: 16.46859\n",
            "Epoch  0 Loss: 2.39215e+00 Accuracy: 0.14276 Epoch Time: 18.23146\n",
            "Epoch  1 Loss: 2.23410e+00 Accuracy: 0.20209 Epoch Time: 18.36001\n",
            "Epoch  2 Loss: 2.19943e+00 Accuracy: 0.22150 Epoch Time: 18.03962\n",
            "Epoch  3 Loss: 2.18421e+00 Accuracy: 0.22955 Epoch Time: 18.53957\n",
            "Epoch  4 Loss: 2.17443e+00 Accuracy: 0.23895 Epoch Time: 18.11114\n",
            "Epoch  5 Loss: 2.16667e+00 Accuracy: 0.24204 Epoch Time: 19.19941\n",
            "Epoch  6 Loss: 2.15999e+00 Accuracy: 0.24641 Epoch Time: 18.65730\n",
            "Epoch  7 Loss: 2.15427e+00 Accuracy: 0.24969 Epoch Time: 19.16573\n",
            "Epoch  8 Loss: 2.14897e+00 Accuracy: 0.25391 Epoch Time: 19.81568\n",
            "Epoch  9 Loss: 2.14414e+00 Accuracy: 0.25661 Epoch Time: 19.03452\n",
            "Epoch 10 Loss: 2.13972e+00 Accuracy: 0.25727 Epoch Time: 18.31046\n",
            "Epoch 11 Loss: 2.13568e+00 Accuracy: 0.25875 Epoch Time: 18.93132\n",
            "Epoch 12 Loss: 2.13194e+00 Accuracy: 0.26155 Epoch Time: 19.11415\n",
            "Epoch 13 Loss: 2.12843e+00 Accuracy: 0.26204 Epoch Time: 18.52148\n",
            "Epoch 14 Loss: 2.12524e+00 Accuracy: 0.26213 Epoch Time: 18.14972\n",
            "Epoch 15 Loss: 2.12200e+00 Accuracy: 0.26464 Epoch Time: 18.34226\n",
            "Epoch 16 Loss: 2.11914e+00 Accuracy: 0.26632 Epoch Time: 18.84759\n",
            "Epoch 17 Loss: 2.11655e+00 Accuracy: 0.26616 Epoch Time: 18.12753\n",
            "Epoch 18 Loss: 2.11398e+00 Accuracy: 0.26618 Epoch Time: 18.56478\n",
            "Epoch 19 Loss: 2.11164e+00 Accuracy: 0.26685 Epoch Time: 17.67593\n",
            "2.1110285770383657 0.2647863247863248\n",
            "Noise Level: low Mode: target_5_val\n",
            "Train-val-test lengths:  218400 46800 46800\n",
            "Epoch  0 Loss: 1.59505e+00 Epoch Time: 16.00529\n",
            "Epoch  1 Loss: 5.27567e-01 Epoch Time: 16.43177\n",
            "Epoch  2 Loss: 4.28493e-01 Epoch Time: 15.90553\n",
            "Epoch  3 Loss: 3.89854e-01 Epoch Time: 16.80046\n",
            "Epoch  4 Loss: 3.78770e-01 Epoch Time: 16.33507\n",
            "Epoch  5 Loss: 3.65882e-01 Epoch Time: 16.18842\n",
            "Epoch  6 Loss: 3.57891e-01 Epoch Time: 15.86312\n",
            "Epoch  7 Loss: 3.51637e-01 Epoch Time: 15.87191\n",
            "Epoch  8 Loss: 3.48018e-01 Epoch Time: 16.28991\n",
            "Epoch  9 Loss: 3.45232e-01 Epoch Time: 16.26023\n",
            "Epoch 10 Loss: 3.43426e-01 Epoch Time: 16.46883\n",
            "Epoch 11 Loss: 3.41748e-01 Epoch Time: 16.12536\n",
            "Epoch 12 Loss: 3.40425e-01 Epoch Time: 16.06239\n",
            "Epoch 13 Loss: 3.38577e-01 Epoch Time: 16.11385\n",
            "Epoch 14 Loss: 3.37105e-01 Epoch Time: 16.58749\n",
            "Epoch 15 Loss: 3.36036e-01 Epoch Time: 16.49421\n",
            "Epoch 16 Loss: 3.34588e-01 Epoch Time: 15.53457\n",
            "Epoch 17 Loss: 3.33102e-01 Epoch Time: 15.61876\n",
            "Epoch 18 Loss: 3.32005e-01 Epoch Time: 16.46186\n",
            "Epoch 19 Loss: 3.31007e-01 Epoch Time: 16.76298\n",
            "Epoch 20 Loss: 3.30397e-01 Epoch Time: 16.69873\n",
            "Epoch 21 Loss: 3.29685e-01 Epoch Time: 16.56471\n",
            "Epoch 22 Loss: 3.29056e-01 Epoch Time: 16.26817\n",
            "Epoch 23 Loss: 3.28193e-01 Epoch Time: 16.37856\n",
            "Epoch 24 Loss: 3.27620e-01 Epoch Time: 16.50758\n",
            "Epoch 25 Loss: 3.26947e-01 Epoch Time: 17.00641\n",
            "Epoch 26 Loss: 3.26278e-01 Epoch Time: 16.04076\n",
            "Epoch 27 Loss: 3.25496e-01 Epoch Time: 16.78348\n",
            "Epoch 28 Loss: 3.24272e-01 Epoch Time: 16.72389\n",
            "Epoch 29 Loss: 3.22735e-01 Epoch Time: 16.46068\n",
            "Epoch 30 Loss: 3.21270e-01 Epoch Time: 16.10589\n",
            "Epoch 31 Loss: 3.19499e-01 Epoch Time: 15.84089\n",
            "Epoch 32 Loss: 3.18054e-01 Epoch Time: 16.32207\n",
            "Epoch 33 Loss: 3.16479e-01 Epoch Time: 15.90530\n",
            "Epoch 34 Loss: 3.15045e-01 Epoch Time: 15.97070\n",
            "Epoch 35 Loss: 3.13681e-01 Epoch Time: 15.95492\n",
            "Epoch 36 Loss: 3.12371e-01 Epoch Time: 16.62016\n",
            "Epoch 37 Loss: 3.11056e-01 Epoch Time: 15.86691\n",
            "Epoch 38 Loss: 3.09255e-01 Epoch Time: 16.05635\n",
            "Epoch 39 Loss: 3.07463e-01 Epoch Time: 16.65866\n",
            "Epoch 40 Loss: 3.05843e-01 Epoch Time: 16.01558\n",
            "Epoch 41 Loss: 3.04165e-01 Epoch Time: 16.14534\n",
            "Epoch 42 Loss: 3.02807e-01 Epoch Time: 16.44825\n",
            "Epoch 43 Loss: 3.01615e-01 Epoch Time: 16.23674\n",
            "Epoch 44 Loss: 3.00288e-01 Epoch Time: 16.63350\n",
            "Epoch 45 Loss: 2.98936e-01 Epoch Time: 16.29202\n",
            "Epoch 46 Loss: 2.98001e-01 Epoch Time: 16.33411\n",
            "Epoch 47 Loss: 2.97416e-01 Epoch Time: 16.43591\n",
            "Epoch 48 Loss: 2.96828e-01 Epoch Time: 16.75717\n",
            "Epoch 49 Loss: 2.96141e-01 Epoch Time: 15.57228\n",
            "Epoch 50 Loss: 2.95476e-01 Epoch Time: 15.90861\n",
            "Epoch 51 Loss: 2.95059e-01 Epoch Time: 15.81782\n",
            "Epoch 52 Loss: 2.94418e-01 Epoch Time: 15.71096\n",
            "Epoch 53 Loss: 2.93806e-01 Epoch Time: 15.21835\n",
            "Epoch 54 Loss: 2.93306e-01 Epoch Time: 16.09474\n",
            "Epoch 55 Loss: 2.92494e-01 Epoch Time: 15.85781\n",
            "Epoch 56 Loss: 2.92082e-01 Epoch Time: 15.88344\n",
            "Epoch 57 Loss: 2.91399e-01 Epoch Time: 16.49436\n",
            "Epoch 58 Loss: 2.90432e-01 Epoch Time: 15.82346\n",
            "Epoch 59 Loss: 2.89862e-01 Epoch Time: 15.81768\n",
            "Epoch 60 Loss: 2.89315e-01 Epoch Time: 16.44810\n",
            "Epoch 61 Loss: 2.88803e-01 Epoch Time: 16.06298\n",
            "Epoch 62 Loss: 2.88247e-01 Epoch Time: 16.17317\n",
            "Epoch 63 Loss: 2.87707e-01 Epoch Time: 16.05276\n",
            "Epoch 64 Loss: 2.87185e-01 Epoch Time: 16.68452\n",
            "Epoch 65 Loss: 2.86834e-01 Epoch Time: 15.99238\n",
            "Epoch 66 Loss: 2.86468e-01 Epoch Time: 15.37441\n",
            "Epoch 67 Loss: 2.86113e-01 Epoch Time: 16.27980\n",
            "Epoch 68 Loss: 2.85656e-01 Epoch Time: 15.87271\n",
            "Epoch 69 Loss: 2.85290e-01 Epoch Time: 16.21124\n",
            "Epoch 70 Loss: 2.84840e-01 Epoch Time: 15.60036\n",
            "Epoch 71 Loss: 2.84522e-01 Epoch Time: 15.64226\n",
            "Epoch 72 Loss: 2.84026e-01 Epoch Time: 15.63657\n",
            "Epoch 73 Loss: 2.83537e-01 Epoch Time: 15.82755\n",
            "Epoch 74 Loss: 2.83257e-01 Epoch Time: 15.78581\n",
            "Epoch 75 Loss: 2.83084e-01 Epoch Time: 15.25512\n",
            "Epoch 76 Loss: 2.82631e-01 Epoch Time: 15.57099\n",
            "Epoch 77 Loss: 2.82210e-01 Epoch Time: 15.61712\n",
            "Epoch 78 Loss: 2.81975e-01 Epoch Time: 15.41152\n",
            "Epoch 79 Loss: 2.81653e-01 Epoch Time: 15.70784\n",
            "Epoch 80 Loss: 2.81395e-01 Epoch Time: 15.83886\n",
            "Epoch 81 Loss: 2.81086e-01 Epoch Time: 15.44455\n",
            "Epoch 82 Loss: 2.80854e-01 Epoch Time: 15.99383\n",
            "Epoch 83 Loss: 2.80537e-01 Epoch Time: 15.78044\n",
            "Epoch 84 Loss: 2.80276e-01 Epoch Time: 15.89849\n",
            "Epoch 85 Loss: 2.79958e-01 Epoch Time: 16.23177\n",
            "Epoch 86 Loss: 2.79474e-01 Epoch Time: 16.01272\n",
            "Epoch 87 Loss: 2.79222e-01 Epoch Time: 16.15796\n",
            "Epoch 88 Loss: 2.78788e-01 Epoch Time: 16.27518\n",
            "Epoch 89 Loss: 2.78140e-01 Epoch Time: 16.50060\n",
            "Epoch 90 Loss: 2.77619e-01 Epoch Time: 16.59130\n",
            "Epoch 91 Loss: 2.77257e-01 Epoch Time: 16.57298\n",
            "Epoch 92 Loss: 2.76649e-01 Epoch Time: 16.42358\n",
            "Epoch 93 Loss: 2.76024e-01 Epoch Time: 16.59512\n",
            "Epoch 94 Loss: 2.75866e-01 Epoch Time: 17.17047\n",
            "Epoch 95 Loss: 2.75360e-01 Epoch Time: 16.01611\n",
            "Epoch 96 Loss: 2.75027e-01 Epoch Time: 16.68556\n",
            "Epoch 97 Loss: 2.74394e-01 Epoch Time: 16.50331\n",
            "Epoch 98 Loss: 2.73878e-01 Epoch Time: 16.75652\n",
            "Epoch 99 Loss: 2.73352e-01 Epoch Time: 16.54330\n",
            "Epoch  0 Loss: 5.55749e-01 Accuracy: 0.78143 Epoch Time: 18.36071\n",
            "Epoch  1 Loss: 4.00083e-01 Accuracy: 0.83377 Epoch Time: 18.77757\n",
            "Epoch  2 Loss: 3.90919e-01 Accuracy: 0.83505 Epoch Time: 18.19460\n",
            "Epoch  3 Loss: 3.87316e-01 Accuracy: 0.83479 Epoch Time: 18.52033\n",
            "Epoch  4 Loss: 3.85013e-01 Accuracy: 0.83485 Epoch Time: 18.50707\n",
            "Epoch  5 Loss: 3.83424e-01 Accuracy: 0.83552 Epoch Time: 18.28148\n",
            "Epoch  6 Loss: 3.82265e-01 Accuracy: 0.83570 Epoch Time: 18.59899\n",
            "Epoch  7 Loss: 3.81433e-01 Accuracy: 0.83580 Epoch Time: 18.25409\n",
            "Epoch  8 Loss: 3.80779e-01 Accuracy: 0.83609 Epoch Time: 18.69202\n",
            "Epoch  9 Loss: 3.80263e-01 Accuracy: 0.83622 Epoch Time: 17.82074\n",
            "Epoch 10 Loss: 3.79923e-01 Accuracy: 0.83633 Epoch Time: 17.82209\n",
            "Epoch 11 Loss: 3.79658e-01 Accuracy: 0.83631 Epoch Time: 17.76091\n",
            "Epoch 12 Loss: 3.79463e-01 Accuracy: 0.83637 Epoch Time: 17.70478\n",
            "Epoch 13 Loss: 3.79275e-01 Accuracy: 0.83627 Epoch Time: 17.72515\n",
            "Epoch 14 Loss: 3.79120e-01 Accuracy: 0.83646 Epoch Time: 17.89905\n",
            "Epoch 15 Loss: 3.79066e-01 Accuracy: 0.83654 Epoch Time: 18.26175\n",
            "Epoch 16 Loss: 3.78956e-01 Accuracy: 0.83655 Epoch Time: 17.62449\n",
            "Epoch 17 Loss: 3.78959e-01 Accuracy: 0.83639 Epoch Time: 17.72508\n",
            "Epoch 18 Loss: 3.78902e-01 Accuracy: 0.83653 Epoch Time: 17.46699\n",
            "Epoch 19 Loss: 3.78869e-01 Accuracy: 0.83644 Epoch Time: 17.88294\n",
            "0.37999701051630524 0.8363247863247864\n",
            "Noise Level: low Mode: target_10_val\n",
            "Train-val-test lengths:  218400 46800 46800\n",
            "Epoch  0 Loss: 1.12812e+00 Epoch Time: 15.50956\n",
            "Epoch  1 Loss: 3.87163e-01 Epoch Time: 15.49132\n",
            "Epoch  2 Loss: 3.33206e-01 Epoch Time: 15.39789\n",
            "Epoch  3 Loss: 3.15607e-01 Epoch Time: 16.11265\n",
            "Epoch  4 Loss: 3.03301e-01 Epoch Time: 15.95717\n",
            "Epoch  5 Loss: 2.93054e-01 Epoch Time: 15.94697\n",
            "Epoch  6 Loss: 2.84499e-01 Epoch Time: 15.73027\n",
            "Epoch  7 Loss: 2.79807e-01 Epoch Time: 15.65155\n",
            "Epoch  8 Loss: 2.76137e-01 Epoch Time: 15.83815\n",
            "Epoch  9 Loss: 2.72608e-01 Epoch Time: 16.65978\n",
            "Epoch 10 Loss: 2.70024e-01 Epoch Time: 17.05267\n",
            "Epoch 11 Loss: 2.67221e-01 Epoch Time: 15.86048\n",
            "Epoch 12 Loss: 2.64840e-01 Epoch Time: 15.84945\n",
            "Epoch 13 Loss: 2.63032e-01 Epoch Time: 16.15251\n",
            "Epoch 14 Loss: 2.61327e-01 Epoch Time: 15.67609\n",
            "Epoch 15 Loss: 2.59690e-01 Epoch Time: 16.11345\n",
            "Epoch 16 Loss: 2.57888e-01 Epoch Time: 15.29698\n",
            "Epoch 17 Loss: 2.56358e-01 Epoch Time: 16.04640\n",
            "Epoch 18 Loss: 2.54970e-01 Epoch Time: 16.22059\n",
            "Epoch 19 Loss: 2.53064e-01 Epoch Time: 15.63223\n",
            "Epoch 20 Loss: 2.51490e-01 Epoch Time: 16.25982\n",
            "Epoch 21 Loss: 2.50007e-01 Epoch Time: 16.39571\n",
            "Epoch 22 Loss: 2.48769e-01 Epoch Time: 15.73772\n",
            "Epoch 23 Loss: 2.48003e-01 Epoch Time: 16.11629\n",
            "Epoch 24 Loss: 2.47187e-01 Epoch Time: 15.97632\n",
            "Epoch 25 Loss: 2.46418e-01 Epoch Time: 16.28208\n",
            "Epoch 26 Loss: 2.45481e-01 Epoch Time: 16.18224\n",
            "Epoch 27 Loss: 2.44311e-01 Epoch Time: 15.97541\n",
            "Epoch 28 Loss: 2.43467e-01 Epoch Time: 15.72405\n",
            "Epoch 29 Loss: 2.42751e-01 Epoch Time: 15.69734\n",
            "Epoch 30 Loss: 2.41955e-01 Epoch Time: 15.76286\n",
            "Epoch 31 Loss: 2.40998e-01 Epoch Time: 15.56296\n",
            "Epoch 32 Loss: 2.40129e-01 Epoch Time: 16.00405\n",
            "Epoch 33 Loss: 2.39533e-01 Epoch Time: 15.75446\n",
            "Epoch 34 Loss: 2.38905e-01 Epoch Time: 15.71195\n",
            "Epoch 35 Loss: 2.38110e-01 Epoch Time: 15.42335\n",
            "Epoch 36 Loss: 2.37555e-01 Epoch Time: 15.54315\n",
            "Epoch 37 Loss: 2.37129e-01 Epoch Time: 15.34437\n",
            "Epoch 38 Loss: 2.36649e-01 Epoch Time: 15.58950\n",
            "Epoch 39 Loss: 2.36148e-01 Epoch Time: 15.94769\n",
            "Epoch 40 Loss: 2.35783e-01 Epoch Time: 15.73483\n",
            "Epoch 41 Loss: 2.35522e-01 Epoch Time: 15.22547\n",
            "Epoch 42 Loss: 2.35133e-01 Epoch Time: 15.63578\n",
            "Epoch 43 Loss: 2.34813e-01 Epoch Time: 15.86394\n",
            "Epoch 44 Loss: 2.34419e-01 Epoch Time: 15.51227\n",
            "Epoch 45 Loss: 2.34181e-01 Epoch Time: 14.98719\n",
            "Epoch 46 Loss: 2.33565e-01 Epoch Time: 15.10516\n",
            "Epoch 47 Loss: 2.33076e-01 Epoch Time: 15.37677\n",
            "Epoch 48 Loss: 2.32599e-01 Epoch Time: 15.01701\n",
            "Epoch 49 Loss: 2.32336e-01 Epoch Time: 15.93332\n",
            "Epoch 50 Loss: 2.31695e-01 Epoch Time: 15.54347\n",
            "Epoch 51 Loss: 2.31302e-01 Epoch Time: 15.98406\n",
            "Epoch 52 Loss: 2.30787e-01 Epoch Time: 15.67083\n",
            "Epoch 53 Loss: 2.30238e-01 Epoch Time: 15.94828\n",
            "Epoch 54 Loss: 2.29947e-01 Epoch Time: 15.53890\n",
            "Epoch 55 Loss: 2.29445e-01 Epoch Time: 15.60996\n",
            "Epoch 56 Loss: 2.29168e-01 Epoch Time: 15.39263\n",
            "Epoch 57 Loss: 2.28687e-01 Epoch Time: 15.80284\n",
            "Epoch 58 Loss: 2.28298e-01 Epoch Time: 15.45442\n",
            "Epoch 59 Loss: 2.28246e-01 Epoch Time: 15.30115\n",
            "Epoch 60 Loss: 2.27417e-01 Epoch Time: 15.70166\n",
            "Epoch 61 Loss: 2.27011e-01 Epoch Time: 15.49366\n",
            "Epoch 62 Loss: 2.26613e-01 Epoch Time: 15.03374\n",
            "Epoch 63 Loss: 2.26289e-01 Epoch Time: 15.17887\n",
            "Epoch 64 Loss: 2.25841e-01 Epoch Time: 15.81536\n",
            "Epoch 65 Loss: 2.25501e-01 Epoch Time: 15.84650\n",
            "Epoch 66 Loss: 2.25352e-01 Epoch Time: 15.15908\n",
            "Epoch 67 Loss: 2.24917e-01 Epoch Time: 15.58447\n",
            "Epoch 68 Loss: 2.24511e-01 Epoch Time: 15.79933\n",
            "Epoch 69 Loss: 2.24226e-01 Epoch Time: 15.35710\n",
            "Epoch 70 Loss: 2.24009e-01 Epoch Time: 15.77933\n",
            "Epoch 71 Loss: 2.23725e-01 Epoch Time: 14.86772\n",
            "Epoch 72 Loss: 2.23473e-01 Epoch Time: 15.58054\n",
            "Epoch 73 Loss: 2.23252e-01 Epoch Time: 15.54833\n",
            "Epoch 74 Loss: 2.23049e-01 Epoch Time: 15.25046\n",
            "Epoch 75 Loss: 2.22735e-01 Epoch Time: 15.54622\n",
            "Epoch 76 Loss: 2.22506e-01 Epoch Time: 15.97718\n",
            "Epoch 77 Loss: 2.22271e-01 Epoch Time: 16.23245\n",
            "Epoch 78 Loss: 2.22228e-01 Epoch Time: 15.24180\n",
            "Epoch 79 Loss: 2.21959e-01 Epoch Time: 16.35655\n",
            "Epoch 80 Loss: 2.21800e-01 Epoch Time: 16.01446\n",
            "Epoch 81 Loss: 2.21642e-01 Epoch Time: 16.48975\n",
            "Epoch 82 Loss: 2.21523e-01 Epoch Time: 16.57253\n",
            "Epoch 83 Loss: 2.21388e-01 Epoch Time: 15.91563\n",
            "Epoch 84 Loss: 2.21027e-01 Epoch Time: 15.73818\n",
            "Epoch 85 Loss: 2.21025e-01 Epoch Time: 15.90053\n",
            "Epoch 86 Loss: 2.20779e-01 Epoch Time: 15.92448\n",
            "Epoch 87 Loss: 2.20774e-01 Epoch Time: 15.56229\n",
            "Epoch 88 Loss: 2.20559e-01 Epoch Time: 15.73587\n",
            "Epoch 89 Loss: 2.20403e-01 Epoch Time: 15.61350\n",
            "Epoch 90 Loss: 2.20304e-01 Epoch Time: 16.03713\n",
            "Epoch 91 Loss: 2.19942e-01 Epoch Time: 15.62784\n",
            "Epoch 92 Loss: 2.19801e-01 Epoch Time: 15.68969\n",
            "Epoch 93 Loss: 2.19578e-01 Epoch Time: 15.82871\n",
            "Epoch 94 Loss: 2.19440e-01 Epoch Time: 16.30278\n",
            "Epoch 95 Loss: 2.19230e-01 Epoch Time: 15.44609\n",
            "Epoch 96 Loss: 2.18927e-01 Epoch Time: 15.65372\n",
            "Epoch 97 Loss: 2.18815e-01 Epoch Time: 15.45104\n",
            "Epoch 98 Loss: 2.18559e-01 Epoch Time: 15.12063\n",
            "Epoch 99 Loss: 2.18438e-01 Epoch Time: 15.47085\n",
            "Epoch  0 Loss: 6.18214e-01 Accuracy: 0.71532 Epoch Time: 18.56387\n",
            "Epoch  1 Loss: 5.04020e-01 Accuracy: 0.76929 Epoch Time: 17.33642\n",
            "Epoch  2 Loss: 4.95549e-01 Accuracy: 0.77420 Epoch Time: 17.94319\n",
            "Epoch  3 Loss: 4.92797e-01 Accuracy: 0.77484 Epoch Time: 18.04996\n",
            "Epoch  4 Loss: 4.91329e-01 Accuracy: 0.77588 Epoch Time: 17.84808\n",
            "Epoch  5 Loss: 4.90408e-01 Accuracy: 0.77657 Epoch Time: 18.00195\n",
            "Epoch  6 Loss: 4.89884e-01 Accuracy: 0.77712 Epoch Time: 16.19815\n",
            "Epoch  7 Loss: 4.89429e-01 Accuracy: 0.77722 Epoch Time: 15.64198\n",
            "Epoch  8 Loss: 4.89166e-01 Accuracy: 0.77740 Epoch Time: 17.29377\n",
            "Epoch  9 Loss: 4.89005e-01 Accuracy: 0.77777 Epoch Time: 16.79815\n",
            "Epoch 10 Loss: 4.88835e-01 Accuracy: 0.77794 Epoch Time: 18.59128\n",
            "Epoch 11 Loss: 4.88749e-01 Accuracy: 0.77752 Epoch Time: 18.20202\n",
            "Epoch 12 Loss: 4.88692e-01 Accuracy: 0.77779 Epoch Time: 18.05743\n",
            "Epoch 13 Loss: 4.88598e-01 Accuracy: 0.77792 Epoch Time: 18.54274\n",
            "Epoch 14 Loss: 4.88601e-01 Accuracy: 0.77812 Epoch Time: 16.34347\n",
            "Epoch 15 Loss: 4.88528e-01 Accuracy: 0.77783 Epoch Time: 15.79960\n",
            "Epoch 16 Loss: 4.88560e-01 Accuracy: 0.77834 Epoch Time: 15.76451\n",
            "Epoch 17 Loss: 4.88543e-01 Accuracy: 0.77833 Epoch Time: 15.16956\n",
            "Epoch 18 Loss: 4.88484e-01 Accuracy: 0.77809 Epoch Time: 15.41458\n",
            "Epoch 19 Loss: 4.88563e-01 Accuracy: 0.77815 Epoch Time: 15.38128\n",
            "0.489382263085781 0.7782051282051282\n",
            "Noise Level: high Mode: era\n",
            "Train-val-test lengths:  174720 37440 37440\n",
            "Epoch  0 Loss: 2.55263e+00 Epoch Time: 12.57643\n",
            "Epoch  1 Loss: 5.91817e-01 Epoch Time: 12.60442\n",
            "Epoch  2 Loss: 5.15512e-01 Epoch Time: 12.00984\n",
            "Epoch  3 Loss: 4.90426e-01 Epoch Time: 12.30726\n",
            "Epoch  4 Loss: 4.75586e-01 Epoch Time: 12.68598\n",
            "Epoch  5 Loss: 4.36016e-01 Epoch Time: 12.80089\n",
            "Epoch  6 Loss: 3.92862e-01 Epoch Time: 12.18982\n",
            "Epoch  7 Loss: 3.86835e-01 Epoch Time: 12.11714\n",
            "Epoch  8 Loss: 3.83367e-01 Epoch Time: 12.41275\n",
            "Epoch  9 Loss: 3.80074e-01 Epoch Time: 11.96025\n",
            "Epoch 10 Loss: 3.77525e-01 Epoch Time: 12.68234\n",
            "Epoch 11 Loss: 3.75657e-01 Epoch Time: 12.39521\n",
            "Epoch 12 Loss: 3.74279e-01 Epoch Time: 12.23947\n",
            "Epoch 13 Loss: 3.72936e-01 Epoch Time: 13.01837\n",
            "Epoch 14 Loss: 3.71680e-01 Epoch Time: 12.74507\n",
            "Epoch 15 Loss: 3.70330e-01 Epoch Time: 12.39417\n",
            "Epoch 16 Loss: 3.69255e-01 Epoch Time: 12.13533\n",
            "Epoch 17 Loss: 3.68330e-01 Epoch Time: 12.35030\n",
            "Epoch 18 Loss: 3.66968e-01 Epoch Time: 12.46058\n",
            "Epoch 19 Loss: 3.64881e-01 Epoch Time: 12.43522\n",
            "Epoch 20 Loss: 3.63152e-01 Epoch Time: 12.23690\n",
            "Epoch 21 Loss: 3.61844e-01 Epoch Time: 12.54938\n",
            "Epoch 22 Loss: 3.60740e-01 Epoch Time: 12.53255\n",
            "Epoch 23 Loss: 3.59762e-01 Epoch Time: 12.09377\n",
            "Epoch 24 Loss: 3.58774e-01 Epoch Time: 12.71867\n",
            "Epoch 25 Loss: 3.57973e-01 Epoch Time: 12.30676\n",
            "Epoch 26 Loss: 3.57048e-01 Epoch Time: 12.35513\n",
            "Epoch 27 Loss: 3.56404e-01 Epoch Time: 12.46885\n",
            "Epoch 28 Loss: 3.55523e-01 Epoch Time: 12.53174\n",
            "Epoch 29 Loss: 3.54807e-01 Epoch Time: 12.25478\n",
            "Epoch 30 Loss: 3.54209e-01 Epoch Time: 12.37572\n",
            "Epoch 31 Loss: 3.53481e-01 Epoch Time: 12.55665\n",
            "Epoch 32 Loss: 3.52771e-01 Epoch Time: 12.31102\n",
            "Epoch 33 Loss: 3.51794e-01 Epoch Time: 12.56681\n",
            "Epoch 34 Loss: 3.50733e-01 Epoch Time: 12.25828\n",
            "Epoch 35 Loss: 3.50012e-01 Epoch Time: 12.28052\n",
            "Epoch 36 Loss: 3.49332e-01 Epoch Time: 12.55708\n",
            "Epoch 37 Loss: 3.48480e-01 Epoch Time: 12.48329\n",
            "Epoch 38 Loss: 3.47611e-01 Epoch Time: 12.78245\n",
            "Epoch 39 Loss: 3.47070e-01 Epoch Time: 12.29986\n",
            "Epoch 40 Loss: 3.46556e-01 Epoch Time: 12.22118\n",
            "Epoch 41 Loss: 3.45918e-01 Epoch Time: 12.24869\n",
            "Epoch 42 Loss: 3.45529e-01 Epoch Time: 12.42649\n",
            "Epoch 43 Loss: 3.44923e-01 Epoch Time: 12.14121\n",
            "Epoch 44 Loss: 3.44101e-01 Epoch Time: 12.46332\n",
            "Epoch 45 Loss: 3.43844e-01 Epoch Time: 12.48982\n",
            "Epoch 46 Loss: 3.43226e-01 Epoch Time: 12.27244\n",
            "Epoch 47 Loss: 3.42876e-01 Epoch Time: 12.26366\n",
            "Epoch 48 Loss: 3.42321e-01 Epoch Time: 12.47422\n",
            "Epoch 49 Loss: 3.41973e-01 Epoch Time: 12.03488\n",
            "Epoch 50 Loss: 3.41582e-01 Epoch Time: 12.73642\n",
            "Epoch 51 Loss: 3.40999e-01 Epoch Time: 12.14556\n",
            "Epoch 52 Loss: 3.40884e-01 Epoch Time: 12.50270\n",
            "Epoch 53 Loss: 3.40498e-01 Epoch Time: 12.44991\n",
            "Epoch 54 Loss: 3.40258e-01 Epoch Time: 12.39678\n",
            "Epoch 55 Loss: 3.39629e-01 Epoch Time: 12.18969\n",
            "Epoch 56 Loss: 3.39549e-01 Epoch Time: 12.51808\n",
            "Epoch 57 Loss: 3.39024e-01 Epoch Time: 12.35343\n",
            "Epoch 58 Loss: 3.38843e-01 Epoch Time: 12.45465\n",
            "Epoch 59 Loss: 3.38457e-01 Epoch Time: 12.39167\n",
            "Epoch 60 Loss: 3.38096e-01 Epoch Time: 12.23781\n",
            "Epoch 61 Loss: 3.37768e-01 Epoch Time: 12.48623\n",
            "Epoch 62 Loss: 3.37415e-01 Epoch Time: 12.18883\n",
            "Epoch 63 Loss: 3.37522e-01 Epoch Time: 12.05220\n",
            "Epoch 64 Loss: 3.37178e-01 Epoch Time: 12.26659\n",
            "Epoch 65 Loss: 3.36785e-01 Epoch Time: 12.49307\n",
            "Epoch 66 Loss: 3.36633e-01 Epoch Time: 12.22147\n",
            "Epoch 67 Loss: 3.36500e-01 Epoch Time: 12.80196\n",
            "Epoch 68 Loss: 3.36195e-01 Epoch Time: 12.39303\n",
            "Epoch 69 Loss: 3.35590e-01 Epoch Time: 12.22697\n",
            "Epoch 70 Loss: 3.35092e-01 Epoch Time: 12.38823\n",
            "Epoch 71 Loss: 3.34732e-01 Epoch Time: 12.21783\n",
            "Epoch 72 Loss: 3.34205e-01 Epoch Time: 12.38115\n",
            "Epoch 73 Loss: 3.33826e-01 Epoch Time: 12.55503\n",
            "Epoch 74 Loss: 3.33500e-01 Epoch Time: 12.30481\n",
            "Epoch 75 Loss: 3.32865e-01 Epoch Time: 12.74048\n",
            "Epoch 76 Loss: 3.32454e-01 Epoch Time: 12.48799\n",
            "Epoch 77 Loss: 3.32125e-01 Epoch Time: 12.44344\n",
            "Epoch 78 Loss: 3.31655e-01 Epoch Time: 12.27038\n",
            "Epoch 79 Loss: 3.31254e-01 Epoch Time: 12.32452\n",
            "Epoch 80 Loss: 3.31045e-01 Epoch Time: 12.08352\n",
            "Epoch 81 Loss: 3.30548e-01 Epoch Time: 12.60233\n",
            "Epoch 82 Loss: 3.30126e-01 Epoch Time: 12.37333\n",
            "Epoch 83 Loss: 3.29799e-01 Epoch Time: 12.49152\n",
            "Epoch 84 Loss: 3.29588e-01 Epoch Time: 12.17119\n",
            "Epoch 85 Loss: 3.29533e-01 Epoch Time: 12.10273\n",
            "Epoch 86 Loss: 3.29053e-01 Epoch Time: 12.24836\n",
            "Epoch 87 Loss: 3.28871e-01 Epoch Time: 12.48178\n",
            "Epoch 88 Loss: 3.28715e-01 Epoch Time: 12.91632\n",
            "Epoch 89 Loss: 3.28441e-01 Epoch Time: 12.58473\n",
            "Epoch 90 Loss: 3.28551e-01 Epoch Time: 12.58209\n",
            "Epoch 91 Loss: 3.28037e-01 Epoch Time: 12.50678\n",
            "Epoch 92 Loss: 3.27976e-01 Epoch Time: 12.37634\n",
            "Epoch 93 Loss: 3.27944e-01 Epoch Time: 12.23219\n",
            "Epoch 94 Loss: 3.27715e-01 Epoch Time: 12.47267\n",
            "Epoch 95 Loss: 3.27553e-01 Epoch Time: 13.26709\n",
            "Epoch 96 Loss: 3.27337e-01 Epoch Time: 12.32250\n",
            "Epoch 97 Loss: 3.27088e-01 Epoch Time: 12.21204\n",
            "Epoch 98 Loss: 3.27063e-01 Epoch Time: 12.48253\n",
            "Epoch 99 Loss: 3.26763e-01 Epoch Time: 12.30114\n",
            "Epoch  0 Loss: 2.46351e+00 Accuracy: 0.13242 Epoch Time: 12.00971\n",
            "Epoch  1 Loss: 2.40906e+00 Accuracy: 0.16368 Epoch Time: 12.23985\n",
            "Epoch  2 Loss: 2.39061e+00 Accuracy: 0.17248 Epoch Time: 12.31294\n",
            "Epoch  3 Loss: 2.38029e+00 Accuracy: 0.17530 Epoch Time: 12.32362\n",
            "Epoch  4 Loss: 2.37344e+00 Accuracy: 0.17700 Epoch Time: 12.21187\n",
            "Epoch  5 Loss: 2.36815e+00 Accuracy: 0.17884 Epoch Time: 12.23345\n",
            "Epoch  6 Loss: 2.36414e+00 Accuracy: 0.17917 Epoch Time: 12.25039\n",
            "Epoch  7 Loss: 2.36081e+00 Accuracy: 0.18086 Epoch Time: 12.13552\n",
            "Epoch  8 Loss: 2.35800e+00 Accuracy: 0.18095 Epoch Time: 12.70899\n",
            "Epoch  9 Loss: 2.35558e+00 Accuracy: 0.18269 Epoch Time: 12.19207\n",
            "Epoch 10 Loss: 2.35356e+00 Accuracy: 0.18285 Epoch Time: 12.33134\n",
            "Epoch 11 Loss: 2.35172e+00 Accuracy: 0.18294 Epoch Time: 12.78370\n",
            "Epoch 12 Loss: 2.35016e+00 Accuracy: 0.18383 Epoch Time: 14.55776\n",
            "Epoch 13 Loss: 2.34872e+00 Accuracy: 0.18403 Epoch Time: 13.59620\n",
            "Epoch 14 Loss: 2.34749e+00 Accuracy: 0.18550 Epoch Time: 12.28382\n",
            "Epoch 15 Loss: 2.34641e+00 Accuracy: 0.18644 Epoch Time: 12.77469\n",
            "Epoch 16 Loss: 2.34546e+00 Accuracy: 0.18488 Epoch Time: 12.84908\n",
            "Epoch 17 Loss: 2.34466e+00 Accuracy: 0.18555 Epoch Time: 13.33090\n",
            "Epoch 18 Loss: 2.34389e+00 Accuracy: 0.18717 Epoch Time: 12.33954\n",
            "Epoch 19 Loss: 2.34313e+00 Accuracy: 0.18752 Epoch Time: 12.40975\n",
            "2.341973452282767 0.18803418803418803\n",
            "Noise Level: high Mode: target_5_val\n",
            "Train-val-test lengths:  174720 37440 37440\n",
            "Epoch  0 Loss: 2.21859e+00 Epoch Time: 12.79204\n",
            "Epoch  1 Loss: 6.04142e-01 Epoch Time: 13.22187\n",
            "Epoch  2 Loss: 5.02672e-01 Epoch Time: 13.11700\n",
            "Epoch  3 Loss: 4.28305e-01 Epoch Time: 13.00138\n",
            "Epoch  4 Loss: 4.21711e-01 Epoch Time: 13.24918\n",
            "Epoch  5 Loss: 4.19163e-01 Epoch Time: 13.32860\n",
            "Epoch  6 Loss: 4.16503e-01 Epoch Time: 13.03123\n",
            "Epoch  7 Loss: 4.13276e-01 Epoch Time: 12.92769\n",
            "Epoch  8 Loss: 4.10197e-01 Epoch Time: 12.83031\n",
            "Epoch  9 Loss: 4.08626e-01 Epoch Time: 13.14549\n",
            "Epoch 10 Loss: 4.07257e-01 Epoch Time: 12.96258\n",
            "Epoch 11 Loss: 4.04619e-01 Epoch Time: 13.41792\n",
            "Epoch 12 Loss: 4.01182e-01 Epoch Time: 13.11441\n",
            "Epoch 13 Loss: 3.97463e-01 Epoch Time: 13.03701\n",
            "Epoch 14 Loss: 3.96014e-01 Epoch Time: 12.73303\n",
            "Epoch 15 Loss: 3.94829e-01 Epoch Time: 13.17188\n",
            "Epoch 16 Loss: 3.93524e-01 Epoch Time: 13.36325\n",
            "Epoch 17 Loss: 3.92415e-01 Epoch Time: 13.00058\n",
            "Epoch 18 Loss: 3.90592e-01 Epoch Time: 13.01084\n",
            "Epoch 19 Loss: 3.86227e-01 Epoch Time: 13.38872\n",
            "Epoch 20 Loss: 3.83909e-01 Epoch Time: 12.90031\n",
            "Epoch 21 Loss: 3.82475e-01 Epoch Time: 12.93233\n",
            "Epoch 22 Loss: 3.81021e-01 Epoch Time: 13.22789\n",
            "Epoch 23 Loss: 3.80193e-01 Epoch Time: 13.57841\n",
            "Epoch 24 Loss: 3.79464e-01 Epoch Time: 13.47583\n",
            "Epoch 25 Loss: 3.78422e-01 Epoch Time: 13.52400\n",
            "Epoch 26 Loss: 3.77956e-01 Epoch Time: 13.32453\n",
            "Epoch 27 Loss: 3.77239e-01 Epoch Time: 13.04959\n",
            "Epoch 28 Loss: 3.76725e-01 Epoch Time: 13.18846\n",
            "Epoch 29 Loss: 3.76442e-01 Epoch Time: 13.38258\n",
            "Epoch 30 Loss: 3.75709e-01 Epoch Time: 13.40722\n",
            "Epoch 31 Loss: 3.74901e-01 Epoch Time: 13.40294\n",
            "Epoch 32 Loss: 3.74169e-01 Epoch Time: 13.51436\n",
            "Epoch 33 Loss: 3.73573e-01 Epoch Time: 13.73766\n",
            "Epoch 34 Loss: 3.72341e-01 Epoch Time: 13.60175\n",
            "Epoch 35 Loss: 3.70796e-01 Epoch Time: 13.60216\n",
            "Epoch 36 Loss: 3.69897e-01 Epoch Time: 13.24303\n",
            "Epoch 37 Loss: 3.68736e-01 Epoch Time: 13.88104\n",
            "Epoch 38 Loss: 3.67864e-01 Epoch Time: 13.12322\n",
            "Epoch 39 Loss: 3.67064e-01 Epoch Time: 12.75578\n",
            "Epoch 40 Loss: 3.65971e-01 Epoch Time: 13.04357\n",
            "Epoch 41 Loss: 3.64354e-01 Epoch Time: 13.71655\n",
            "Epoch 42 Loss: 3.61969e-01 Epoch Time: 13.17077\n",
            "Epoch 43 Loss: 3.60072e-01 Epoch Time: 13.77787\n",
            "Epoch 44 Loss: 3.58770e-01 Epoch Time: 13.28767\n",
            "Epoch 45 Loss: 3.57785e-01 Epoch Time: 13.15781\n",
            "Epoch 46 Loss: 3.56863e-01 Epoch Time: 13.34724\n",
            "Epoch 47 Loss: 3.56145e-01 Epoch Time: 13.26029\n",
            "Epoch 48 Loss: 3.55174e-01 Epoch Time: 13.56719\n",
            "Epoch 49 Loss: 3.54416e-01 Epoch Time: 13.41035\n",
            "Epoch 50 Loss: 3.53482e-01 Epoch Time: 13.86327\n",
            "Epoch 51 Loss: 3.52861e-01 Epoch Time: 13.80520\n",
            "Epoch 52 Loss: 3.51944e-01 Epoch Time: 13.25645\n",
            "Epoch 53 Loss: 3.51080e-01 Epoch Time: 13.51025\n",
            "Epoch 54 Loss: 3.50567e-01 Epoch Time: 13.51958\n",
            "Epoch 55 Loss: 3.49936e-01 Epoch Time: 13.49722\n",
            "Epoch 56 Loss: 3.49348e-01 Epoch Time: 12.99774\n",
            "Epoch 57 Loss: 3.48924e-01 Epoch Time: 13.63344\n",
            "Epoch 58 Loss: 3.48435e-01 Epoch Time: 13.53480\n",
            "Epoch 59 Loss: 3.47973e-01 Epoch Time: 13.62784\n",
            "Epoch 60 Loss: 3.47400e-01 Epoch Time: 13.74646\n",
            "Epoch 61 Loss: 3.47048e-01 Epoch Time: 13.93421\n",
            "Epoch 62 Loss: 3.46646e-01 Epoch Time: 13.85167\n",
            "Epoch 63 Loss: 3.46263e-01 Epoch Time: 13.93332\n",
            "Epoch 64 Loss: 3.46214e-01 Epoch Time: 13.54764\n",
            "Epoch 65 Loss: 3.45549e-01 Epoch Time: 13.38934\n",
            "Epoch 66 Loss: 3.45266e-01 Epoch Time: 13.66424\n",
            "Epoch 67 Loss: 3.44821e-01 Epoch Time: 12.89526\n",
            "Epoch 68 Loss: 3.44107e-01 Epoch Time: 13.18563\n",
            "Epoch 69 Loss: 3.43315e-01 Epoch Time: 13.27371\n",
            "Epoch 70 Loss: 3.42649e-01 Epoch Time: 13.47482\n",
            "Epoch 71 Loss: 3.42265e-01 Epoch Time: 13.03167\n",
            "Epoch 72 Loss: 3.41823e-01 Epoch Time: 13.64328\n",
            "Epoch 73 Loss: 3.41306e-01 Epoch Time: 13.30291\n",
            "Epoch 74 Loss: 3.40759e-01 Epoch Time: 13.56694\n",
            "Epoch 75 Loss: 3.40368e-01 Epoch Time: 13.72909\n",
            "Epoch 76 Loss: 3.39739e-01 Epoch Time: 13.59266\n",
            "Epoch 77 Loss: 3.39470e-01 Epoch Time: 13.62520\n",
            "Epoch 78 Loss: 3.39093e-01 Epoch Time: 13.51216\n",
            "Epoch 79 Loss: 3.38547e-01 Epoch Time: 13.06800\n",
            "Epoch 80 Loss: 3.37995e-01 Epoch Time: 13.56883\n",
            "Epoch 81 Loss: 3.37812e-01 Epoch Time: 13.27339\n",
            "Epoch 82 Loss: 3.37299e-01 Epoch Time: 13.14443\n",
            "Epoch 83 Loss: 3.36833e-01 Epoch Time: 12.87017\n",
            "Epoch 84 Loss: 3.36465e-01 Epoch Time: 13.62804\n",
            "Epoch 85 Loss: 3.36288e-01 Epoch Time: 13.20690\n",
            "Epoch 86 Loss: 3.35865e-01 Epoch Time: 13.50221\n",
            "Epoch 87 Loss: 3.35586e-01 Epoch Time: 13.23958\n",
            "Epoch 88 Loss: 3.35410e-01 Epoch Time: 13.56295\n",
            "Epoch 89 Loss: 3.35062e-01 Epoch Time: 13.97311\n",
            "Epoch 90 Loss: 3.34967e-01 Epoch Time: 13.21219\n",
            "Epoch 91 Loss: 3.34680e-01 Epoch Time: 13.23658\n",
            "Epoch 92 Loss: 3.34391e-01 Epoch Time: 14.14784\n",
            "Epoch 93 Loss: 3.34151e-01 Epoch Time: 12.90189\n",
            "Epoch 94 Loss: 3.33872e-01 Epoch Time: 13.66980\n",
            "Epoch 95 Loss: 3.33719e-01 Epoch Time: 13.34525\n",
            "Epoch 96 Loss: 3.33393e-01 Epoch Time: 13.12595\n",
            "Epoch 97 Loss: 3.33341e-01 Epoch Time: 12.90671\n",
            "Epoch 98 Loss: 3.32981e-01 Epoch Time: 13.11935\n",
            "Epoch 99 Loss: 3.32866e-01 Epoch Time: 12.84431\n",
            "Epoch  0 Loss: 5.76028e-01 Accuracy: 0.75924 Epoch Time: 15.18228\n",
            "Epoch  1 Loss: 5.04600e-01 Accuracy: 0.78160 Epoch Time: 14.97634\n",
            "Epoch  2 Loss: 4.99277e-01 Accuracy: 0.78490 Epoch Time: 15.61016\n",
            "Epoch  3 Loss: 4.97455e-01 Accuracy: 0.78432 Epoch Time: 15.00965\n",
            "Epoch  4 Loss: 4.96599e-01 Accuracy: 0.78386 Epoch Time: 15.36847\n",
            "Epoch  5 Loss: 4.96189e-01 Accuracy: 0.78348 Epoch Time: 15.51045\n",
            "Epoch  6 Loss: 4.95972e-01 Accuracy: 0.78289 Epoch Time: 15.18484\n",
            "Epoch  7 Loss: 4.95744e-01 Accuracy: 0.78241 Epoch Time: 15.32466\n",
            "Epoch  8 Loss: 4.95651e-01 Accuracy: 0.78198 Epoch Time: 14.91466\n",
            "Epoch  9 Loss: 4.95593e-01 Accuracy: 0.78191 Epoch Time: 15.64862\n",
            "Epoch 10 Loss: 4.95478e-01 Accuracy: 0.78176 Epoch Time: 15.79507\n",
            "Epoch 11 Loss: 4.95516e-01 Accuracy: 0.78151 Epoch Time: 15.43226\n",
            "Epoch 12 Loss: 4.95494e-01 Accuracy: 0.78122 Epoch Time: 15.66893\n",
            "Epoch 13 Loss: 4.95441e-01 Accuracy: 0.78127 Epoch Time: 15.35555\n",
            "Epoch 14 Loss: 4.95522e-01 Accuracy: 0.78136 Epoch Time: 15.61637\n",
            "Epoch 15 Loss: 4.95417e-01 Accuracy: 0.78082 Epoch Time: 15.56594\n",
            "Epoch 16 Loss: 4.95415e-01 Accuracy: 0.78103 Epoch Time: 15.61556\n",
            "Epoch 17 Loss: 4.95447e-01 Accuracy: 0.78090 Epoch Time: 14.79169\n",
            "Epoch 18 Loss: 4.95407e-01 Accuracy: 0.78117 Epoch Time: 15.09395\n",
            "Epoch 19 Loss: 4.95443e-01 Accuracy: 0.78044 Epoch Time: 15.18596\n",
            "0.4873718948445768 0.7869123931623931\n",
            "Noise Level: high Mode: target_10_val\n",
            "Train-val-test lengths:  174720 37440 37440\n",
            "Epoch  0 Loss: 2.15441e+00 Epoch Time: 12.96869\n",
            "Epoch  1 Loss: 6.47755e-01 Epoch Time: 12.70861\n",
            "Epoch  2 Loss: 6.05643e-01 Epoch Time: 12.91589\n",
            "Epoch  3 Loss: 5.91440e-01 Epoch Time: 13.24760\n",
            "Epoch  4 Loss: 5.78217e-01 Epoch Time: 13.36373\n",
            "Epoch  5 Loss: 5.69608e-01 Epoch Time: 13.38986\n",
            "Epoch  6 Loss: 5.63788e-01 Epoch Time: 13.36434\n",
            "Epoch  7 Loss: 5.56629e-01 Epoch Time: 13.11976\n",
            "Epoch  8 Loss: 5.51097e-01 Epoch Time: 13.68868\n",
            "Epoch  9 Loss: 5.48047e-01 Epoch Time: 13.17834\n",
            "Epoch 10 Loss: 5.45962e-01 Epoch Time: 13.50078\n",
            "Epoch 11 Loss: 5.44020e-01 Epoch Time: 13.47542\n",
            "Epoch 12 Loss: 5.42302e-01 Epoch Time: 13.50953\n",
            "Epoch 13 Loss: 5.40246e-01 Epoch Time: 13.17218\n",
            "Epoch 14 Loss: 5.38233e-01 Epoch Time: 13.12912\n",
            "Epoch 15 Loss: 5.36483e-01 Epoch Time: 13.25785\n",
            "Epoch 16 Loss: 5.34278e-01 Epoch Time: 12.81973\n",
            "Epoch 17 Loss: 5.32167e-01 Epoch Time: 13.36342\n",
            "Epoch 18 Loss: 5.29369e-01 Epoch Time: 13.25608\n",
            "Epoch 19 Loss: 5.26626e-01 Epoch Time: 13.33535\n",
            "Epoch 20 Loss: 5.24026e-01 Epoch Time: 13.29494\n",
            "Epoch 21 Loss: 5.22041e-01 Epoch Time: 13.65610\n",
            "Epoch 22 Loss: 5.19386e-01 Epoch Time: 13.35613\n",
            "Epoch 23 Loss: 5.17556e-01 Epoch Time: 13.33350\n",
            "Epoch 24 Loss: 5.15434e-01 Epoch Time: 13.43885\n",
            "Epoch 25 Loss: 5.13964e-01 Epoch Time: 13.37490\n",
            "Epoch 26 Loss: 5.12250e-01 Epoch Time: 13.03533\n",
            "Epoch 27 Loss: 5.07711e-01 Epoch Time: 13.30102\n",
            "Epoch 28 Loss: 5.04071e-01 Epoch Time: 13.61330\n",
            "Epoch 29 Loss: 5.01879e-01 Epoch Time: 13.51522\n",
            "Epoch 30 Loss: 4.99901e-01 Epoch Time: 13.68617\n",
            "Epoch 31 Loss: 4.98724e-01 Epoch Time: 12.99716\n",
            "Epoch 32 Loss: 4.97325e-01 Epoch Time: 13.50163\n",
            "Epoch 33 Loss: 4.96565e-01 Epoch Time: 13.42528\n",
            "Epoch 34 Loss: 4.95144e-01 Epoch Time: 13.36084\n",
            "Epoch 35 Loss: 4.94138e-01 Epoch Time: 13.52845\n",
            "Epoch 36 Loss: 4.93053e-01 Epoch Time: 13.79004\n",
            "Epoch 37 Loss: 4.92385e-01 Epoch Time: 13.34431\n",
            "Epoch 38 Loss: 4.91592e-01 Epoch Time: 13.44307\n",
            "Epoch 39 Loss: 4.90508e-01 Epoch Time: 13.09305\n",
            "Epoch 40 Loss: 4.89554e-01 Epoch Time: 13.49859\n",
            "Epoch 41 Loss: 4.88547e-01 Epoch Time: 13.09929\n",
            "Epoch 42 Loss: 4.87358e-01 Epoch Time: 13.50964\n",
            "Epoch 43 Loss: 4.85767e-01 Epoch Time: 13.22055\n",
            "Epoch 44 Loss: 4.84371e-01 Epoch Time: 13.01002\n",
            "Epoch 45 Loss: 4.83482e-01 Epoch Time: 13.06002\n",
            "Epoch 46 Loss: 4.82368e-01 Epoch Time: 12.73433\n",
            "Epoch 47 Loss: 4.81777e-01 Epoch Time: 13.36431\n",
            "Epoch 48 Loss: 4.80979e-01 Epoch Time: 12.73105\n",
            "Epoch 49 Loss: 4.79924e-01 Epoch Time: 12.92904\n",
            "Epoch 50 Loss: 4.79419e-01 Epoch Time: 12.88597\n",
            "Epoch 51 Loss: 4.78168e-01 Epoch Time: 12.99563\n",
            "Epoch 52 Loss: 4.77451e-01 Epoch Time: 12.77947\n",
            "Epoch 53 Loss: 4.76534e-01 Epoch Time: 12.69336\n",
            "Epoch 54 Loss: 4.76109e-01 Epoch Time: 12.93396\n",
            "Epoch 55 Loss: 4.75330e-01 Epoch Time: 12.77417\n",
            "Epoch 56 Loss: 4.74606e-01 Epoch Time: 12.80277\n",
            "Epoch 57 Loss: 4.73955e-01 Epoch Time: 12.62310\n",
            "Epoch 58 Loss: 4.73837e-01 Epoch Time: 12.97080\n",
            "Epoch 59 Loss: 4.73129e-01 Epoch Time: 12.84561\n",
            "Epoch 60 Loss: 4.72735e-01 Epoch Time: 12.83406\n",
            "Epoch 61 Loss: 4.72211e-01 Epoch Time: 12.78914\n",
            "Epoch 62 Loss: 4.71863e-01 Epoch Time: 12.86787\n",
            "Epoch 63 Loss: 4.71408e-01 Epoch Time: 13.89894\n",
            "Epoch 64 Loss: 4.70929e-01 Epoch Time: 12.64519\n",
            "Epoch 65 Loss: 4.70180e-01 Epoch Time: 14.80786\n",
            "Epoch 66 Loss: 4.70139e-01 Epoch Time: 13.60944\n",
            "Epoch 67 Loss: 4.69779e-01 Epoch Time: 12.90598\n",
            "Epoch 68 Loss: 4.69241e-01 Epoch Time: 13.32240\n",
            "Epoch 69 Loss: 4.68953e-01 Epoch Time: 13.28778\n",
            "Epoch 70 Loss: 4.68203e-01 Epoch Time: 12.78016\n",
            "Epoch 71 Loss: 4.68135e-01 Epoch Time: 12.77157\n",
            "Epoch 72 Loss: 4.67410e-01 Epoch Time: 12.61951\n",
            "Epoch 73 Loss: 4.67232e-01 Epoch Time: 13.05960\n",
            "Epoch 74 Loss: 4.66584e-01 Epoch Time: 12.84342\n",
            "Epoch 75 Loss: 4.66329e-01 Epoch Time: 12.87486\n",
            "Epoch 76 Loss: 4.65729e-01 Epoch Time: 12.90338\n",
            "Epoch 77 Loss: 4.65471e-01 Epoch Time: 13.02045\n",
            "Epoch 78 Loss: 4.64999e-01 Epoch Time: 13.04229\n",
            "Epoch 79 Loss: 4.64601e-01 Epoch Time: 12.65135\n",
            "Epoch 80 Loss: 4.64103e-01 Epoch Time: 12.81206\n",
            "Epoch 81 Loss: 4.63783e-01 Epoch Time: 13.00818\n",
            "Epoch 82 Loss: 4.63240e-01 Epoch Time: 12.99496\n",
            "Epoch 83 Loss: 4.62769e-01 Epoch Time: 12.59347\n",
            "Epoch 84 Loss: 4.62312e-01 Epoch Time: 12.91797\n",
            "Epoch 85 Loss: 4.61790e-01 Epoch Time: 12.93033\n",
            "Epoch 86 Loss: 4.61391e-01 Epoch Time: 13.15750\n",
            "Epoch 87 Loss: 4.61181e-01 Epoch Time: 13.06333\n",
            "Epoch 88 Loss: 4.60799e-01 Epoch Time: 12.84765\n",
            "Epoch 89 Loss: 4.59984e-01 Epoch Time: 12.98913\n",
            "Epoch 90 Loss: 4.58918e-01 Epoch Time: 13.02648\n",
            "Epoch 91 Loss: 4.57560e-01 Epoch Time: 12.76685\n",
            "Epoch 92 Loss: 4.56914e-01 Epoch Time: 12.98960\n",
            "Epoch 93 Loss: 4.56204e-01 Epoch Time: 13.05502\n",
            "Epoch 94 Loss: 4.55421e-01 Epoch Time: 12.72376\n",
            "Epoch 95 Loss: 4.54102e-01 Epoch Time: 12.87137\n",
            "Epoch 96 Loss: 4.52979e-01 Epoch Time: 12.93965\n",
            "Epoch 97 Loss: 4.51669e-01 Epoch Time: 13.13157\n",
            "Epoch 98 Loss: 4.50785e-01 Epoch Time: 12.76052\n",
            "Epoch 99 Loss: 4.50439e-01 Epoch Time: 12.63520\n",
            "Epoch  0 Loss: 7.44672e-01 Accuracy: 0.68412 Epoch Time: 14.57724\n",
            "Epoch  1 Loss: 5.34003e-01 Accuracy: 0.74736 Epoch Time: 14.84595\n",
            "Epoch  2 Loss: 5.19779e-01 Accuracy: 0.75489 Epoch Time: 14.73225\n",
            "Epoch  3 Loss: 5.15533e-01 Accuracy: 0.75683 Epoch Time: 15.55674\n",
            "Epoch  4 Loss: 5.13922e-01 Accuracy: 0.75759 Epoch Time: 15.22225\n",
            "Epoch  5 Loss: 5.13315e-01 Accuracy: 0.75773 Epoch Time: 15.36265\n",
            "Epoch  6 Loss: 5.12950e-01 Accuracy: 0.75750 Epoch Time: 15.43226\n",
            "Epoch  7 Loss: 5.12754e-01 Accuracy: 0.75741 Epoch Time: 16.57438\n",
            "Epoch  8 Loss: 5.12681e-01 Accuracy: 0.75741 Epoch Time: 16.70208\n",
            "Epoch  9 Loss: 5.12648e-01 Accuracy: 0.75740 Epoch Time: 16.90296\n",
            "Epoch 10 Loss: 5.12650e-01 Accuracy: 0.75730 Epoch Time: 17.88661\n",
            "Epoch 11 Loss: 5.12625e-01 Accuracy: 0.75729 Epoch Time: 16.39454\n",
            "Epoch 12 Loss: 5.12627e-01 Accuracy: 0.75734 Epoch Time: 17.89865\n",
            "Epoch 13 Loss: 5.12621e-01 Accuracy: 0.75715 Epoch Time: 17.35576\n",
            "Epoch 14 Loss: 5.12628e-01 Accuracy: 0.75770 Epoch Time: 16.64812\n",
            "Epoch 15 Loss: 5.12646e-01 Accuracy: 0.75711 Epoch Time: 16.90676\n",
            "Epoch 16 Loss: 5.12656e-01 Accuracy: 0.75743 Epoch Time: 16.93812\n",
            "Epoch 17 Loss: 5.12653e-01 Accuracy: 0.75740 Epoch Time: 17.54941\n",
            "Epoch 18 Loss: 5.12613e-01 Accuracy: 0.75731 Epoch Time: 16.82997\n",
            "Epoch 19 Loss: 5.12620e-01 Accuracy: 0.75751 Epoch Time: 18.63784\n",
            "0.5182145917517507 0.7568376068376068\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "df_paths = ['./df_syn_train_0_0_.csv',\n",
        "            './df_synA_train_shuffled.csv',\n",
        "            './df_synA_test_hard_shuffled_sample.csv']\n",
        "\n",
        "noise_levels = ['none', 'low', 'high']\n",
        "batch_sizes = [32, 128, 128]\n",
        "\n",
        "losses_arr = []\n",
        "accs_arr = []\n",
        "\n",
        "for i in range(0, 3):\n",
        "    df = pd.read_csv(df_paths[i])\n",
        "\n",
        "    modes = ['era', 'target_5_val', 'target_10_val']\n",
        "\n",
        "    loss_per_mode = []\n",
        "    acc_per_mode = []\n",
        "\n",
        "    for mode in modes:\n",
        "        print(\"Noise Level:\", noise_levels[i], \"Mode:\", mode)\n",
        "        loader_train, loader_val, loader_test, data = make_data_splits(df, mode=mode, \\\n",
        "                                                                       batch_size=batch_sizes[i])\n",
        "        mode = mode + \"_ae\"\n",
        "        net_auto = MLP(dims=[data.X.shape[1], 32, 16, 8, 16, 32, data.X.shape[1]], task='regression').to(device)\n",
        "        net_auto, losses_ae = TrainAE(net_auto, loader_train, mode, noise_levels[i], \\\n",
        "                                      epochs=100, verbose=True, device=device, val_ds=loader_val, \\\n",
        "                                      plot_accs=True, plot_losses=True)\n",
        "\n",
        "        net = MLP(dims=[data.X.shape[1], 32, 16, 8, len(data.y.unique())], task='classification').to(device)\n",
        "\n",
        "        for j in range(6):\n",
        "            net.layers[j] = net_auto.layers[j]\n",
        "            net.layers[j].requires_grad = False\n",
        "\n",
        "        net, losses, accs, val_losses, val_accL = Train(net, loader_train, mode, noise_levels[i], \\\n",
        "                                      epochs=20, verbose=True, device=device, val_ds=loader_val, \\\n",
        "                                      plot_accs=True, plot_losses=True)\n",
        "    \n",
        "        losses = losses_ae+losses\n",
        "\n",
        "        plot_loss_acc(losses, accs, val_losses, val_accL, mode, noise_levels[i])\n",
        "        #Testing code\n",
        "        test_loss, test_acc = Test(net, loader_test, mode, noise_levels[i], device=device)\n",
        "        print(test_loss, test_acc)\n",
        "        loss_per_mode.append(test_loss)\n",
        "        acc_per_mode.append(test_acc)\n",
        "\n",
        "    losses_arr.append(loss_per_mode)\n",
        "    accs_arr.append(acc_per_mode)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(f'{prefix}/losses_dump.pkl', 'wb') as f:\n",
        "    pkl.dump(losses_arr, f)\n",
        "\n",
        "with open(f'{prefix}/accs_dump.pkl', 'wb') as f:\n",
        "    pkl.dump(accs_arr, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.19914529914529913, 0.8538461538461538, 0.8487179487179487], [0.2647863247863248, 0.8363247863247864, 0.7782051282051282], [0.18803418803418803, 0.7869123931623931, 0.7568376068376068]]\n"
          ]
        }
      ],
      "source": [
        "import pickle as pkl\n",
        "prefix = './data_dump_ae'\n",
        "with open(f'{prefix}/accs_dump.pkl', 'rb') as f:\n",
        "    accs = pkl.load(f)\n",
        "\n",
        "print(accs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcE0-Y6JQQLQ"
      },
      "source": [
        "#NAL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4CdEn7cZUD5O"
      },
      "outputs": [],
      "source": [
        "# this would only work on the target_x_val cases"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2vazKruX9bl"
      },
      "source": [
        "#SubTab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21Y278HqX-jD"
      },
      "outputs": [],
      "source": [
        "# need to go through the github"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
