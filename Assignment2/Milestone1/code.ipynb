{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn.functional as F\n",
    "from IPython import display\n",
    "from tqdm.notebook import tqdm\n",
    "import random\n",
    "import math, time, os\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle as pkl\n",
    "\n",
    "from AutoEncoder import Autoencoder as AE\n",
    "from copy import deepcopy\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "prefix = './data_dump'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW FILE\n",
      "[65]\n",
      "NEW FILE\n",
      "[65]\n",
      "NEW FILE\n",
      "[65]\n",
      "NEW FILE\n",
      "[65]\n"
     ]
    }
   ],
   "source": [
    "# day checker\n",
    "file_paths = ['../Datasets/cf_train_no_noise.csv', \n",
    "              '../Datasets/cf_test_no_noise.csv', \n",
    "              '../Datasets/cf_train.csv', \n",
    "              '../Datasets/cf_test.csv']\n",
    "\n",
    "for file in file_paths:\n",
    "    print(\"NEW FILE\")\n",
    "    df = pd.read_csv(file)\n",
    "    print(np.unique(df['day_no'].value_counts().to_numpy()))\n",
    "\n",
    "    # cur_day = df['day_no'][0]\n",
    "    # cur_era = df['era'][0]\n",
    "    # for i in range(1, df.shape[0]):\n",
    "    #     if df['day_no'][i] == cur_day and df['era'][i] == cur_era:\n",
    "    #         pass\n",
    "    #     elif df['day_no'][i] == cur_day and df['era'][i] != cur_era:\n",
    "    #         print(\"1\")\n",
    "    #     elif df['day_no'][i] != cur_day and df['era'][i] == cur_era:\n",
    "    #         print(\"2\")\n",
    "    #     else:\n",
    "    #         pass\n",
    "    #     cur_era = df['era'][i]\n",
    "    #     cur_day = df['day_no'][i] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SinusodialDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        \"\"\" creating label columns of eras and targets \"\"\"\n",
    "        self.NUM_FEATURES = 24\n",
    "        self.X = df.iloc[:, :self.NUM_FEATURES]\n",
    "        self.y = df['target_10_val']\n",
    "        self.X = self.create_categorical_one_hot(self.X)\n",
    "    \n",
    "    def create_categorical_one_hot(self, df):\n",
    "        categories = [0, 0.25, 0.5, 0.75, 1]\n",
    "        one_hot_encoded_columns = []\n",
    "        for col in df.columns:\n",
    "            for cat in categories:\n",
    "                new_col_name = f\"{col}_{cat}\"\n",
    "                one_hot_encoded_col = (df[col] == cat).astype(int)\n",
    "                one_hot_encoded_col.name = new_col_name\n",
    "                one_hot_encoded_columns.append(one_hot_encoded_col)\n",
    "\n",
    "        # Concatenate the one-hot encoded columns along axis 1\n",
    "        return pd.concat(one_hot_encoded_columns, axis=1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X = torch.tensor(self.X.iloc[idx].values, dtype=torch.float32)\n",
    "        y = torch.tensor(int(self.y.iloc[idx]), dtype=torch.long)\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data_splits(train_df, test_df, batch_size=32, train_perc=0.9):\n",
    "\n",
    "    def encode(v, class_values):\n",
    "        return class_values.index(v)\n",
    "\n",
    "    #adding new era_label column indexed 0, 1,...\n",
    "    class_values = train_df['target_10_val'].unique().tolist()\n",
    "    train_df['target_10_val'] = train_df['target_10_val'].apply(lambda x: encode(x, class_values))\n",
    "    train_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    class_values = test_df['target_10_val'].unique().tolist()\n",
    "    test_df['target_10_val'] = test_df['target_10_val'].apply(lambda x: encode(x, class_values))\n",
    "    test_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    train_samples = int(len(train_df)*train_perc)\n",
    "    val_samples = len(train_df)-train_samples\n",
    "    \n",
    "    data = SinusodialDataset(train_df)\n",
    "    data_test = SinusodialDataset(test_df)\n",
    "\n",
    "    data_train, data_val = train_test_split(data, test_size=(1-train_perc), shuffle=False)\n",
    "\n",
    "    print(\"Train-val-test lengths: \", len(data_train), len(data_val), len(data_test))\n",
    "\n",
    "    loader_train = DataLoader(data_train, batch_size=batch_size, shuffle=False)\n",
    "    loader_val = DataLoader(data_val, batch_size=batch_size, shuffle=False)\n",
    "    loader_test = DataLoader(data_test, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return loader_train, loader_val, loader_test, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestTimeAdapter(nn.Module):\n",
    "    \n",
    "    def __init__(self, ae_dims, cl_dims, lr=1e-3, weight_decay=1e-3):\n",
    "        super(TestTimeAdapter,self).__init__()\n",
    "        self.ae_dims=ae_dims\n",
    "        self.cl_dims = cl_dims\n",
    "\n",
    "        self.ae = AE(ae_dims)\n",
    "        self.classifier=nn.ModuleList()\n",
    "        \n",
    "        for i in range(len(cl_dims)-2):\n",
    "            self.classifier.append(nn.Linear(cl_dims[i],cl_dims[i+1]))\n",
    "            self.classifier.append(nn.ReLU())\n",
    "        self.classifier.append(nn.Linear(cl_dims[i+1],cl_dims[i+2]))\n",
    "        self.classifier.append(nn.LogSoftmax(dim=1))\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    def forward(self, x, classifier=False):\n",
    "        if classifier:\n",
    "            x = x.float()\n",
    "            x = self.ae.encode(x)\n",
    "            for l in self.classifier:\n",
    "                x = l(x)\n",
    "            return x\n",
    "        \n",
    "        x = x.float()\n",
    "        x = self.ae(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_pred, y_test, verbose=True):\n",
    "    m = y_test.shape[0]\n",
    "    predicted = torch.max(y_pred, 1)[1]\n",
    "    correct = (predicted == y_test).float().sum().item()\n",
    "    if verbose:\n",
    "        print(correct,m)\n",
    "    accuracy = correct/m\n",
    "    return accuracy, correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Test(net, loader_test, \\\n",
    "         device='cpu', Loss=nn.NLLLoss(reduction='sum'), \\\n",
    "         test_time_epochs = 3):\n",
    "    net.train()\n",
    "    total_samples = 0\n",
    "    correct_samples = 0\n",
    "    loss = 0.0\n",
    "    step=0\n",
    "    (X_prev, y_prev) = (None, None)\n",
    "    (X_prev_prev, y_prev_prev) = (None, None)\n",
    "    for (X, y) in loader_test:\n",
    "        # print(step, end=\" \")\n",
    "        X=X.to(device)\n",
    "        y=y.to(device)\n",
    "        total_samples += y.shape[0]\n",
    "   \n",
    "        for e in range(test_time_epochs): \n",
    "            x_reconst = net(X, classifier=False)\n",
    "            ae_loss = 0.0\n",
    "            for feat in range(0, X.shape[-1], 5):\n",
    "                ae_loss += Loss(nn.LogSoftmax(dim=1)(x_reconst[:, feat:feat+5]),X[:, feat:feat+5].argmax(dim=1))\n",
    "            net.optimizer.zero_grad()\n",
    "            ae_loss.backward()\n",
    "            net.optimizer.step()\n",
    "        \n",
    "            if X_prev_prev is not None:\n",
    "                y_pred = net(X_prev_prev, classifier=True)\n",
    "                cl_loss = Loss(y_pred, y_prev_prev)\n",
    "                net.optimizer.zero_grad()\n",
    "                cl_loss.backward()\n",
    "                net.optimizer.step()\n",
    "\n",
    "        y_pred = net(X, classifier=True)\n",
    "        cl_loss = Loss(y_pred, y)\n",
    "\n",
    "        loss += (ae_loss+cl_loss).item()\n",
    "        _, i_cor_sam = accuracy(y_pred, y,verbose=False)\n",
    "        correct_samples += i_cor_sam\n",
    "        step+=1\n",
    "\n",
    "        (X_prev_prev, y_prev_prev) = (X_prev, y_prev)\n",
    "        (X_prev, y_prev) = (X, y)\n",
    "\n",
    "    # print()\n",
    "    \n",
    "    acc = correct_samples / total_samples\n",
    "    loss /= total_samples\n",
    "    print('Test/Val loss:', loss, 'Test/Val acc:', acc)\n",
    "    return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train(Net, train_loader, noise_level, epochs=20, Loss=nn.NLLLoss(reduction='sum'), \n",
    "          verbose=False, device='cpu',\n",
    "          val_ds=None, loader_test=None):\n",
    "    model_save_time = time.time()\n",
    "    losses = []\n",
    "    accs = []\n",
    "    val_losses=[]\n",
    "    val_accL=[]\n",
    "    Net.to(device)\n",
    "    for e in range(epochs):\n",
    "        Net.train()\n",
    "        step=0\n",
    "        tot_loss=0.0\n",
    "        start_time = time.time()\n",
    "        correct_samples = 0\n",
    "        total_samples = 0\n",
    "        for (X,y) in train_loader:\n",
    "            X=X.to(device)\n",
    "            y=y.to(device)\n",
    "            total_samples += y.shape[0]\n",
    "            x_reconst = Net(X, classifier=False) # B x nd x nc = B x 24 x 5\n",
    "            ae_loss = 0.0\n",
    "            for feat in range(0, X.shape[-1], 5):\n",
    "                # print((x_reconst[:, feat:feat+5]),X[:, feat:feat+5].argmax(dim=1))\n",
    "                # print((x_reconst[:, feat:feat+5]).shape,X[:, feat:feat+5].argmax(dim=1).shape)\n",
    "                ae_loss += Loss(nn.LogSoftmax(dim=1)(x_reconst[:, feat:feat+5]),X[:, feat:feat+5].argmax(dim=1))\n",
    "            Net.optimizer.zero_grad()\n",
    "            ae_loss.backward()\n",
    "            Net.optimizer.step()\n",
    "\n",
    "            y_pred = Net(X, classifier=True)\n",
    "            cl_loss = Loss(y_pred, y)\n",
    "            Net.optimizer.zero_grad()\n",
    "            cl_loss.backward()\n",
    "            Net.optimizer.step()\n",
    "\n",
    "            step+=1\n",
    "            tot_loss+=(ae_loss+cl_loss)\n",
    "            if verbose:\n",
    "                _, i_cor_sam = accuracy(y_pred, y,verbose=False)\n",
    "                correct_samples += i_cor_sam\n",
    "            \n",
    "        end_time = time.time()\n",
    "        t = end_time-start_time\n",
    "        l = tot_loss.item()/total_samples\n",
    "        losses += [l]\n",
    "        a = correct_samples/total_samples\n",
    "        accs += [a]\n",
    "\n",
    "        if verbose:\n",
    "            print('Epoch %2d Loss: %2.5e Accuracy: %2.5f Epoch Time: %2.5f' %(e,l,a,t))\n",
    "\n",
    "        val_loss, val_acc = Test(deepcopy(Net), val_ds, device = device)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accL.append(val_acc)\n",
    "\n",
    "        # print(\"TESTING BUDDY:\")\n",
    "        # Test(deepcopy(Net), loader_test, device=device)\n",
    "\n",
    "        torch.save(Net.state_dict(), f'{prefix}/net_{noise_level}_{str(model_save_time)}.pth')\n",
    "\n",
    "    return Net, losses, accs, val_losses, val_accL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_acc(losses, accs, val_losses, val_accs, noise_level):\n",
    "\n",
    "    plt.plot(np.array(accs),color='red', label='Train accuracy')\n",
    "    plt.plot(np.array(val_accs),color='blue', label='Val accuracy')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'{prefix}/acc_{noise_level}.png')\n",
    "    plt.clf()\n",
    "\n",
    "    plt.plot(np.array(losses),color='red', label='Train loss')\n",
    "    plt.plot(np.array(val_losses),color='blue', label='Val loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'{prefix}/loss_{noise_level}.png')\n",
    "    plt.clf()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise Level: none\n",
      "Train-val-test lengths:  56160 6240 62400\n",
      "Epoch  0 Loss: 1.35562e+01 Accuracy: 0.66451 Epoch Time: 13.73608\n",
      "Test/Val loss: 6.441279413761237 Test/Val acc: 0.7636217948717948\n",
      "Epoch  1 Loss: 5.64665e+00 Accuracy: 0.81033 Epoch Time: 13.19080\n",
      "Test/Val loss: 4.4791025479634605 Test/Val acc: 0.8016025641025641\n",
      "Epoch  2 Loss: 4.06327e+00 Accuracy: 0.84687 Epoch Time: 13.49744\n",
      "Test/Val loss: 3.3675367538745586 Test/Val acc: 0.8283653846153847\n",
      "Epoch  3 Loss: 3.18884e+00 Accuracy: 0.86519 Epoch Time: 14.06193\n",
      "Test/Val loss: 2.6006258988991764 Test/Val acc: 0.8421474358974359\n",
      "Epoch  4 Loss: 2.62698e+00 Accuracy: 0.87815 Epoch Time: 12.89028\n",
      "Test/Val loss: 2.056350353436592 Test/Val acc: 0.8649038461538462\n",
      "Epoch  5 Loss: 2.26596e+00 Accuracy: 0.89154 Epoch Time: 13.38373\n",
      "Test/Val loss: 1.5909811148276696 Test/Val acc: 0.875\n",
      "Epoch  6 Loss: 1.90132e+00 Accuracy: 0.90132 Epoch Time: 13.34750\n",
      "Test/Val loss: 1.2922603154793764 Test/Val acc: 0.8849358974358974\n",
      "Epoch  7 Loss: 1.78554e+00 Accuracy: 0.91165 Epoch Time: 12.76845\n",
      "Test/Val loss: 1.0901425358576653 Test/Val acc: 0.9009615384615385\n",
      "Epoch  8 Loss: 1.24565e+00 Accuracy: 0.92215 Epoch Time: 13.15418\n",
      "Test/Val loss: 1.675867136930808 Test/Val acc: 0.8945512820512821\n",
      "Epoch  9 Loss: 8.30812e-01 Accuracy: 0.93082 Epoch Time: 13.03945\n",
      "Test/Val loss: 1.3449051392384064 Test/Val acc: 0.8857371794871794\n",
      "Epoch 10 Loss: 1.15572e+00 Accuracy: 0.93362 Epoch Time: 13.33844\n",
      "Test/Val loss: 1.0202429066865872 Test/Val acc: 0.9049679487179487\n",
      "Epoch 11 Loss: 1.42074e+00 Accuracy: 0.93488 Epoch Time: 13.25285\n",
      "Test/Val loss: 0.6075392402899571 Test/Val acc: 0.9209935897435897\n",
      "Epoch 12 Loss: 1.11537e+00 Accuracy: 0.93866 Epoch Time: 13.42379\n",
      "Test/Val loss: 0.49178018631079257 Test/Val acc: 0.9251602564102565\n",
      "Epoch 13 Loss: 1.32213e+00 Accuracy: 0.94035 Epoch Time: 13.56739\n",
      "Test/Val loss: 0.5311151987467057 Test/Val acc: 0.9350961538461539\n",
      "Epoch 14 Loss: 3.40027e-01 Accuracy: 0.95280 Epoch Time: 13.22936\n",
      "Test/Val loss: 0.5998724634066607 Test/Val acc: 0.9181089743589743\n",
      "Epoch 15 Loss: 1.29711e+00 Accuracy: 0.94398 Epoch Time: 13.39242\n",
      "Test/Val loss: 0.37048355363882507 Test/Val acc: 0.9274038461538462\n",
      "Epoch 16 Loss: 2.42304e-01 Accuracy: 0.95673 Epoch Time: 12.96228\n",
      "Test/Val loss: 1.2434740213247446 Test/Val acc: 0.9102564102564102\n",
      "Epoch 17 Loss: 9.78673e-01 Accuracy: 0.95100 Epoch Time: 13.56100\n",
      "Test/Val loss: 0.3406080497763096 Test/Val acc: 0.9270833333333334\n",
      "Epoch 18 Loss: 1.06461e+00 Accuracy: 0.95082 Epoch Time: 12.79053\n",
      "Test/Val loss: 0.35095373789469403 Test/Val acc: 0.9434294871794872\n",
      "Epoch 19 Loss: 2.20262e-01 Accuracy: 0.96143 Epoch Time: 13.28801\n",
      "Test/Val loss: 0.27569650018062347 Test/Val acc: 0.9358974358974359\n",
      "Test/Val loss: 4.339528981538919 Test/Val acc: 0.7740544871794872\n",
      "4.339528981538919 0.7740544871794872\n",
      "Noise Level: high\n",
      "Train-val-test lengths:  56160 6240 62400\n",
      "Epoch  0 Loss: 2.21814e+01 Accuracy: 0.42466 Epoch Time: 13.76999\n",
      "Test/Val loss: 16.32612878359281 Test/Val acc: 0.4341346153846154\n",
      "Epoch  1 Loss: 1.42649e+01 Accuracy: 0.49541 Epoch Time: 13.26373\n",
      "Test/Val loss: 14.109246752812313 Test/Val acc: 0.4423076923076923\n",
      "Epoch  2 Loss: 1.24394e+01 Accuracy: 0.50808 Epoch Time: 14.12932\n",
      "Test/Val loss: 12.676643430269682 Test/Val acc: 0.4592948717948718\n",
      "Epoch  3 Loss: 1.11804e+01 Accuracy: 0.51743 Epoch Time: 13.12553\n",
      "Test/Val loss: 11.64025768622374 Test/Val acc: 0.4620192307692308\n",
      "Epoch  4 Loss: 1.03436e+01 Accuracy: 0.52117 Epoch Time: 13.18072\n",
      "Test/Val loss: 10.885559844970704 Test/Val acc: 0.46474358974358976\n",
      "Epoch  5 Loss: 9.67496e+00 Accuracy: 0.52658 Epoch Time: 12.26201\n",
      "Test/Val loss: 10.207240527715438 Test/Val acc: 0.4684294871794872\n",
      "Epoch  6 Loss: 9.09078e+00 Accuracy: 0.52975 Epoch Time: 12.95717\n",
      "Test/Val loss: 9.677922261066925 Test/Val acc: 0.4809294871794872\n",
      "Epoch  7 Loss: 8.61838e+00 Accuracy: 0.53360 Epoch Time: 13.05607\n",
      "Test/Val loss: 9.313852288172795 Test/Val acc: 0.4846153846153846\n",
      "Epoch  8 Loss: 8.25781e+00 Accuracy: 0.53723 Epoch Time: 12.89584\n",
      "Test/Val loss: 9.038282504448524 Test/Val acc: 0.48701923076923076\n",
      "Epoch  9 Loss: 7.98856e+00 Accuracy: 0.53951 Epoch Time: 14.02072\n",
      "Test/Val loss: 8.779620287968562 Test/Val acc: 0.49567307692307694\n",
      "Epoch 10 Loss: 7.75681e+00 Accuracy: 0.54087 Epoch Time: 13.59616\n",
      "Test/Val loss: 8.551289829841027 Test/Val acc: 0.5011217948717949\n",
      "Epoch 11 Loss: 7.53400e+00 Accuracy: 0.54295 Epoch Time: 12.96438\n",
      "Test/Val loss: 8.331160851013966 Test/Val acc: 0.5036858974358974\n",
      "Epoch 12 Loss: 7.30420e+00 Accuracy: 0.54526 Epoch Time: 14.35755\n",
      "Test/Val loss: 8.104790532283294 Test/Val acc: 0.5049679487179487\n",
      "Epoch 13 Loss: 7.08790e+00 Accuracy: 0.54644 Epoch Time: 13.05217\n",
      "Test/Val loss: 7.896042820123526 Test/Val acc: 0.5104166666666666\n",
      "Epoch 14 Loss: 6.88631e+00 Accuracy: 0.54793 Epoch Time: 12.61148\n",
      "Test/Val loss: 7.691263658572466 Test/Val acc: 0.5059294871794872\n",
      "Epoch 15 Loss: 6.71045e+00 Accuracy: 0.55077 Epoch Time: 13.08179\n",
      "Test/Val loss: 7.493895298395401 Test/Val acc: 0.5128205128205128\n",
      "Epoch 16 Loss: 6.55667e+00 Accuracy: 0.55240 Epoch Time: 13.46892\n",
      "Test/Val loss: 7.320419715001033 Test/Val acc: 0.5137820512820512\n",
      "Epoch 17 Loss: 6.41476e+00 Accuracy: 0.55383 Epoch Time: 13.86503\n",
      "Test/Val loss: 7.180613789191613 Test/Val acc: 0.5120192307692307\n",
      "Epoch 18 Loss: 6.28543e+00 Accuracy: 0.55584 Epoch Time: 13.35318\n",
      "Test/Val loss: 7.05987990452693 Test/Val acc: 0.514102564102564\n",
      "Epoch 19 Loss: 6.17577e+00 Accuracy: 0.55684 Epoch Time: 13.51717\n",
      "Test/Val loss: 6.937205052987123 Test/Val acc: 0.5128205128205128\n",
      "Test/Val loss: 7.611560446176774 Test/Val acc: 0.45142628205128205\n",
      "7.611560446176774 0.45142628205128205\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_paths = ['../Datasets/cf_train_no_noise.csv', \n",
    "              '../Datasets/cf_test_no_noise.csv', \n",
    "              '../Datasets/cf_train.csv', \n",
    "              '../Datasets/cf_test.csv']\n",
    "\n",
    "noise_levels = ['none', 'high']\n",
    "batch_sizes = [65, 65,]\n",
    "\n",
    "losses_arr = []\n",
    "accs_arr = []\n",
    "\n",
    "for i in range(0, 3, 2):\n",
    "    train_df = pd.read_csv(df_paths[i])\n",
    "    test_df = pd.read_csv(df_paths[i+1])\n",
    "\n",
    "    print(\"Noise Level:\", noise_levels[i//2])\n",
    "    loader_train, loader_val, loader_test, data = make_data_splits(train_df, test_df, batch_size=batch_sizes[i//2])\n",
    "    net = TestTimeAdapter(ae_dims=[120, 64, 32, 16, 32, 64, 120], \n",
    "                          cl_dims=[16, 16, 5], ).to(device)\n",
    "    net, losses, accs, val_losses, val_accL = Train(net, loader_train, noise_levels[i//2], \\\n",
    "                                    epochs=20, verbose=True, device=device, \\\n",
    "                                        val_ds=loader_val,loader_test=loader_test)\n",
    "    plot_loss_acc(losses, accs, val_losses, val_accL, noise_levels[i//2])\n",
    "    #Testing code\n",
    "    test_loss, test_acc = Test(deepcopy(net), loader_test, device=device)\n",
    "    print(test_loss, test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = Test(net, loader_test, device=device)\n",
    "print(test_loss, test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = Test(net, loader_val, device=device)\n",
    "print(test_loss, test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tiger",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
